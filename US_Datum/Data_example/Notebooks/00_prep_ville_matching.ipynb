{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemple Prepare ETS Data : Normalisation Ville\n",
    "\n",
    "La préparation de la donnée se fait en deux étapes.\n",
    "\n",
    "1. Préparation de l'INPI\n",
    "2. Préparation de l'INSEE\n",
    "\n",
    "L'étape 1 va mettre en conformité la data de l'INPI en vue d'une siretisation. L'étape 2 va utiliser les siren présents lors de l'étape 1 pour ne préparer que ce sous ensemble dans la donnée de l'INSEE.\n",
    "\n",
    "Pour la présentation de la création de la donnée, nous allons utiliser une donnée synthétique qui est l'extraction de toutes les possibilités uniques de dénomination de ville à l'INPI (US [2264](https://tree.taiga.io/project/olivierlubet-air/us/2464)). La donnée est disponible dans le Gitlab [ville_inpi.csv](https://scm.saas.cagip.group.gca/PERNETTH/inseeinpi_matching/raw/master/Notebooks_matching/Data_preprocessed/programme_matching/data/input/RawParameters/ville_inpi.csv)\n",
    "\n",
    "# Introduction\n",
    "\n",
    "Avant de commencer, il faut rappeler pourquoi nous avons besoin de ses nouvelles variables. La finalité de la table inpi_etablissement_historique  est de pouvoir faire le rapprochement avec les établissements à l’INSEE. Ce rapprochement va permettre de récupérer le numéro SIRET de l’établissement qui figure à l’INSEE mais pas à l’INPI.\n",
    "\n",
    "L’étape de sirétisation repose sur un algorithme assez simple qui cherche a matcher des variables communes dans les deux bases puis vérifie la conformité du matching.\n",
    "\n",
    "L'algorithme de SIRETISATION fonctionne avec l'aide de trois fonctions:\n",
    "\n",
    "* [step_one](https://scm.saas.cagip.group.gca/PERNETTH/inseeinpi_matching/tree/master/Notebooks_matching/Data_preprocessed/programme_matching/02_siretisation#step-one) : permet d'écarter les doublons du merge et d'appliquer les premières règles afin de connaitre l'origine de la siretisation\n",
    "* [step_two_assess_test](https://scm.saas.cagip.group.gca/PERNETTH/inseeinpi_matching/tree/master/Notebooks_matching/Data_preprocessed/programme_matching/02_siretisation#step_two_assess_test) : détermine l'origine du matching, a savoir la date, adresse, voie, numéro de voie\n",
    "* [step_two_duplication](https://scm.saas.cagip.group.gca/PERNETTH/inseeinpi_matching/tree/master/Notebooks_matching/Data_preprocessed/programme_matching/02_siretisation#step_two_duplication) : permet de récupérer des SIRET sur les doublons émanant du merge avec l'INSEE\n",
    "\n",
    "L'algorithme va utiliser séquentiellement les variables suivantes, en plus du siren:\n",
    "\n",
    "```\n",
    " {'ville_matching', 'Code_Postal', 'Code_Commune', 'INSEE', 'digit_inpi'},\n",
    " {'ville_matching', 'Code_Postal', 'Code_Commune', 'INSEE'},\n",
    " {'ville_matching', 'Code_Postal', 'Code_Commune', 'digit_inpi'},\n",
    " {'ville_matching', 'Code_Postal', 'Code_Commune'},   \n",
    " {'ville_matching', 'Code_Postal'},\n",
    " {'ville_matching'},\n",
    " {'Code_Postal'},\n",
    " {'Code_Commune'}\n",
    " ```\n",
    " \n",
    "Chacune des variables ci dessus proviennent de l’INPI, et sont disponibles a l’INSEE sous les noms suivants:\n",
    "\n",
    "| Source | Method        | Preparation                 | URL                         | INPI_INSEE_equiv            | Detail création                 |\n",
    "|--------|---------------|-----------------------------|-----------------------------|-----------------------------|---------------------------------|\n",
    "| INSEE  | normalisation | libelleCommuneEtablissement | [libelleCommuneEtablissement](https://scm.saas.cagip.group.gca/PERNETTH/inseeinpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/inpi_insee/preparation_data.py#L708) | ville_matching                         |                                 |\n",
    "| INPI   | Creation      | ville_matching                         | [ncc](https://scm.saas.cagip.group.gca/PERNETTH/inseeinpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/inpi_insee/preparation_data.py#L131)                         | libelleCommuneEtablissement | Detail preparation siretisation |\n",
    "| INPI   | Creation      | adresse_new_clean_reg       | [adresse_new_clean_reg](https://scm.saas.cagip.group.gca/PERNETTH/inseeinpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/inpi_insee/preparation_data.py#L311)       | libelleVoieEtablissement    | Detail preparation siretisation |\n",
    "| INPI   | Creation      | digit_inpi                  | [digit_inpi](https://scm.saas.cagip.group.gca/PERNETTH/inseeinpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/inpi_insee/preparation_data.py#L315)                  | numeroVoieEtablissement     | Detail preparation siretisation |\n",
    "| INPI   | Creation      | INSEE                       | [INSEE](https://scm.saas.cagip.group.gca/PERNETTH/inseeinpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/inpi_insee/preparation_data.py#L325)                       | typeVoieEtablissement       | Detail preparation siretisation |\n",
    "| INPI   | normalisation | code_commune                |                             | codeCommuneEtablissement    |                                 |\n",
    "| INPI   | normalisation | code_postal                 |                             | codePostalEtablissement     |                                 |\n",
    "| INSEE   | normalisation | ville_matching                 |                             | ville_matching     |                                 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "os.chdir('../')\n",
    "current_dir = os.getcwd()\n",
    "#from inpi_insee import preparation_data\n",
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpi_ville = 'https://scm.saas.cagip.group.gca/PERNETTH/inseeinpi_matching/raw' \\\n",
    "'/master/Notebooks_matching/Data_preprocessed/programme_matching/data/input' \\\n",
    "'/RawParameters/ville_inpi.csv'\n",
    "\n",
    "path_commune = 'https://scm.saas.cagip.group.gca/PERNETTH/inseeinpi_matching/raw' \\\n",
    "'/master/Notebooks_matching/Data_preprocessed/programme_matching/data/input' \\\n",
    "'/RawParameters/communes-01012019.csv'\n",
    "\n",
    "param = {\n",
    "    #'communes_insee': commune,\n",
    "    #'upper_word':stopword,\n",
    "    # \"voie\": voie,\n",
    "    'insee_ville':  path_commune,\n",
    "   # 'inpi_etb': etb_ex,\n",
    "    'inpi_ville':inpi_ville,\n",
    "    #'date_end':\"2020-01-01\"\n",
    "}\n",
    "#prep_data = preparation_data.preparation(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La technique de normalisation a été proposé par Jonathan Collet. L'idée est de nettoyer suiffisant les villes à l'INPI afin de les faire correspondre à l'INSEE. La technique utilise un trick, qui est d'enlever tous les espaces dans les deux tables afin d'avoir une \"clé\" unique. Par exemple, la ville suivante à l'INPI est `Soisy-sur-Seine`, alors qu'à l'INSEE, c'est `SOISY SUR SEINE`. En nettoyant la ville à l'INPI et en enlevant les espaces dans les deux champs, on peut créer une clé unique pour faire le matching, donnant lieu à la valeur suivante: `SOISYSURSEINE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step by step approach\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation ville_matching\n",
    "\n",
    " \n",
    "La variable `ville_matching` correspond a la valeur normalisée du libellé de la commune. La même variable sera a créer a l'INSEE, appelé aussi `ville_matching`.\n",
    "\n",
    "La création de cette variable s’opère en 1 étape:\n",
    "\n",
    "1. Ajout `ville_matching` dans la table historique\n",
    "  1. input [Table] : `inpi_etablissement_historique_` \n",
    "    2. Code préparation: [Jupyter notebook 00_prep_ville_matching](https://scm.saas.cagip.group.gca/PERNETTH/inseeinpi_matching/blob/master/US_Datum/Data_example/Notebooks/00_prep_ville_matching.md#regex-nettoyage)\n",
    "  2. Output [Champs]\n",
    "    1. `ville_matching`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpi = pd.read_csv(param['inpi_ville'])\n",
    "inpi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex nettoyage\n",
    "\n",
    "Le regex opère de manière séquentiel:\n",
    "\n",
    "1. Extraction des accents\n",
    "2. Extraction des digits\n",
    "3. Mettre en lettre majuscule le string\n",
    "4. Extraction de \"LA\", \"LES\" et \"LE\" (methode imparfaite actuellement)\n",
    "5. Normalisation \"ST\", \"ST \" à \"SAINT\"\n",
    "6. Normalisation \"S\", \"S/ \" à \"SUR\"\n",
    "7. Extraction pattern regex:\n",
    "    1. charactère sepciaux\n",
    "    2. Espace debut de string\n",
    "    3. Parenthèse\n",
    "    4. ER ARRONDISSEMENT, E ARRONDISSEMENT\n",
    "    5. SUR\n",
    "    6. CEDEX\n",
    "    7. Digit\n",
    "    8. espace\n",
    "8. Remplacement 'MARSEILLEE' à \"MARSEILLE\"\n",
    "    - Ceci est du au pattern suivant:\n",
    "        - MARSEILLE (15E)\n",
    "        - Regex enlève \"(\", \")\",\" \" et \"15\"\n",
    "            - output: \"MARSEILLEE\"\n",
    "            \n",
    "le code sous forme de notebook est disponible dans le Gitlab: [Jupyter notebook 00_prep_ville_matching](https://scm.saas.cagip.group.gca/PERNETTH/inseeinpi_matching/blob/master/US_Datum/Data_example/Notebooks/00_prep_ville_matching.md#regex-nettoyage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r\"[^\\w\\s]|\\([^()]*\\)|ER ARRONDISSEMENT|E ARRONDISSEMENT|\" \\\n",
    "\"|^SUR$|CEDEX|[0-9]+|\\s+\"\n",
    "test = (inpi\n",
    " .assign(\n",
    "ville_matching =lambda x: x['ville']\n",
    "     .str.normalize('NFKD') ### Supprimer accents\n",
    "     .str.encode('ascii', errors='ignore')\n",
    "     .str.decode('utf-8')\n",
    "     .str.replace(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", '') #### digit\n",
    "     .str.upper() ### Majuscule\n",
    "     .str.replace(\"^LA\\s+|^LES\\s+|^LE\\s+\", '') #### Pas de LE/LA/LES a l'INSEE\n",
    "     .str.replace('^ST$|^ST\\s+', 'SAINT')  #### Normalise SAINT\n",
    "     .str.replace('^S$|S/', 'SUR')  #### Normaliser SUR\n",
    "     .str.replace(regex, '') ### pattern regex\n",
    "     .str.replace('MARSEILLEE', 'MARSEILLE') #### Probleme dans le regex, donc modification temporaire\n",
    " )\n",
    " )\n",
    "test.loc[lambda x: x['ville_matching'].isin(['MARSEILLE'])][\n",
    "    ['ville','ville_matching']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test acceptance\n",
    "\n",
    "Pour vérifier si le nettoyage est plus ou moins correcte, nous pouvons faire les tests suivants:\n",
    "\n",
    "1. Compter le nombre de villes unique à L'INPI.Au moment du test, il y avait 76545 patterns uniques a l'INPI\n",
    "2. Compter le nombre uniques de patterns uniques à l'INPI. Au moment du test, il y avait 38802 patterns uniques a l'INPI\n",
    "3. Utiliser le fichier des communes à l'INSEE, [Code officiel géographique au 1er janvier 2019 et au 1er avril 2019 | Insee](https://www.insee.fr/fr/information/3720946), et le merger avec toutes les valeurs uniques possibles de l'INPI. Lors du test, nous avons matché 90% des valeurs à l'INPI, soit 76543 observations, laissant de coté 8796 valeurs possibles. Lors de nos tests, nous avons stocké un fichier Excel avec les villes non matchées. Il est disponible à l'adresse [suivante](https://scm.saas.cagip.group.gca/PERNETTH/inseeinpi_matching/blob/master/US_Datum/Data_example/ville_non_matchees.xlsx). Un tel fichier peut être créer afin d'améliorer les règles de gestion dans l'avenir. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Compter le nombre uniques de ville à l'INPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['ville'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Compter le nombre uniques de patterns uniques à l'INPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['ville_matching'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Test match INSEE et INPI \n",
    "\n",
    "Pour réaliser ce test, il est possible de récupérer les valeurs uniques possibles de `ville_matching` à l'INPI, puis d'utiliser le csv [communes-01012019.csv](https://scm.saas.cagip.group.gca/PERNETTH/inseeinpi_matching/raw/master/Notebooks_matching/Data_preprocessed/programme_matching/data/input/RawParameters/communes-01012019.csv) et d'appliquer le pattern regex et enlever les espaces. Dès que la variable est prête à l'INSEE, un simple right_join (INSEE -> INPI), en gardant les valeurs non matchées permet de vérifier l'exactitude du matching. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "insee = pd.read_csv(param['insee_ville'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merge = (insee\n",
    " .assign(ncc = lambda x: x['ncc'].str.replace(r'\\s+', '').str.replace(regex, ''))       \n",
    " .merge(test, how = 'right', indicator = True, left_on = 'ncc', \n",
    "        right_on = 'ville_matching')\n",
    ")\n",
    "\n",
    "pd.concat([\n",
    "    test_merge['_merge'].value_counts().rename('count'),\n",
    "    test_merge['_merge'].value_counts(normalize = True).rename('pct')\n",
    "], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple avec la ville `Soisy-sur-Seine`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insee.loc[lambda x: x['nccenr'].isin(['Soisy-sur-Seine'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merge.loc[lambda x: x['ville'].isin(['Soisy-sur-Seine'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegarde des non matchées dans un fichier Excel, appellé, \"ville_non_matchees.xlsx\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_merge\n",
    " .loc[lambda x: x['_merge'].isin(['right_only'])]\n",
    " .drop_duplicates(subset = [\"ville_matching\"])[['ville', 'ville_matching']]\n",
    " .sort_values(by = 'ville')\n",
    " .to_excel('ville_non_matchees.xlsx')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
