{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Test Matching Insee/ETS\n",
    "\n",
    "## INSEE\n",
    "\n",
    "- https://s3.console.aws.amazon.com/s3/object/calfdata/INSEE/Stock/ETS/\n",
    "        - INSEE/Stock/ETS/StockEtablissement_utf8.csv\n",
    "        \n",
    "```\n",
    "['siren', 'siret']\n",
    "```\n",
    "\n",
    "## INPI\n",
    "\n",
    "- https://s3.console.aws.amazon.com/s3/buckets/calfdata/INPI/TC_1/Stock_processed/\n",
    "    - INPI/TC_1/Stock_processed/initial_ETS.gz\n",
    "    - INPI/TC_1/Stock_processed/initial_ETS.json\n",
    "    \n",
    "Colonnes test:\n",
    "\n",
    "```\n",
    "[\"Siren\",\"Date_Immatriculation\", \"Date_Clôture\", \"Date_Greffe\"]\n",
    "```\n",
    "\n",
    "## Sauvegarde\n",
    "\n",
    "* La liste des SIREN matchés sera sauvegardée selon leur nature et origine\n",
    "  * nature → ACTES/COMPTES/ETS/etc\n",
    "  * origine → initial/partiel/new/evt\n",
    "\n",
    "Les matchés seront sauvegardé dans calfdata/SIRETISATION/matche/ au format suivant:\n",
    "\n",
    "* insee_nature_origine_matche.gz\n",
    "    * ex: insee_pm_initial_matche.gz\n",
    "    \n",
    "    \n",
    "\n",
    "## Moteur de recherche TEST\n",
    "\n",
    "* Insee\n",
    "  * http://avis-situation-sirene.insee.fr/IdentificationListeSiret.action\n",
    "* INPI/TC\n",
    "  * https://data.inpi.fr/\n",
    "* Infogreffe\n",
    "  * https://www.infogreffe.fr/\n",
    "\n",
    "\n",
    "Le siège ne donne pas de nouveau SIRET, il indique seulement le lieu de la juridiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import boto3, json\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "#import Match_inpi_insee.aws_connectors as aws\n",
    "#from tqdm.notebook import tqdm\n",
    "#import tqdm\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#instance_aws = 'https://calfdata.s3.eu-west-3.amazonaws.com'\n",
    "#bucket = 'calfdata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# instanciate AWS connection\n",
    "#AWS_connection = aws.aws_instantiate(instance_aws, bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Preparation fichiers\n",
    "\n",
    "## Matching établissement principal\n",
    "\n",
    "Ici, on filtre les variables communes pour l'INSEE & INPI établissements secondaires.\n",
    "\n",
    "### Candidats\n",
    "\n",
    "**INSEE**\n",
    "\n",
    "https://www.sirene.fr/sirene/public/static/liste-variables\n",
    "\n",
    "- numeroVoieEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/numeroVoieEtablissement\n",
    "- indiceRepetitionEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/indiceRepetitionEtablissement\n",
    "- typeVoieEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/typeVoieEtablissement\n",
    "- libelleVoieEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/libelleVoieEtablissement\n",
    "- complementAdresseEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/complementAdresseEtablissement\n",
    "- codeCommuneEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/codeCommuneEtablissement\n",
    "- libelleCommuneEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/libelleCommuneEtablissement\n",
    "- codePostalEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/codePostalEtablissement\n",
    "- codeCedexEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/codeCedexEtablissement\n",
    "- libelleCedexEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/libelleCedexEtablissement\n",
    "- distributionSpecialeEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/distributionSpecialeEtablissement\n",
    "- libelleCommuneEtrangerEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/libelleCommuneEtrangerEtablissement\n",
    "- codePaysEtrangerEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/codePaysEtrangerEtablissement\n",
    "- libellePaysEtrangerEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/libellePaysEtrangerEtablissement\n",
    "\n",
    "**INPI**\n",
    "\n",
    "- Adresse_Ligne1/Adresse_Ligne2/Adresse_Ligne3: Selon les greffes, l’adresse (n°+ voie) sera présente soit en ligne1 adresse, soit en ligne2 adresse.\n",
    "Toutes les lignes d’adresse ne sont pas nécessairement renseignées.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Créer fichier toutes les possibilités communes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "communes = pd.read_csv('temp_local\\communes-01012019.csv').set_index('ncc').reindex(columns = ['nccenr', 'libelle'])#.unstack()\n",
    "communes.loc[lambda x: x['libelle'].isin(['Châtillon-sur-Chalaronne'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "communes = (pd.read_csv('temp_local\\communes-01012019.csv')\n",
    "            .set_index('ncc')\n",
    "            .reindex(columns=['nccenr', 'libelle'])\n",
    "            .assign(\n",
    "    noaccent=lambda x: x['nccenr'].str.normalize('NFKD')\n",
    "    .str.encode('ascii', errors='ignore')\n",
    "    .str.decode('utf-8'),\n",
    "    nccenr_noponc=lambda x: x['nccenr'].str.replace('[^\\w\\s]', ' '),\n",
    "    libelle_noponc=lambda x: x['libelle'].str.replace('[^\\w\\s]', ' '),\n",
    "    noaccent_noponc=lambda x: x['noaccent'].str.replace('[^\\w\\s]', ' '),\n",
    "    uppercase=lambda x: x.index,\n",
    "    nccenr_uppercase=lambda x: x['nccenr'].str.upper(),\n",
    "    libelle_uppercase=lambda x: x['libelle'].str.upper(),\n",
    "    noaccent_uppercase=lambda x: x['noaccent'].str.upper(),\n",
    "    nccenr_noponc_uppercase=lambda x: x['nccenr_noponc'].str.upper(),\n",
    "    libelle_noponc_uppercase=lambda x: x['libelle_noponc'].str.upper(),\n",
    "    noaccent_noponc_uppercase=lambda x: x['noaccent_noponc'].str.upper(),\n",
    "    nccenr_lowercase=lambda x: x['nccenr'].str.lower(),\n",
    "    libelle_lowercase=lambda x: x['libelle'].str.lower(),\n",
    "    noaccent_lowercase=lambda x: x['noaccent'].str.lower(),\n",
    "    nccenr_noponc_lowercase=lambda x: x['nccenr_noponc'].str.lower(),\n",
    "    libelle_noponc_lowercase=lambda x: x['libelle_noponc'].str.lower(),\n",
    "    noaccent_noponc_lowercase=lambda x: x['noaccent_noponc'].str.lower(),\n",
    "    nccenr_noarrond1=lambda x: x['nccenr'].str.replace(\n",
    "        'er Arrondissement', ''),\n",
    "    uppercase_noarrond1=lambda x: x['uppercase'].str.replace(\n",
    "        'ER ARRONDISSEMENT', ''),\n",
    "    lowercase_noarrond1=lambda x: x['nccenr_lowercase'].str.replace(\n",
    "        'er arrondissement', ''),\n",
    "    nccenr_noarrond=lambda x: x['nccenr'].str.replace('e Arrondissement', ''),\n",
    "    uppercase_noarrond=lambda x: x['uppercase'].str.replace(\n",
    "        'E ARRONDISSEMENT', ''),\n",
    "    lowercase_noarrond=lambda x: x['nccenr_lowercase'].str.replace(\n",
    "        'e arrondissement', ''),\n",
    ")\n",
    ")\n",
    "\n",
    "for n in communes.columns:\n",
    "    var_ = '{}_ST'.format(n)\n",
    "    var_1 = '{}_st'.format(n)\n",
    "    var_2 = '{}_St'.format(n)\n",
    "    \n",
    "    communes[var_] = communes[n].str.replace('SAINT', 'ST')\n",
    "    communes[var_1] = communes[n].str.replace('Saint', 'st')\n",
    "    communes[var_2] = communes[n].str.replace('Saint', 'St')\n",
    "    \n",
    "    var_ = '{}_Sbar'.format(n)\n",
    "    var_1 = '{}_sbar'.format(n)\n",
    "    \n",
    "    communes[var_] = communes[n].str.replace('SUR', 'S/')\n",
    "    communes[var_1] = communes[n].str.replace('sur', 's/')\n",
    "    \n",
    "communes = (communes\n",
    "            .stack()\n",
    "            .rename('possibilite')\n",
    "            .reset_index()\n",
    "            .drop(columns='level_1')\n",
    "            .drop_duplicates(subset=['possibilite']))\n",
    "communes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#insee = AWS_connection.url_instance_bucket(path_file = 'INSEE/Stock/ETS/StockEtablissement_utf8.csv')\n",
    "#ets = AWS_connection.url_instance_bucket(path_file = 'INPI/TC_1/Stock_processed/initial_ETS.gz')\n",
    "#ets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "insee = r\"\\temp_local\\StockEtablissement_utf8.csv\"\n",
    "ets = r\"\\temp_local\\initial_ETS.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  1min 16.5s\n",
      "[########################################] | 100% Completed |  1min 16.5s\n"
     ]
    }
   ],
   "source": [
    "# load data into dataframes\n",
    "data_insee_ = dd.read_csv(insee,\n",
    "                          usecols=['siren',\n",
    "                                   'siret',\n",
    "                                   \"numeroVoieEtablissement\",\n",
    "                                   \"indiceRepetitionEtablissement\",\n",
    "                                   \"typeVoieEtablissement\",\n",
    "                                   \"libelleVoieEtablissement\",\n",
    "                                   \"complementAdresseEtablissement\",\n",
    "                                   \"codeCommuneEtablissement\",\n",
    "                                   \"libelleCommuneEtablissement\",\n",
    "                                   \"codePostalEtablissement\",\n",
    "                                   \"codeCedexEtablissement\",\n",
    "                                   \"libelleCedexEtablissement\",\n",
    "                                   \"distributionSpecialeEtablissement\",\n",
    "                                   \"libelleCommuneEtrangerEtablissement\",\n",
    "                                   \"codePaysEtrangerEtablissement\",\n",
    "                                   \"libellePaysEtrangerEtablissement\",\n",
    "                                   \"dateCreationEtablissement\"\n",
    "                                   ],\n",
    "                          dtype={'siren': 'object',\n",
    "                                 'siret': 'object',\n",
    "                                 \"numeroVoieEtablissement\":'object',\n",
    "                                   \"indiceRepetitionEtablissement\":'object',\n",
    "                                   \"typeVoieEtablissement\":'object',\n",
    "                                   \"libelleVoieEtablissement\":'object',\n",
    "                                   \"complementAdresseEtablissement\":'object',\n",
    "                                   \"codeCommuneEtablissement\":'object',\n",
    "                                   \"libelleCommuneEtablissement\":'object',\n",
    "                                   \"codePostalEtablissement\":'object',\n",
    "                                   \"codeCedexEtablissement\":'object',\n",
    "                                   \"libelleCedexEtablissement\":'object',\n",
    "                                   \"distributionSpecialeEtablissement\":'object',\n",
    "                                   \"libelleCommuneEtrangerEtablissement\":'object',\n",
    "                                   \"codePaysEtrangerEtablissement\":'object',\n",
    "                                   \"libellePaysEtrangerEtablissement\":'object'\n",
    "                                 }\n",
    "                          )\n",
    "\n",
    "data_ets_ = (dd.read_csv(ets,\n",
    "                         usecols=[\n",
    "                             'Type',\n",
    "                             'Siren',\n",
    "                             'Code_Postal',\n",
    "                             'Code_Commune',\n",
    "                             'Adresse_Ligne1',\n",
    "                             'Adresse_Ligne2',\n",
    "                             'Adresse_Ligne3',\n",
    "                             'Ville',\n",
    "                             'Pays'\n",
    "                         ],\n",
    "                         dtype={\n",
    "                             'Type': 'object',\n",
    "                             'Siren': 'object',\n",
    "                             'Code_Postal': 'object',\n",
    "                             'Code_Commune': 'object',\n",
    "                             'Adresse_Ligne1': 'object',\n",
    "                             'Adresse_Ligne2': 'object',\n",
    "                             'Adresse_Ligne3': 'object',\n",
    "                             'Ville':'object',\n",
    "                             'Pays':'object'\n",
    "                         },\n",
    "                         compression='gzip',\n",
    "                         blocksize=None,\n",
    "                         low_memory=False\n",
    "                         )\n",
    "             .compute()\n",
    "             .rename(columns={\"Siren\": \"siren\"})\n",
    "             .loc[lambda x: ~x['Type'].isin(['SIE'])]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data_insee_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data_ets_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "siren_inpi = data_ets_['siren'].drop_duplicates()\n",
    "len(siren_inpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "len(siren_inpi)/data_ets_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_insee = (data_insee_\n",
    "                .loc[data_insee_['siren'].isin(siren_inpi.to_list())]\n",
    "                .loc[data_insee_['dateCreationEtablissement'] <= \"2018-01-01\"]\n",
    "                .assign(\n",
    "                libelleCommuneEtablissement = lambda x:\n",
    "                    x['libelleCommuneEtablissement'].str.replace('-', ' ')\n",
    "                )\n",
    "                .compute()\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Siren INPI mais pas INSEE -> Cette entreprise a exercé son droit d'opposition auprès de l'INSEE. Ses données ne peuvent pas être diffusées publiquement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "temp insee - > gagner du temps pendant la periode de dév\n",
    "temp inpi - > gagner du temps pendant la periode de dév"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "siren_to_remove = siren_inpi.loc[lambda x : ~x.isin(subset_insee['siren'])]\n",
    "len(siren_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_siren_to_find = data_ets_.loc[lambda x:\n",
    "                                 (~x['siren'].isin(siren_to_remove))    \n",
    "                                 ]\n",
    "len(df_siren_to_find)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_siren_to_find.to_csv('temp_inpi.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Nan variables matching \n",
    "\n",
    "on exclue les variables avec que des nan dans les variables candidates\n",
    "\n",
    "-> on les traitera après"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "siren_fullna = df_siren_to_find.loc[lambda x:\n",
    "                      (x['Adresse_Ligne1'].isin([np.nan]))\n",
    "                     & (x['Adresse_Ligne2'].isin([np.nan]))\n",
    "                     & (x['Adresse_Ligne3'].isin([np.nan]))\n",
    "                     & (x['Code_Postal'].isin([np.nan]))\n",
    "                     & (x['Ville'].isin([np.nan]))\n",
    "                     & (x['Code_Commune'].isin([np.nan]))\n",
    "                     ]['siren']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_siren_to_find = df_siren_to_find.loc[lambda x:\n",
    "                                 (~x['siren'].isin(siren_fullna))\n",
    "                                 ]\n",
    "len(siren_fullna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Nombres d'ets par SIREN INSEE\n",
    "\n",
    "On calcule le nombre d'etb pour le fichier INSEE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_insee_count = subset_insee.merge(\n",
    "    (subset_insee\n",
    "     .groupby('siren')['siren']\n",
    "     .count()\n",
    "     .rename('count')\n",
    "     .reset_index())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_siren_to_find = df_siren_to_find.merge(\n",
    "    (df_siren_to_find\n",
    "     .groupby('siren')['siren']\n",
    "     .count()\n",
    "     .rename('count')\n",
    "     .reset_index()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_siren_to_find.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Insee enlever les tirets dans la ville"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def siren_unique(df):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    print(\"Nombre total obs: {}\".format(len(df)))\n",
    "    count_ = (df\n",
    "              .groupby('siren')['siren']\n",
    "              .count()\n",
    "              .rename('count')\n",
    "              .reset_index()\n",
    "              .groupby('count')['count']\n",
    "              .count()\n",
    "              .reset_index(name='total_count')\n",
    "              .set_index('count')\n",
    "              # .compute()\n",
    "              .assign(pct=lambda x: x/x.sum())\n",
    "              .iloc[:10, :]\n",
    "              .style\n",
    "              .format('{:,.2%}', subset=['pct'])\n",
    "              )\n",
    "    return count_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Quick stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "siren_unique(df = subset_insee_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "siren_unique(df = df_siren_to_find)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 0: Clean ville\n",
    "\n",
    "Ajout matching des communes pour retrouver le libelé commune de l'INSEE\n",
    "\n",
    "ATTENTION, il faut nétoyer la variables ville dans l'INSEE. Veuillez regarder le fichier `communes.xlsx` pour voir les différents problèmes\n",
    "\n",
    "ex: \n",
    "- CEDEX, cedex, digit, (d+), \n",
    "\n",
    "attention, l'arrondissement peut être mis entre parenthèse \n",
    "\n",
    "- MARSEILLE (7E)\n",
    "\n",
    "- process:\n",
    "    - creer variables avec numeric seulement\n",
    "    - recreer ville 2 si test pas NAN pour avoir l'arrondissement\n",
    "    - virer les differentes informations dans ville via regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "regex = 'CEDEX|cedex|Cedex|\\([^)]*\\)|/\\s\\s+/|^\\d+\\s|\\s\\d+\\s|\\s\\d+$|\\d+|\\.|\\--|COMMUNE DE |COMMUNE DE|commune de |commune de|Commune de |Commune de |\\s$'\n",
    "test_adress = df_siren_to_find.copy()\n",
    "test_adress['test'] =test_adress['Ville'].str.extract(r'(\\d+)')\n",
    "test_adress['Ville_clean'] = test_adress['Ville'].str.replace(regex,'')\n",
    "test_adress['Ville_clean'] = test_adress['Ville_clean'].str.replace('\\s$|\\s^','')\n",
    "test_adress['ville2'] = np.where(\n",
    "    np.logical_and(\n",
    "         ~test_adress['test'].isin([np.nan]),\n",
    "        test_adress['test'].str.len() <=2\n",
    "    )\n",
    "   ,\n",
    "    test_adress['Ville_clean'] + '' + test_adress['test'].astype(str),\n",
    "    test_adress['Ville_clean']\n",
    ")\n",
    "\n",
    "test_adress = test_adress.merge(communes,\n",
    "                         left_on='ville2',\n",
    "                         right_on='possibilite',\n",
    "                         how='left',\n",
    "                         indicator=True)\n",
    "\n",
    "test_adress = pd.concat([\n",
    "    test_adress.loc[lambda x: x['_merge'].isin(['both'])],\n",
    "    (test_adress\n",
    "     .loc[lambda x: x['_merge'].isin(['left_only'])]\n",
    "     .drop(columns=['ncc', 'possibilite', '_merge'])\n",
    "     .merge(communes,\n",
    "            left_on='Ville_clean',\n",
    "            right_on='possibilite',\n",
    "            how='left',\n",
    "            indicator=True)\n",
    "     )\n",
    "\n",
    "])\n",
    "\n",
    "test_adress = pd.concat([\n",
    "    test_adress.loc[lambda x: x['_merge'].isin(['both'])],\n",
    "    (test_adress\n",
    "     .loc[lambda x: x['_merge'].isin(['left_only'])]\n",
    "     .drop(columns=['ncc', 'possibilite', '_merge'])\n",
    "     .assign(\n",
    "         noaccent=lambda x: x['Ville_clean'].str.normalize('NFKD')\n",
    "         .str.encode('ascii', errors='ignore')\n",
    "         .str.decode('utf-8'))\n",
    "     ).merge(communes,\n",
    "             left_on='noaccent',\n",
    "             right_on='possibilite',\n",
    "             how='left',\n",
    "             indicator=True)])\n",
    "test_adress.groupby('_merge')[\"_merge\"].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress = test_adress.drop(columns = '_merge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_insee_count.to_csv('subset_insee_count.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": false
   },
   "source": [
    "## Process\n",
    "\n",
    "On ne match que les SIREN dont la date de création est inférieur a 2018\n",
    "\n",
    "1) ~Step : Calculer le nombre de `nan` dans les colonnes de matching~\n",
    "\n",
    "2) ~Step : Compter le nombre de SIRET by SIREN~\n",
    "\n",
    "2) Step 2:  merge sur siren et code postal\n",
    "\n",
    "3) Step 3:  merge sur siren et code commune\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Step 1: Match uniquement les 1 dans INSEE/INPI\n",
    "\n",
    "On enlève les matches du dataframe `df_siren_to_find` et on ajoute les `left_only`.\n",
    "\n",
    "Pareil pour l'INSEE pour gagner en mémoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "## Il y a 4312053 établissements uniques dans l'INPI\n",
    "siren_unique(df = test_adress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "m1_unique = (\n",
    "    subset_insee_count.loc[lambda x: x['count'].isin([1])]\n",
    "    .merge(test_adress.loc[lambda x: x['count'].isin([1])],\n",
    "           how='right', indicator=True)\n",
    ")\n",
    "m1_unique.groupby('_merge')[\"_merge\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Sur les 4312053 etbs uniques, on match 3009904 correctement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Pour recuperer les matchés, on filtre la base initiale -> a savoir `test_adress`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "list_inpi = ['siren',\n",
    "             'siret',\n",
    "             'Type',\n",
    "             'Adresse_Ligne1',\n",
    "             'Adresse_Ligne2',\n",
    "             'Adresse_Ligne3',\n",
    "             'Code_Postal',\n",
    "             'Ville',\n",
    "             'Code_Commune',\n",
    "             'Pays',\n",
    "             'count',\n",
    "             'test',\n",
    "             'Ville_clean',\n",
    "             'ville2',\n",
    "             'ncc',\n",
    "             'possibilite',\n",
    "             'noaccent',\n",
    "             '_merge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def match_unmatch(df_inpi_initial, df_inpi_mergeboth, step = '1_unique_siren',\n",
    "                  to_csv = True):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    merge_ = (\n",
    "        df_inpi_mergeboth\n",
    "        .merge(df_inpi_initial,\n",
    "               how='right',\n",
    "               indicator=True)\n",
    "    )\n",
    "    \n",
    "    match_ = merge_.loc[lambda x: \n",
    "                       x['_merge'].isin(['both'])].drop(columns = '_merge')\n",
    "    \n",
    "    unmatch_ = merge_.loc[lambda x: \n",
    "                       ~x['_merge'].isin(['both'])].drop(columns = ['_merge',\n",
    "                                                                    'siret'])\n",
    "    \n",
    "    dic_ = {\n",
    "        \n",
    "        'total_match':match_.shape[0],\n",
    "        'total_unmatch':unmatch_.shape[0],\n",
    "    }\n",
    "    \n",
    "    if to_csv:\n",
    "        name_match = 'data/Match/match_{}_{}.gz'.format(step, match_.shape[0])\n",
    "        name_unmatch = 'data/Unmatch/unmatch_{}_{}.gz'.format(\n",
    "            step, unmatch_.shape[0])\n",
    "        match_.to_csv(name_match, index = True, compression='gzip',)\n",
    "        unmatch_.to_csv(name_unmatch, index = True,compression='gzip')\n",
    "        \n",
    "    return unmatch_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress1 = match_unmatch(\n",
    "    df_inpi_initial=test_adress,\n",
    "    df_inpi_merge=m1_unique.reindex(columns=list_inpi).loc[lambda x:\n",
    "                                         x['_merge'].isin(['both'])].drop(columns=['_merge']),\n",
    "    step='1_unique_siren',\n",
    "    to_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Conclusion step 1:\n",
    "\n",
    "- matched: 3009904\n",
    "- Unmatched: 1969368"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "siren_unique(df = test_adress1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Exemple de SIREN qui ont seulement une ligne dans l'INPI mais plusieurs SIRET dans l'INSEE.\n",
    "\n",
    "- 813543063\n",
    "- 800897092"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress1.loc[lambda x: x['count'] ==1].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_insee_count.loc[lambda x: x['siren'].isin(['813543063'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_insee_count.loc[lambda x: x['siren'].isin(['800897092'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_insee_count.isna().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress.isna().sum().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Step 2: Merging \n",
    "\n",
    "Dans cette partie, on va merger sur plusieurs candidats. La plupart des SIREN peuvent être matché via le code postal, code commune, ou ville directement. Si un SIREN a plusieurs SIRET dans la même ville ou code postal, il fera l'objet d'une recherche plus poussée.\n",
    "\n",
    "Trois cas de figure découle du merge:\n",
    "\n",
    "- 1) Merge forte pertinence\n",
    "- 2) merge pertinence moyenne -> plusieurs SIRET pour un même candidat\n",
    "- 3) Unmerge\n",
    "\n",
    "#### 1:  merge sur siren et Ville\n",
    "\n",
    "- Merge sur siren & libelleCommuneEtablissement|Ville_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test = test_adress1.merge(subset_insee_count,\n",
    "                   how='left',\n",
    "                   left_on=['siren', 'ncc'],\n",
    "                   right_on=['siren', 'libelleCommuneEtablissement'],\n",
    "                   indicator=True,\n",
    "                   suffixes=['_insee', '_inpi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test['_merge'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "### calcul le nombre cas de figure 2 -> très conservative\n",
    "test_match = (test.loc[lambda x: x['_merge'].isin(['both'])]\n",
    "              .merge(\n",
    "                  (test.loc[lambda x: x['_merge'].isin(['both'])]\n",
    "            .groupby(['siren', 'libelleCommuneEtablissement'])['siren']\n",
    "            .count()\n",
    "            .rename('count')\n",
    "            .reset_index()\n",
    "                  )\n",
    "              )\n",
    ")\n",
    "test_match['count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress2 = match_unmatch(\n",
    "    df_inpi_initial=test_adress1,\n",
    "    df_inpi_mergeboth=(test_match\n",
    "                       .loc[lambda x: x['count'].isin([1])]\n",
    "                   .reindex(columns=list_inpi).loc[lambda x:\n",
    "                                         x['_merge'].isin(['both'])]\n",
    "                   .drop(columns = ['count','_merge'])),\n",
    "    step='2_ville',\n",
    "    to_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress2.shape[0] + test_match['count'].value_counts().loc[1] == test_adress1.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### 2:  merge sur siren et code postal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test = test_adress2.merge(subset_insee_count,\n",
    "                   how='left',\n",
    "                   left_on=['siren', 'Code_Postal'],\n",
    "                   right_on=['siren', 'codePostalEtablissement'],\n",
    "                   indicator=True,\n",
    "                   suffixes=['_insee', '_inpi'])\n",
    "test['_merge'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "### calcul le nombre cas de figure 2 -> très conservative\n",
    "test_match = (test.loc[lambda x: x['_merge'].isin(['both'])]\n",
    "              .merge(\n",
    "                  (test.loc[lambda x: x['_merge'].isin(['both'])]\n",
    "            .groupby(['siren', 'codePostalEtablissement'])['siren']\n",
    "            .count()\n",
    "            .rename('count')\n",
    "            .reset_index()\n",
    "                  )\n",
    "              )\n",
    ")\n",
    "test_match['count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress3 = match_unmatch(\n",
    "    df_inpi_initial=test_adress2,\n",
    "    df_inpi_mergeboth=(test_match\n",
    "                       .loc[lambda x: x['count'].isin([1])]\n",
    "                   .reindex(columns=list_inpi).loc[lambda x:\n",
    "                                         x['_merge'].isin(['both'])]\n",
    "                   .drop(columns = ['count','_merge'])),\n",
    "    step='3_codePostal',\n",
    "    to_csv=True)\n",
    "test_adress3.shape[0] + test_match['count'].value_counts().loc[1] == test_adress2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 3:  merge sur siren et code commune\n",
    "\n",
    "- Merge sur siren & codeCommuneEtablissement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test = test_adress3.merge(subset_insee_count,\n",
    "                   how='left',\n",
    "                   left_on=['siren', 'Code_Commune'],\n",
    "                   right_on=['siren', 'codeCommuneEtablissement'],\n",
    "                   indicator=True,\n",
    "                   suffixes=['_insee', '_inpi'])\n",
    "test['_merge'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "### calcul le nombre cas de figure 2 -> très conservative\n",
    "test_match = (test.loc[lambda x: x['_merge'].isin(['both'])]\n",
    "              .merge(\n",
    "                  (test.loc[lambda x: x['_merge'].isin(['both'])]\n",
    "            .groupby(['siren', 'codeCommuneEtablissement'])['siren']\n",
    "            .count()\n",
    "            .rename('count')\n",
    "            .reset_index()\n",
    "                  )\n",
    "              )\n",
    ")\n",
    "test_match['count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_match['count'].value_counts().loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress4 = match_unmatch(\n",
    "    df_inpi_initial=test_adress3,\n",
    "    df_inpi_mergeboth=(test_match\n",
    "                       .loc[lambda x: x['count'].isin([1])]\n",
    "                   .reindex(columns=list_inpi).loc[lambda x:\n",
    "                                         x['_merge'].isin(['both'])]\n",
    "                   .drop(columns = ['count','_merge'])),\n",
    "    step='4_codecommune',\n",
    "    to_csv=True)\n",
    "test_adress4.shape[0] + test_match['count'].value_counts().loc[1] == test_adress3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress4.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Créer code loop step 1/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Match adresse\n",
    "\n",
    "Il reste 14% des siren a matcher avec l'adresse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "### Total a matcher avant ville/code postal/commune\n",
    "test_adress4.shape[0] / test_adress.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Match avec adresse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "On selectionne uniquement ceux pas matché.\n",
    "Pour accélerer la recherche, on utilise que le sous ensemble de siren a vérifier dans le fichier INSEE\n",
    "\n",
    "Verifier si on peut matcher avec le numéro de l'adresse -> au cas ou principal et secondaire dans le même endroit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Il faut retravailler les adresses:\n",
    "\n",
    "- Upper case\n",
    "\n",
    "La recherche se fait sur le libellé adresse. Dans l'INSEE, pas de numéro de voie, ni de typologie (rue, avenue, etc)\n",
    "\n",
    "ALL: Allée\n",
    "AV: Avenue\n",
    "BD: Boulevard\n",
    "CAR: Carrefour\n",
    "CHE: Chemin\n",
    "CHS: Chaussée\n",
    "CITE: Cité\n",
    "COR: Corniche\n",
    "CRS: Cours\n",
    "DOM: Domaine\n",
    "DSC: Descente\n",
    "ECA: Ecart\n",
    "ESP: Esplanade\n",
    "FG: Faubourg\n",
    "GR: Grande Rue\n",
    "HAM: Hameau\n",
    "HLE: Halle\n",
    "IMP: Impasse\n",
    "LD: Lieu dit\n",
    "LOT: Lotissement\n",
    "MAR: Marché\n",
    "MTE: Montée\n",
    "PAS: Passage\n",
    "PL: Place\n",
    "PLN: Plaine\n",
    "PLT: Plateau\n",
    "PRO: Promenade\n",
    "PRV: Parvis\n",
    "QUA: Quartier\n",
    "QUAI: Quai\n",
    "RES: Résidence\n",
    "RLE: Ruelle\n",
    "ROC: Rocade\n",
    "RPT: Rond Point\n",
    "RTE: Route\n",
    "RUE: Rue\n",
    "SEN: Sente - Sentier\n",
    "SQ: Square\n",
    "TPL: Terre-plein\n",
    "TRA: Traverse\n",
    "VLA: Villa\n",
    "VLGE: Village"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "additional = [\"Avenue\",\n",
    "\"Boulevard\",\n",
    "\"Carrefour\",\n",
    "\"Chemin\",\n",
    "\"Chaussee\",\n",
    "\"Cite\",\n",
    "\"Corniche\",\n",
    "\"Cours\",\n",
    "\"Domaine\",\n",
    "\"Descente\",\n",
    "\"Ecart\",\n",
    "\"Esplanade\",\n",
    "\"Faubourg\",\n",
    "\"Grande Rue\",\n",
    "\"Hameau\",\n",
    "\"Halle\",\n",
    "\"Impasse\",\n",
    "\"Lieu dit\",\n",
    "\"Lotissement\",\n",
    "\"Marche\",\n",
    "\"Montee\",\n",
    "\"Passage\",\n",
    "\"Place\",\n",
    "\"Plaine\",\n",
    "\"Plateau\",\n",
    "\"Promenade\",\n",
    "\"Parvis\",\n",
    "\"Quartier\",\n",
    "\"Quai\",\n",
    "\"Residence\",\n",
    "\"Ruelle\",\n",
    "\"Rocade\",\n",
    "\"Rond Point\",\n",
    "\"Route\",\n",
    "\"Rue\",\n",
    "\"Sentier\",\n",
    "\"Square\",\n",
    "\"Terre plein\",\n",
    "\"Traverse\",\n",
    "\"Villa\",\n",
    "\"Village\", 'Rn',\n",
    "'bp', 'cedex', 'Bis',\n",
    "\t\t'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N',\n",
    "\t\t'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('french')\n",
    "stop_words.extend(additional)\n",
    "upper_stop = [i.upper() for i in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def create_split_adress(x):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    split_ = x.str.split().to_list()\n",
    "    return  split_\n",
    "\n",
    "\n",
    "def create_regex_adress(x):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        split_ = [i + \"$\" for i in x]\n",
    "        reg = '|'.join(split_)\n",
    "    except:\n",
    "        reg = np.nan\n",
    "    return  reg\n",
    "\n",
    "import re\n",
    "\n",
    "def find_regex(regex, test_str, siret):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        matches = re.search(regex, test_str)\n",
    "        if matches:\n",
    "            return siret\n",
    "        else:\n",
    "            return np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def prepare_adress(df):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    temp_adresse = df.assign(\n",
    "    \n",
    "        Adress_new = lambda x: \n",
    "        x['Adresse_Ligne1'].fillna('') + ' '+\\\n",
    "        x['Adresse_Ligne2'].fillna('') + ' '+\\\n",
    "        x['Adresse_Ligne3'].fillna(''),\n",
    "        Adresse_new_clean=lambda x: x['Adress_new'].str.normalize(\n",
    "            'NFKD')\n",
    "        .str.encode('ascii', errors='ignore')\n",
    "        .str.decode('utf-8')\n",
    "        .str.replace('[^\\w\\s]|\\d+', ' ')\n",
    "        .str.upper(),\n",
    "\n",
    "    )\n",
    "    temp_adresse['Adresse_new_clean'] = (temp_adresse['Adresse_new_clean']\n",
    "                                            .apply(lambda x:\n",
    "                                                   ' '.join([word for word in\n",
    "                                                             str(x).split() if\n",
    "                                                             word not in \n",
    "                                                             (upper_stop)]))\n",
    "                                            )\n",
    "                                            \n",
    "    temp_adresse = temp_adresse.assign(\n",
    "        Adresse_new_clean_split=lambda x:\n",
    "        create_split_adress(x['Adresse_new_clean'])\n",
    "    )\n",
    "\n",
    "    temp_adresse['Adresse_new_clean_reg'] = \\\n",
    "    temp_adresse['Adresse_new_clean_split'].apply(lambda x:\n",
    "                                                     create_regex_adress(x))\n",
    "    \n",
    "    temp_adresse = temp_adresse.drop(columns = ['Adresse_new_clean',\n",
    "                                                'Adresse_new_clean_split'])\n",
    "\n",
    "    return temp_adresse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Creer des fichiers intermediaires pour éviter prob memoire\n",
    "\n",
    "Pour accelerer le code, on utilise uniquement les adresses sans les na et on filtre l'insee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#http://yaoyao.codes/pandas/2018/01/23/pandas-split-a-dataframe-into-chunks\n",
    "def index_marks(nrows, chunk_size):\n",
    "    return range(1 * chunk_size, (nrows // chunk_size + 1) * chunk_size, chunk_size)\n",
    "\n",
    "def split(dfm, chunk_size):\n",
    "    indices = index_marks(dfm.shape[0], chunk_size)\n",
    "    return np.split(dfm, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "POur acceleter le calcul, on convertit la df en Dask et on fait un map partition\n",
    "\n",
    "Penser a garder NCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar\n",
    "from dask.multiprocessing import get\n",
    "import re\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pbar = ProgressBar()\n",
    "pbar.register()\n",
    "\n",
    "\n",
    "\n",
    "# load data into dataframes\n",
    "subset_insee_count = dd.read_csv('subset_insee_count.csv',\n",
    "                          usecols=['siren',\n",
    "            'siret',\n",
    "            'libelleCommuneEtablissement',\n",
    "            'libelleVoieEtablissement',\n",
    "            'numeroVoieEtablissement',\n",
    "                                   'codePostalEtablissement',\n",
    "                                   'codeCommuneEtablissement'\n",
    "                                   ],\n",
    "                          dtype={'siren': 'object',\n",
    "                                 'siret': 'object',\n",
    "                                 \"libelleCommuneEtablissement\":'object',\n",
    "                                   \"libelleVoieEtablissement\":'object',\n",
    "                                   \"numeroVoieEtablissement\":'object',\n",
    "                                 'codePostalEtablissement':'object',\n",
    "                                 'codeCommuneEtablissement':'object'\n",
    "                                 }\n",
    "                          )\n",
    "\n",
    "def find_regex(regex, test_str, siret):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        matches = re.search(regex, test_str)\n",
    "        if matches:\n",
    "            return siret\n",
    "        else:\n",
    "            return np.nan\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress4 = pd.read_csv(r'data\\Unmatch\\unmatch_4_codecommune_703641.gz',\n",
    "                          compression='gzip',low_memory=False)\n",
    "city_ = prepare_adress(test_adress4).iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "city_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "chunks = split(city_, 60000)\n",
    "try:\n",
    "    for i in range(0, 10):\n",
    "        chunks[i].to_csv(\n",
    "        r'Data\\Unmatch\\chunk\\chunk_{}.csv'.format(i), index = False)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def prepare_csvAdress(df_input, option=['ncc', 'libelleCommuneEtablissement'],\n",
    "                      chunk=0):\n",
    "    \"\"\"\n",
    "    option list can only be one of these:\n",
    "    - ['ncc', 'libelleCommuneEtablissement']\n",
    "    - ['ncc', 'libelleCommuneEtablissement']\n",
    "    - ['ncc', 'libelleCommuneEtablissement']\n",
    "    \"\"\"\n",
    "\n",
    "    list_inpi = ['siren',\n",
    "                 'siret',\n",
    "                 'Type',\n",
    "                 'Adresse_Ligne1',\n",
    "                 'Adresse_Ligne2',\n",
    "                 'Adresse_Ligne3',\n",
    "                 'Code_Postal',\n",
    "                 'Ville',\n",
    "                 'Code_Commune',\n",
    "                 'Pays',\n",
    "                 'test',\n",
    "                 'Ville_clean',\n",
    "                 'ville2',\n",
    "                 'ncc',\n",
    "                 'possibilite',\n",
    "                 'noaccent']\n",
    "    if '_merge' in df_input.columns:\n",
    "        df_input = (df_input\n",
    "                    .drop(columns=['siret',\n",
    "                                   'numeroVoieEtablissement',\n",
    "                                   'libelleVoieEtablissement',\n",
    "                                   'codePostalEtablissement',\n",
    "                                   'libelleCommuneEtablissement',\n",
    "                                   'codeCommuneEtablissement',\n",
    "                                   '_merge']))\n",
    "\n",
    "    temp = df_input.merge(subset_insee_count,\n",
    "                          how='left',\n",
    "                          left_on=['siren', option[0]],\n",
    "                          right_on=['siren',  option[1]],\n",
    "                          indicator=True,\n",
    "                          suffixes=['_insee', '_inpi'])\n",
    "\n",
    "    to_check = temp[temp['_merge'].isin(['both'])]\n",
    "    nomatch = temp[~temp['_merge'].isin(['both'])]\n",
    "    # test\n",
    "    # to_check = to_check.dropna(subset = ['libelleVoieEtablissement'])\n",
    "    to_check['siret_test1'] = to_check.map_partitions(\n",
    "        lambda df:\n",
    "        df.apply(lambda x:\n",
    "                 find_regex(\n",
    "                     x['Adresse_new_clean_reg'],\n",
    "                     x['libelleVoieEtablissement'],\n",
    "                     x['siret']), axis=1)\n",
    "    )\n",
    "\n",
    "    to_check = to_check.dropna(subset=['siret_test1']).compute()\n",
    "\n",
    "    # calcul le nombre cas de figure 2 -> très conservative\n",
    "    test_match = (to_check\n",
    "                  .merge(\n",
    "                      (to_check\n",
    "                       .groupby(['siren', 'Adress_new'])['siren']\n",
    "                       .count()\n",
    "                       .rename('count')\n",
    "                       .reset_index()\n",
    "                       )\n",
    "                  )\n",
    "                  )\n",
    "    print(test_match['count'].value_counts())\n",
    "    true_match = (test_match\n",
    "                  .loc[lambda x:x['count'] == 1]\n",
    "                  .reindex(columns=list_inpi))\n",
    "\n",
    "    name_csv = r'Data\\\\Match\\chunk\\{}\\{}_true_match_{}.csv'.format(\n",
    "        option[0], chunk, true_match.shape[0])\n",
    "\n",
    "    true_match.to_csv(name_csv, index=False)\n",
    "\n",
    "    dic_ = {\n",
    "        'true_match': true_match,\n",
    "        'unmatch': nomatch\n",
    "    }\n",
    "\n",
    "    return dic_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_nomatch = pd.DataFrame()\n",
    "for chunk in [0,\n",
    "              1,2,3,4,5,6,7,8,9\n",
    "             ]:\n",
    "    csv_file = r'Data\\Unmatch\\chunk\\chunk_{}.csv'.format(chunk)\n",
    "    test1 = dd.read_csv('{}'.format(csv_file),\n",
    "                                 usecols=[\n",
    "                                     'siren',\n",
    "                                     'Code_Postal',\n",
    "                                     'Adress_new',\n",
    "                                     'Adresse_new_clean_reg',\n",
    "                                     'Type',\n",
    "                                     'Adresse_Ligne1',\n",
    "                                     'Adresse_Ligne2',\n",
    "                                     'Adresse_Ligne3',\n",
    "                                     'Ville',\n",
    "                                     'Code_Commune',\n",
    "                                     'Pays',\n",
    "                                     'test',\n",
    "                                     'Ville_clean',\n",
    "                                     'ville2',\n",
    "                                     'ncc',\n",
    "                                     'possibilite',\n",
    "                                     'noaccent',\n",
    "                                     'Adress_new',\n",
    "                                     'Adresse_new_clean_reg'],\n",
    "                dtype={\n",
    "                    'siren':'object',\n",
    "                                     'Code_Postal':'object',\n",
    "                                     'Adress_new':'object',\n",
    "                                     'Adresse_new_clean_reg':'object',\n",
    "                                     'Type':'object',\n",
    "                                     'Adresse_Ligne1':'object',\n",
    "                                     'Adresse_Ligne2':'object',\n",
    "                                     'Adresse_Ligne3':'object',\n",
    "                                     'Ville':'object',\n",
    "                                     'Code_Commune':'object',\n",
    "                                     'Pays':'object',\n",
    "                                     'test':'object',\n",
    "                                     'Ville_clean':'object',\n",
    "                                     'ville2':'object',\n",
    "                                     'ncc':'object',\n",
    "                                     'possibilite':'object',\n",
    "                                     'noaccent':'object',\n",
    "                                     'Adress_new':'object',\n",
    "                                     'Adresse_new_clean_reg':'object'\n",
    "            },\n",
    "                blocksize=None,\n",
    "            )\n",
    "\n",
    "    df_input = test1\n",
    "    total_match = pd.DataFrame()\n",
    "    for i in [\n",
    "        ['ncc', 'libelleCommuneEtablissement'],\n",
    "        ['Code_Postal', 'codePostalEtablissement'],\n",
    "        ['Code_Commune', 'codeCommuneEtablissement']\n",
    "    ]:\n",
    "        df_input_ = prepare_csvAdress(df_input=df_input,\n",
    "                                  option=i, chunk=chunk)\n",
    "\n",
    "        df_input = df_input_['unmatch']\n",
    "        total_match = total_match.append(df_input_['true_match'])\n",
    "        \n",
    "    chunk0 = pd.read_csv(r'data\\Unmatch\\chunk\\chunk_{}.csv'.format(chunk),dtype={\n",
    "                    'siren':'object',\n",
    "                                     'Code_Postal':'object',\n",
    "                                     'Adress_new':'object',\n",
    "                                     'Adresse_new_clean_reg':'object',\n",
    "                                     'Type':'object',\n",
    "                                     'Adresse_Ligne1':'object',\n",
    "                                     'Adresse_Ligne2':'object',\n",
    "                                     'Adresse_Ligne3':'object',\n",
    "                                     'Ville':'object',\n",
    "                                     'Code_Commune':'object',\n",
    "                                     'Pays':'object',\n",
    "                                     'test':'object',\n",
    "                                     'Ville_clean':'object',\n",
    "                                     'ville2':'object',\n",
    "                                     'ncc':'object',\n",
    "                                     'possibilite':'object',\n",
    "                                     'noaccent':'object',\n",
    "                                     'Adress_new':'object',\n",
    "                                     'Adresse_new_clean_reg':'object'\n",
    "            })\n",
    "    \n",
    "    test_adress2 = match_unmatch(\n",
    "        df_inpi_initial=chunk0,\n",
    "        df_inpi_mergeboth=total_match,\n",
    "        step='5_adress_{}'.format(chunk),\n",
    "        to_csv=False)\n",
    "    \n",
    "    df_nomatch = df_nomatch.append(test_adress2)\n",
    "\n",
    "\n",
    "#name_csv = r'Data\\Unmatch\\chunk\\{}\\{}_to_check.csv'.format(\n",
    "#    'adress_only', 0)\n",
    "#df_input_['unmatch'].compute().to_csv(name_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_nomatch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_nomatch.shape[0] / 4312053"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_nomatch.loc[lambda x:x['siren'].isin(['388239667'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#subset_insee_count = subset_insee_count.compute()\n",
    "#subset_insee_count.loc[lambda x:x['siren'].isin(['388239667'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#subset_insee_count.loc[lambda x:x['siren'].isin(['388239667'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Match avec numero de rue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_nomatch = df_nomatch.drop(columns = 'digit_inpi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def match_voie(df_input, option=['ncc', 'libelleCommuneEtablissement']):\n",
    "    \"\"\"\n",
    "    option list can only be one of these:\n",
    "    - ['ncc', 'libelleCommuneEtablissement']\n",
    "    - ['ncc', 'libelleCommuneEtablissement']\n",
    "    - ['ncc', 'libelleCommuneEtablissement']\n",
    "    \"\"\"\n",
    "\n",
    "    list_inpi = ['siren',\n",
    "                 'siret',\n",
    "                 'Type',\n",
    "                 'Adresse_Ligne1',\n",
    "                 'Adresse_Ligne2',\n",
    "                 'Adresse_Ligne3',\n",
    "                 'Code_Postal',\n",
    "                 'Ville',\n",
    "                 'Code_Commune',\n",
    "                 'Pays',\n",
    "                 'test',\n",
    "                 'Ville_clean',\n",
    "                 'ville2',\n",
    "                 'ncc',\n",
    "                 'possibilite',\n",
    "                 'noaccent']\n",
    "    if '_merge' in df_input.columns:\n",
    "        df_input = (df_input\n",
    "                    .drop(columns=['siret',\n",
    "                                   'numeroVoieEtablissement',\n",
    "                                   'libelleVoieEtablissement',\n",
    "                                   'codePostalEtablissement',\n",
    "                                   'libelleCommuneEtablissement',\n",
    "                                   'codeCommuneEtablissement',\n",
    "                                   '_merge']))\n",
    "\n",
    "    temp = df_input.merge(subset_insee_count,\n",
    "                          how='left',\n",
    "                          left_on=['siren', option[0]],\n",
    "                          right_on=['siren',  option[1]],\n",
    "                          indicator=True,\n",
    "                          suffixes=['_insee', '_inpi'])\n",
    "\n",
    "    to_check = temp[temp['_merge'].isin(['both'])]\n",
    "    nomatch = temp[~temp['_merge'].isin(['both'])]\n",
    "    \n",
    "    to_check['siret_test1'] = to_check.map_partitions(\n",
    "        lambda df:\n",
    "        df.apply(lambda x:\n",
    "                 find_regex(\n",
    "                     x['Adresse_new_clean_reg'],\n",
    "                     x['libelleVoieEtablissement'],\n",
    "                     x['siret']), axis=1)\n",
    "    )\n",
    "    to_check = to_check.dropna(subset=['siret_test1']).compute()\n",
    "    to_check['digit_inpi'] = to_check['Adress_new'].str.extract(r'(\\d+)')\n",
    "    return to_check\n",
    "    \n",
    "    # test\n",
    "    # to_check = to_check.dropna(subset = ['libelleVoieEtablissement'])\n",
    "    to_check['test'] = np.where(\n",
    "    to_check['digit_inpi'] == \n",
    "        to_check['numeroVoieEtablissement'] ,\n",
    "    True, False\n",
    "    )\n",
    "\n",
    "    to_check = to_check[to_check['test'].isin([True])]\n",
    "\n",
    "    # calcul le nombre cas de figure 2 -> très conservative\n",
    "    test_match = (to_check\n",
    "                  .merge(\n",
    "                      (to_check\n",
    "                       .groupby(['siren', 'numeroVoieEtablissement'])['siren']\n",
    "                       .count()\n",
    "                       .rename('count')\n",
    "                       .reset_index()\n",
    "                       )\n",
    "                  )\n",
    "                  )\n",
    "    print(test_match['count'].value_counts())\n",
    "    true_match = (test_match\n",
    "                  .loc[lambda x:x['count'] == 1]\n",
    "                  .reindex(columns=list_inpi))\n",
    "\n",
    "    name_csv = r'Data\\Match\\numero\\{}\\voie_match_{}.csv'.format(\n",
    "        option[0], true_match.shape[0])\n",
    "\n",
    "    true_match.to_csv(name_csv, index=False)\n",
    "\n",
    "    dic_ = {\n",
    "        'true_match': true_match,\n",
    "        'unmatch': nomatch\n",
    "    }\n",
    "\n",
    "    return dic_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_nomatch.to_csv(r'data\\Unmatch\\06_voie.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "unmatch_adress = dd.read_csv(r'data\\Unmatch\\06_voie.csv',dtype={\n",
    "                    'siren':'object',\n",
    "                                     'Code_Postal':'object',\n",
    "                                     'Adress_new':'object',\n",
    "                                     'Adresse_new_clean_reg':'object',\n",
    "                                     'Type':'object',\n",
    "                                     'Adresse_Ligne1':'object',\n",
    "                                     'Adresse_Ligne2':'object',\n",
    "                                     'Adresse_Ligne3':'object',\n",
    "                                     'Ville':'object',\n",
    "                                     'Code_Commune':'object',\n",
    "                                     'Pays':'object',\n",
    "                                     'test':'object',\n",
    "                                     'Ville_clean':'object',\n",
    "                                     'ville2':'object',\n",
    "                                     'ncc':'object',\n",
    "                                     'possibilite':'object',\n",
    "                                     'noaccent':'object',\n",
    "                                     'Adress_new':'object',\n",
    "                                     'Adresse_new_clean_reg':'object'\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  1min 45.0s\n",
      "[########################################] | 100% Completed |  1min 45.0s\n"
     ]
    }
   ],
   "source": [
    "df_input_ = match_voie(df_input=unmatch_adress,\n",
    "                       option=['ncc', 'libelleCommuneEtablissement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  0.8s\n",
      "[########################################] | 100% Completed |  0.9s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siren</th>\n",
       "      <th>Type</th>\n",
       "      <th>Adresse_Ligne1</th>\n",
       "      <th>Adresse_Ligne2</th>\n",
       "      <th>Adresse_Ligne3</th>\n",
       "      <th>Code_Postal</th>\n",
       "      <th>Ville</th>\n",
       "      <th>Code_Commune</th>\n",
       "      <th>Pays</th>\n",
       "      <th>test</th>\n",
       "      <th>Ville_clean</th>\n",
       "      <th>ville2</th>\n",
       "      <th>ncc</th>\n",
       "      <th>possibilite</th>\n",
       "      <th>noaccent</th>\n",
       "      <th>count</th>\n",
       "      <th>Adress_new</th>\n",
       "      <th>Adresse_new_clean_reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>750767907</td>\n",
       "      <td>SEP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15 rue Ampère</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01100</td>\n",
       "      <td>Oyonnax</td>\n",
       "      <td>01283</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oyonnax</td>\n",
       "      <td>Oyonnax</td>\n",
       "      <td>OYONNAX</td>\n",
       "      <td>Oyonnax</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>15 rue Ampère</td>\n",
       "      <td>AMPERE$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>750767907</td>\n",
       "      <td>SEP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15 rue Ampère</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01100</td>\n",
       "      <td>Oyonnax</td>\n",
       "      <td>01283</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oyonnax</td>\n",
       "      <td>Oyonnax</td>\n",
       "      <td>OYONNAX</td>\n",
       "      <td>Oyonnax</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>15 rue Ampère</td>\n",
       "      <td>AMPERE$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        siren Type Adresse_Ligne1 Adresse_Ligne2 Adresse_Ligne3 Code_Postal  \\\n",
       "85  750767907  SEP            NaN  15 rue Ampère            NaN       01100   \n",
       "86  750767907  SEP            NaN  15 rue Ampère            NaN       01100   \n",
       "\n",
       "      Ville Code_Commune    Pays test Ville_clean   ville2      ncc  \\\n",
       "85  Oyonnax        01283  FRANCE  NaN     Oyonnax  Oyonnax  OYONNAX   \n",
       "86  Oyonnax        01283  FRANCE  NaN     Oyonnax  Oyonnax  OYONNAX   \n",
       "\n",
       "   possibilite noaccent  count       Adress_new Adresse_new_clean_reg  \n",
       "85     Oyonnax      NaN      2   15 rue Ampère                AMPERE$  \n",
       "86     Oyonnax      NaN      2   15 rue Ampère                AMPERE$  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmatch_adress.compute().loc[lambda x:x['siren'].isin(['750767907'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ets = r\"C:\\Users\\PERNETTH\\Documents\\Projects\\InseeInpi_matching\\Notebooks_matching\\temp_local\\initial_ETS.gz\"\n",
    "data_ets_ = pd.read_csv(ets,\n",
    "                         compression='gzip',\n",
    "                         low_memory=False\n",
    "                         ).loc[lambda x:x['siren'].isin(['750767907'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 12.6s\n",
      "[########################################] | 100% Completed | 12.6s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siren</th>\n",
       "      <th>siret</th>\n",
       "      <th>numeroVoieEtablissement</th>\n",
       "      <th>libelleVoieEtablissement</th>\n",
       "      <th>codePostalEtablissement</th>\n",
       "      <th>libelleCommuneEtablissement</th>\n",
       "      <th>codeCommuneEtablissement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>336737</th>\n",
       "      <td>750767907</td>\n",
       "      <td>75076790700017</td>\n",
       "      <td>15</td>\n",
       "      <td>AMPERE</td>\n",
       "      <td>01100</td>\n",
       "      <td>OYONNAX</td>\n",
       "      <td>01283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            siren           siret numeroVoieEtablissement  \\\n",
       "336737  750767907  75076790700017                      15   \n",
       "\n",
       "       libelleVoieEtablissement codePostalEtablissement  \\\n",
       "336737                   AMPERE                   01100   \n",
       "\n",
       "       libelleCommuneEtablissement codeCommuneEtablissement  \n",
       "336737                     OYONNAX                    01283  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_insee_count.compute().loc[lambda x:x['siren'].isin(['750767907'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siren</th>\n",
       "      <th>Type</th>\n",
       "      <th>Adresse_Ligne1</th>\n",
       "      <th>Adresse_Ligne2</th>\n",
       "      <th>Adresse_Ligne3</th>\n",
       "      <th>Code_Postal</th>\n",
       "      <th>Ville</th>\n",
       "      <th>Code_Commune</th>\n",
       "      <th>Pays</th>\n",
       "      <th>test</th>\n",
       "      <th>...</th>\n",
       "      <th>Adresse_new_clean_reg</th>\n",
       "      <th>siret</th>\n",
       "      <th>numeroVoieEtablissement</th>\n",
       "      <th>libelleVoieEtablissement</th>\n",
       "      <th>codePostalEtablissement</th>\n",
       "      <th>libelleCommuneEtablissement</th>\n",
       "      <th>codeCommuneEtablissement</th>\n",
       "      <th>_merge</th>\n",
       "      <th>siret_test1</th>\n",
       "      <th>digit_inpi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>750767907</td>\n",
       "      <td>SEP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15 rue Ampère</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01100</td>\n",
       "      <td>Oyonnax</td>\n",
       "      <td>01283</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>AMPERE$</td>\n",
       "      <td>75076790700017</td>\n",
       "      <td>15</td>\n",
       "      <td>AMPERE</td>\n",
       "      <td>01100</td>\n",
       "      <td>OYONNAX</td>\n",
       "      <td>01283</td>\n",
       "      <td>both</td>\n",
       "      <td>75076790700017</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>750767907</td>\n",
       "      <td>SEP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15 rue Ampère</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01100</td>\n",
       "      <td>Oyonnax</td>\n",
       "      <td>01283</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>AMPERE$</td>\n",
       "      <td>75076790700017</td>\n",
       "      <td>15</td>\n",
       "      <td>AMPERE</td>\n",
       "      <td>01100</td>\n",
       "      <td>OYONNAX</td>\n",
       "      <td>01283</td>\n",
       "      <td>both</td>\n",
       "      <td>75076790700017</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>758200349</td>\n",
       "      <td>SEP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88 rue de Genève</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01220</td>\n",
       "      <td>Divonne-les-Bains</td>\n",
       "      <td>01143</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>GENEVE$</td>\n",
       "      <td>75820034900044</td>\n",
       "      <td>10</td>\n",
       "      <td>DE GENEVE</td>\n",
       "      <td>01220</td>\n",
       "      <td>DIVONNE LES BAINS</td>\n",
       "      <td>01143</td>\n",
       "      <td>both</td>\n",
       "      <td>75820034900044</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>758200349</td>\n",
       "      <td>SEP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88 rue de Genève</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01220</td>\n",
       "      <td>Divonne-les-Bains</td>\n",
       "      <td>01143</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>GENEVE$</td>\n",
       "      <td>75820034900051</td>\n",
       "      <td>88</td>\n",
       "      <td>DE GENEVE</td>\n",
       "      <td>01220</td>\n",
       "      <td>DIVONNE LES BAINS</td>\n",
       "      <td>01143</td>\n",
       "      <td>both</td>\n",
       "      <td>75820034900051</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>662043116</td>\n",
       "      <td>SEC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11 C rue René Char</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21000</td>\n",
       "      <td>Dijon</td>\n",
       "      <td>21231</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>RENE$|CHAR$</td>\n",
       "      <td>66204311603731</td>\n",
       "      <td>11</td>\n",
       "      <td>RENE CHAR</td>\n",
       "      <td>21000</td>\n",
       "      <td>DIJON</td>\n",
       "      <td>21231</td>\n",
       "      <td>both</td>\n",
       "      <td>66204311603731</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        siren Type Adresse_Ligne1      Adresse_Ligne2 Adresse_Ligne3  \\\n",
       "6   750767907  SEP            NaN       15 rue Ampère            NaN   \n",
       "7   750767907  SEP            NaN       15 rue Ampère            NaN   \n",
       "10  758200349  SEP            NaN    88 rue de Genève            NaN   \n",
       "11  758200349  SEP            NaN    88 rue de Genève            NaN   \n",
       "27  662043116  SEC            NaN  11 C rue René Char            NaN   \n",
       "\n",
       "   Code_Postal              Ville Code_Commune    Pays test  ...  \\\n",
       "6        01100            Oyonnax        01283  FRANCE  NaN  ...   \n",
       "7        01100            Oyonnax        01283  FRANCE  NaN  ...   \n",
       "10       01220  Divonne-les-Bains        01143  FRANCE  NaN  ...   \n",
       "11       01220  Divonne-les-Bains        01143  FRANCE  NaN  ...   \n",
       "27       21000              Dijon        21231  FRANCE  NaN  ...   \n",
       "\n",
       "   Adresse_new_clean_reg           siret numeroVoieEtablissement  \\\n",
       "6                AMPERE$  75076790700017                      15   \n",
       "7                AMPERE$  75076790700017                      15   \n",
       "10               GENEVE$  75820034900044                      10   \n",
       "11               GENEVE$  75820034900051                      88   \n",
       "27           RENE$|CHAR$  66204311603731                      11   \n",
       "\n",
       "   libelleVoieEtablissement codePostalEtablissement  \\\n",
       "6                    AMPERE                   01100   \n",
       "7                    AMPERE                   01100   \n",
       "10                DE GENEVE                   01220   \n",
       "11                DE GENEVE                   01220   \n",
       "27                RENE CHAR                   21000   \n",
       "\n",
       "    libelleCommuneEtablissement codeCommuneEtablissement _merge  \\\n",
       "6                       OYONNAX                    01283   both   \n",
       "7                       OYONNAX                    01283   both   \n",
       "10            DIVONNE LES BAINS                    01143   both   \n",
       "11            DIVONNE LES BAINS                    01143   both   \n",
       "27                        DIJON                    21231   both   \n",
       "\n",
       "       siret_test1 digit_inpi  \n",
       "6   75076790700017         15  \n",
       "7   75076790700017         15  \n",
       "10  75820034900044         88  \n",
       "11  75820034900051         88  \n",
       "27  66204311603731         11  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 43.6s\n",
      "[########################################] | 100% Completed | 43.7s\n",
      "1     38220\n",
      "2      3304\n",
      "4       420\n",
      "3        78\n",
      "12       24\n",
      "6        24\n",
      "5         5\n",
      "Name: count, dtype: int64\n",
      "[########################################] | 100% Completed |  1min 12.6s\n",
      "[########################################] | 100% Completed |  1min 12.6s\n",
      "1    10972\n",
      "2     1226\n",
      "4      124\n",
      "3       33\n",
      "6       12\n",
      "8        8\n",
      "5        5\n",
      "Name: count, dtype: int64\n",
      "[########################################] | 100% Completed |  1min 44.5s\n",
      "[########################################] | 100% Completed |  1min 44.5s\n",
      "1    123\n",
      "2     10\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Can only merge Series or DataFrame objects, a <class 'dask.dataframe.core.DataFrame'> was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-040961bab8d2>\u001b[0m in \u001b[0;36mmatch_unmatch\u001b[1;34m(df_inpi_initial, df_inpi_mergeboth, step, to_csv)\u001b[0m\n\u001b[0;32m      7\u001b[0m         .merge(df_inpi_initial,\n\u001b[0;32m      8\u001b[0m                \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'right'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                indicator=True)\n\u001b[0m\u001b[0;32m     10\u001b[0m     )\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m   7295\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7296\u001b[0m             \u001b[0mindicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7297\u001b[1;33m             \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7298\u001b[0m         )\n\u001b[0;32m   7299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mindicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m     )\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    570\u001b[0m     ):\n\u001b[0;32m    571\u001b[0m         \u001b[0m_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_operand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0m_right\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_operand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_left\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_right\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_right\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_validate_operand\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m   2006\u001b[0m         raise TypeError(\n\u001b[0;32m   2007\u001b[0m             \u001b[1;34m\"Can only merge Series or DataFrame objects, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m             \u001b[1;34m\"a {obj} was passed\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m         )\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Can only merge Series or DataFrame objects, a <class 'dask.dataframe.core.DataFrame'> was passed"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_nomatch = pd.DataFrame()\n",
    "df_input = unmatch_adress\n",
    "  \n",
    "total_match = pd.DataFrame()\n",
    "for i in [\n",
    "        ['ncc', 'libelleCommuneEtablissement'],\n",
    "        ['Code_Postal', 'codePostalEtablissement'],\n",
    "        ['Code_Commune', 'codeCommuneEtablissement']\n",
    "    ]:\n",
    "    df_input_ = match_voie(df_input=df_input,\n",
    "                                  option=i)\n",
    "\n",
    "    df_input = df_input_['unmatch']\n",
    "    total_match = total_match.append(df_input_['true_match'])\n",
    "\n",
    "    \n",
    "df_nomatch = match_unmatch(\n",
    "        df_inpi_initial=unmatch_adress.compute(),\n",
    "        df_inpi_mergeboth=total_match,\n",
    "        step='6_voie_',\n",
    "        to_csv=False)\n",
    "\n",
    "#name_csv = r'Data\\Unmatch\\chunk\\{}\\{}_to_check.csv'.format(\n",
    "#    'adress_only', 0)\n",
    "#df_input_['unmatch'].compute().to_csv(name_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_nomatch = match_unmatch(\n",
    "        df_inpi_initial=chunk0.drop(columns = ['test', 'count']),\n",
    "        df_inpi_mergeboth=total_match.drop(columns =  ['test']),\n",
    "        step='6_voie_',\n",
    "        to_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_nomatch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_nomatch.shape[0] / 4312053"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_nomatch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_insee_count = subset_insee_count.compute()\n",
    "subset_insee_count.loc[lambda x:x['siren'].isin(['388239667'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_nomatch.loc[lambda x:x['siren'].isin(['814837621'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_insee_count.loc[lambda x:x['siren'].isin(['814837621'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Deal avec cas de figure 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
