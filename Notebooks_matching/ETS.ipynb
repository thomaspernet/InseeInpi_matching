{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Test Matching Insee/ETS\n",
    "\n",
    "## INSEE\n",
    "\n",
    "- https://s3.console.aws.amazon.com/s3/object/calfdata/INSEE/Stock/ETS/\n",
    "        - INSEE/Stock/ETS/StockEtablissement_utf8.csv\n",
    "        \n",
    "```\n",
    "['siren', 'siret']\n",
    "```\n",
    "\n",
    "## INPI\n",
    "\n",
    "- https://s3.console.aws.amazon.com/s3/buckets/calfdata/INPI/TC_1/Stock_processed/\n",
    "    - INPI/TC_1/Stock_processed/initial_ETS.gz\n",
    "    - INPI/TC_1/Stock_processed/initial_ETS.json\n",
    "    \n",
    "Colonnes test:\n",
    "\n",
    "```\n",
    "[\"Siren\",\"Date_Immatriculation\", \"Date_Clôture\", \"Date_Greffe\"]\n",
    "```\n",
    "\n",
    "## Sauvegarde\n",
    "\n",
    "* La liste des SIREN matchés sera sauvegardée selon leur nature et origine\n",
    "  * nature → ACTES/COMPTES/ETS/etc\n",
    "  * origine → initial/partiel/new/evt\n",
    "\n",
    "Les matchés seront sauvegardé dans calfdata/SIRETISATION/matche/ au format suivant:\n",
    "\n",
    "* insee_nature_origine_matche.gz\n",
    "    * ex: insee_pm_initial_matche.gz\n",
    "    \n",
    "    \n",
    "\n",
    "## Moteur de recherche TEST\n",
    "\n",
    "* Insee\n",
    "  * http://avis-situation-sirene.insee.fr/IdentificationListeSiret.action\n",
    "* INPI/TC\n",
    "  * https://data.inpi.fr/\n",
    "* Infogreffe\n",
    "  * https://www.infogreffe.fr/\n",
    "\n",
    "\n",
    "Le siège ne donne pas de nouveau SIRET, il indique seulement le lieu de la juridiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import boto3, json\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "#import Match_inpi_insee.aws_connectors as aws\n",
    "#from tqdm.notebook import tqdm\n",
    "#import tqdm\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#instance_aws = 'https://calfdata.s3.eu-west-3.amazonaws.com'\n",
    "#bucket = 'calfdata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# instanciate AWS connection\n",
    "#AWS_connection = aws.aws_instantiate(instance_aws, bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Preparation fichiers\n",
    "\n",
    "## Matching établissement principal\n",
    "\n",
    "Ici, on filtre les variables communes pour l'INSEE & INPI établissements secondaires.\n",
    "\n",
    "### Candidats\n",
    "\n",
    "**INSEE**\n",
    "\n",
    "https://www.sirene.fr/sirene/public/static/liste-variables\n",
    "\n",
    "- numeroVoieEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/numeroVoieEtablissement\n",
    "- indiceRepetitionEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/indiceRepetitionEtablissement\n",
    "- typeVoieEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/typeVoieEtablissement\n",
    "- libelleVoieEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/libelleVoieEtablissement\n",
    "- complementAdresseEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/complementAdresseEtablissement\n",
    "- codeCommuneEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/codeCommuneEtablissement\n",
    "- libelleCommuneEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/libelleCommuneEtablissement\n",
    "- codePostalEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/codePostalEtablissement\n",
    "- codeCedexEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/codeCedexEtablissement\n",
    "- libelleCedexEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/libelleCedexEtablissement\n",
    "- distributionSpecialeEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/distributionSpecialeEtablissement\n",
    "- libelleCommuneEtrangerEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/libelleCommuneEtrangerEtablissement\n",
    "- codePaysEtrangerEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/codePaysEtrangerEtablissement\n",
    "- libellePaysEtrangerEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/libellePaysEtrangerEtablissement\n",
    "\n",
    "**INPI**\n",
    "\n",
    "- Adresse_Ligne1/Adresse_Ligne2/Adresse_Ligne3: Selon les greffes, l’adresse (n°+ voie) sera présente soit en ligne1 adresse, soit en ligne2 adresse.\n",
    "Toutes les lignes d’adresse ne sont pas nécessairement renseignées.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Créer fichier toutes les possibilités communes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "communes = pd.read_csv('temp_local\\communes-01012019.csv').set_index('ncc').reindex(columns = ['nccenr', 'libelle'])#.unstack()\n",
    "communes.loc[lambda x: x['libelle'].isin(['Châtillon-sur-Chalaronne'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "communes = (pd.read_csv('temp_local\\communes-01012019.csv')\n",
    "            .set_index('ncc')\n",
    "            .reindex(columns=['nccenr', 'libelle'])\n",
    "            .assign(\n",
    "    noaccent=lambda x: x['nccenr'].str.normalize('NFKD')\n",
    "    .str.encode('ascii', errors='ignore')\n",
    "    .str.decode('utf-8'),\n",
    "    nccenr_noponc=lambda x: x['nccenr'].str.replace('[^\\w\\s]', ' '),\n",
    "    libelle_noponc=lambda x: x['libelle'].str.replace('[^\\w\\s]', ' '),\n",
    "    noaccent_noponc=lambda x: x['noaccent'].str.replace('[^\\w\\s]', ' '),\n",
    "    uppercase=lambda x: x.index,\n",
    "    nccenr_uppercase=lambda x: x['nccenr'].str.upper(),\n",
    "    libelle_uppercase=lambda x: x['libelle'].str.upper(),\n",
    "    noaccent_uppercase=lambda x: x['noaccent'].str.upper(),\n",
    "    nccenr_noponc_uppercase=lambda x: x['nccenr_noponc'].str.upper(),\n",
    "    libelle_noponc_uppercase=lambda x: x['libelle_noponc'].str.upper(),\n",
    "    noaccent_noponc_uppercase=lambda x: x['noaccent_noponc'].str.upper(),\n",
    "    nccenr_lowercase=lambda x: x['nccenr'].str.lower(),\n",
    "    libelle_lowercase=lambda x: x['libelle'].str.lower(),\n",
    "    noaccent_lowercase=lambda x: x['noaccent'].str.lower(),\n",
    "    nccenr_noponc_lowercase=lambda x: x['nccenr_noponc'].str.lower(),\n",
    "    libelle_noponc_lowercase=lambda x: x['libelle_noponc'].str.lower(),\n",
    "    noaccent_noponc_lowercase=lambda x: x['noaccent_noponc'].str.lower(),\n",
    "    nccenr_noarrond1=lambda x: x['nccenr'].str.replace(\n",
    "        'er Arrondissement', ''),\n",
    "    uppercase_noarrond1=lambda x: x['uppercase'].str.replace(\n",
    "        'ER ARRONDISSEMENT', ''),\n",
    "    lowercase_noarrond1=lambda x: x['nccenr_lowercase'].str.replace(\n",
    "        'er arrondissement', ''),\n",
    "    nccenr_noarrond=lambda x: x['nccenr'].str.replace('e Arrondissement', ''),\n",
    "    uppercase_noarrond=lambda x: x['uppercase'].str.replace(\n",
    "        'E ARRONDISSEMENT', ''),\n",
    "    lowercase_noarrond=lambda x: x['nccenr_lowercase'].str.replace(\n",
    "        'e arrondissement', ''),\n",
    ")\n",
    ")\n",
    "\n",
    "for n in communes.columns:\n",
    "    var_ = '{}_ST'.format(n)\n",
    "    var_1 = '{}_st'.format(n)\n",
    "    var_2 = '{}_St'.format(n)\n",
    "    \n",
    "    communes[var_] = communes[n].str.replace('SAINT', 'ST')\n",
    "    communes[var_1] = communes[n].str.replace('Saint', 'st')\n",
    "    communes[var_2] = communes[n].str.replace('Saint', 'St')\n",
    "    \n",
    "    var_ = '{}_Sbar'.format(n)\n",
    "    var_1 = '{}_sbar'.format(n)\n",
    "    \n",
    "    communes[var_] = communes[n].str.replace('SUR', 'S/')\n",
    "    communes[var_1] = communes[n].str.replace('sur', 's/')\n",
    "    \n",
    "communes = (communes\n",
    "            .stack()\n",
    "            .rename('possibilite')\n",
    "            .reset_index()\n",
    "            .drop(columns='level_1')\n",
    "            .drop_duplicates(subset=['possibilite']))\n",
    "communes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#insee = AWS_connection.url_instance_bucket(path_file = 'INSEE/Stock/ETS/StockEtablissement_utf8.csv')\n",
    "#ets = AWS_connection.url_instance_bucket(path_file = 'INPI/TC_1/Stock_processed/initial_ETS.gz')\n",
    "#ets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "insee = r\"\\temp_local\\StockEtablissement_utf8.csv\"\n",
    "ets = r\"\\temp_local\\initial_ETS.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# load data into dataframes\n",
    "data_insee_ = dd.read_csv(insee,\n",
    "                          usecols=['siren',\n",
    "                                   'siret',\n",
    "                                   \"numeroVoieEtablissement\",\n",
    "                                   \"indiceRepetitionEtablissement\",\n",
    "                                   \"typeVoieEtablissement\",\n",
    "                                   \"libelleVoieEtablissement\",\n",
    "                                   \"complementAdresseEtablissement\",\n",
    "                                   \"codeCommuneEtablissement\",\n",
    "                                   \"libelleCommuneEtablissement\",\n",
    "                                   \"codePostalEtablissement\",\n",
    "                                   \"codeCedexEtablissement\",\n",
    "                                   \"libelleCedexEtablissement\",\n",
    "                                   \"distributionSpecialeEtablissement\",\n",
    "                                   \"libelleCommuneEtrangerEtablissement\",\n",
    "                                   \"codePaysEtrangerEtablissement\",\n",
    "                                   \"libellePaysEtrangerEtablissement\",\n",
    "                                   \"dateCreationEtablissement\"\n",
    "                                   ],\n",
    "                          dtype={'siren': 'object',\n",
    "                                 'siret': 'object',\n",
    "                                 \"numeroVoieEtablissement\":'object',\n",
    "                                   \"indiceRepetitionEtablissement\":'object',\n",
    "                                   \"typeVoieEtablissement\":'object',\n",
    "                                   \"libelleVoieEtablissement\":'object',\n",
    "                                   \"complementAdresseEtablissement\":'object',\n",
    "                                   \"codeCommuneEtablissement\":'object',\n",
    "                                   \"libelleCommuneEtablissement\":'object',\n",
    "                                   \"codePostalEtablissement\":'object',\n",
    "                                   \"codeCedexEtablissement\":'object',\n",
    "                                   \"libelleCedexEtablissement\":'object',\n",
    "                                   \"distributionSpecialeEtablissement\":'object',\n",
    "                                   \"libelleCommuneEtrangerEtablissement\":'object',\n",
    "                                   \"codePaysEtrangerEtablissement\":'object',\n",
    "                                   \"libellePaysEtrangerEtablissement\":'object'\n",
    "                                 }\n",
    "                          )\n",
    "\n",
    "data_ets_ = (dd.read_csv(ets,\n",
    "                         usecols=[\n",
    "                             'Type',\n",
    "                             'Siren',\n",
    "                             'Code_Postal',\n",
    "                             'Code_Commune',\n",
    "                             'Adresse_Ligne1',\n",
    "                             'Adresse_Ligne2',\n",
    "                             'Adresse_Ligne3',\n",
    "                             'Ville',\n",
    "                             'Pays'\n",
    "                         ],\n",
    "                         dtype={\n",
    "                             'Type': 'object',\n",
    "                             'Siren': 'object',\n",
    "                             'Code_Postal': 'object',\n",
    "                             'Code_Commune': 'object',\n",
    "                             'Adresse_Ligne1': 'object',\n",
    "                             'Adresse_Ligne2': 'object',\n",
    "                             'Adresse_Ligne3': 'object',\n",
    "                             'Ville':'object',\n",
    "                             'Pays':'object'\n",
    "                         },\n",
    "                         compression='gzip',\n",
    "                         blocksize=None,\n",
    "                         low_memory=False\n",
    "                         )\n",
    "             .compute()\n",
    "             .rename(columns={\"Siren\": \"siren\"})\n",
    "             .loc[lambda x: ~x['Type'].isin(['SIE'])]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data_insee_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data_ets_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "siren_inpi = data_ets_['siren'].drop_duplicates()\n",
    "len(siren_inpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "len(siren_inpi)/data_ets_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_insee = (data_insee_\n",
    "                .loc[data_insee_['siren'].isin(siren_inpi.to_list())]\n",
    "                .loc[data_insee_['dateCreationEtablissement'] <= \"2018-01-01\"]\n",
    "                .assign(\n",
    "                libelleCommuneEtablissement = lambda x:\n",
    "                    x['libelleCommuneEtablissement'].str.replace('-', ' ')\n",
    "                )\n",
    "                .compute()\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Siren INPI mais pas INSEE -> Cette entreprise a exercé son droit d'opposition auprès de l'INSEE. Ses données ne peuvent pas être diffusées publiquement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "temp insee - > gagner du temps pendant la periode de dév\n",
    "temp inpi - > gagner du temps pendant la periode de dév"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "siren_to_remove = siren_inpi.loc[lambda x : ~x.isin(subset_insee['siren'])]\n",
    "len(siren_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_siren_to_find = data_ets_.loc[lambda x:\n",
    "                                 (~x['siren'].isin(siren_to_remove))    \n",
    "                                 ]\n",
    "len(df_siren_to_find)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_siren_to_find.to_csv('temp_inpi.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Nan variables matching \n",
    "\n",
    "on exclue les variables avec que des nan dans les variables candidates\n",
    "\n",
    "-> on les traitera après"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "siren_fullna = df_siren_to_find.loc[lambda x:\n",
    "                      (x['Adresse_Ligne1'].isin([np.nan]))\n",
    "                     & (x['Adresse_Ligne2'].isin([np.nan]))\n",
    "                     & (x['Adresse_Ligne3'].isin([np.nan]))\n",
    "                     & (x['Code_Postal'].isin([np.nan]))\n",
    "                     & (x['Ville'].isin([np.nan]))\n",
    "                     & (x['Code_Commune'].isin([np.nan]))\n",
    "                     ]['siren']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_siren_to_find = df_siren_to_find.loc[lambda x:\n",
    "                                 (~x['siren'].isin(siren_fullna))\n",
    "                                 ]\n",
    "len(siren_fullna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Nombres d'ets par SIREN INSEE\n",
    "\n",
    "On calcule le nombre d'etb pour le fichier INSEE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_insee_count = subset_insee.merge(\n",
    "    (subset_insee\n",
    "     .groupby('siren')['siren']\n",
    "     .count()\n",
    "     .rename('count')\n",
    "     .reset_index())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_siren_to_find = df_siren_to_find.merge(\n",
    "    (df_siren_to_find\n",
    "     .groupby('siren')['siren']\n",
    "     .count()\n",
    "     .rename('count')\n",
    "     .reset_index()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_siren_to_find.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Insee enlever les tirets dans la ville"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def siren_unique(df):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    print(\"Nombre total obs: {}\".format(len(df)))\n",
    "    count_ = (df\n",
    "              .groupby('siren')['siren']\n",
    "              .count()\n",
    "              .rename('count')\n",
    "              .reset_index()\n",
    "              .groupby('count')['count']\n",
    "              .count()\n",
    "              .reset_index(name='total_count')\n",
    "              .set_index('count')\n",
    "              # .compute()\n",
    "              .assign(pct=lambda x: x/x.sum())\n",
    "              .iloc[:10, :]\n",
    "              .style\n",
    "              .format('{:,.2%}', subset=['pct'])\n",
    "              )\n",
    "    return count_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Quick stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "siren_unique(df = subset_insee_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "siren_unique(df = df_siren_to_find)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 0: Clean ville\n",
    "\n",
    "Ajout matching des communes pour retrouver le libelé commune de l'INSEE\n",
    "\n",
    "ATTENTION, il faut nétoyer la variables ville dans l'INSEE. Veuillez regarder le fichier `communes.xlsx` pour voir les différents problèmes\n",
    "\n",
    "ex: \n",
    "- CEDEX, cedex, digit, (d+), \n",
    "\n",
    "attention, l'arrondissement peut être mis entre parenthèse \n",
    "\n",
    "- MARSEILLE (7E)\n",
    "\n",
    "- process:\n",
    "    - creer variables avec numeric seulement\n",
    "    - recreer ville 2 si test pas NAN pour avoir l'arrondissement\n",
    "    - virer les differentes informations dans ville via regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "regex = 'CEDEX|cedex|Cedex|\\([^)]*\\)|/\\s\\s+/|^\\d+\\s|\\s\\d+\\s|\\s\\d+$|\\d+|\\.|\\--|COMMUNE DE |COMMUNE DE|commune de |commune de|Commune de |Commune de |\\s$'\n",
    "test_adress = df_siren_to_find.copy()\n",
    "test_adress['test'] =test_adress['Ville'].str.extract(r'(\\d+)')\n",
    "test_adress['Ville_clean'] = test_adress['Ville'].str.replace(regex,'')\n",
    "test_adress['Ville_clean'] = test_adress['Ville_clean'].str.replace('\\s$|\\s^','')\n",
    "test_adress['ville2'] = np.where(\n",
    "    np.logical_and(\n",
    "         ~test_adress['test'].isin([np.nan]),\n",
    "        test_adress['test'].str.len() <=2\n",
    "    )\n",
    "   ,\n",
    "    test_adress['Ville_clean'] + '' + test_adress['test'].astype(str),\n",
    "    test_adress['Ville_clean']\n",
    ")\n",
    "\n",
    "test_adress = test_adress.merge(communes,\n",
    "                         left_on='ville2',\n",
    "                         right_on='possibilite',\n",
    "                         how='left',\n",
    "                         indicator=True)\n",
    "\n",
    "test_adress = pd.concat([\n",
    "    test_adress.loc[lambda x: x['_merge'].isin(['both'])],\n",
    "    (test_adress\n",
    "     .loc[lambda x: x['_merge'].isin(['left_only'])]\n",
    "     .drop(columns=['ncc', 'possibilite', '_merge'])\n",
    "     .merge(communes,\n",
    "            left_on='Ville_clean',\n",
    "            right_on='possibilite',\n",
    "            how='left',\n",
    "            indicator=True)\n",
    "     )\n",
    "\n",
    "])\n",
    "\n",
    "test_adress = pd.concat([\n",
    "    test_adress.loc[lambda x: x['_merge'].isin(['both'])],\n",
    "    (test_adress\n",
    "     .loc[lambda x: x['_merge'].isin(['left_only'])]\n",
    "     .drop(columns=['ncc', 'possibilite', '_merge'])\n",
    "     .assign(\n",
    "         noaccent=lambda x: x['Ville_clean'].str.normalize('NFKD')\n",
    "         .str.encode('ascii', errors='ignore')\n",
    "         .str.decode('utf-8'))\n",
    "     ).merge(communes,\n",
    "             left_on='noaccent',\n",
    "             right_on='possibilite',\n",
    "             how='left',\n",
    "             indicator=True)])\n",
    "test_adress.groupby('_merge')[\"_merge\"].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress = test_adress.drop(columns = '_merge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": false
   },
   "source": [
    "## Process\n",
    "\n",
    "On ne match que les SIREN dont la date de création est inférieur a 2018\n",
    "\n",
    "1) ~Step : Calculer le nombre de `nan` dans les colonnes de matching~\n",
    "\n",
    "2) ~Step : Compter le nombre de SIRET by SIREN~\n",
    "\n",
    "2) Step 2:  merge sur siren et code postal\n",
    "\n",
    "3) Step 3:  merge sur siren et code commune\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Step 1: Match uniquement les 1 dans INSEE/INPI\n",
    "\n",
    "On enlève les matches du dataframe `df_siren_to_find` et on ajoute les `left_only`.\n",
    "\n",
    "Pareil pour l'INSEE pour gagner en mémoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "m1_unique = (\n",
    "    subset_insee_count.loc[lambda x: x['count'].isin([1])]\n",
    " .merge(test_adress.loc[lambda x: x['count'].isin([1])],\n",
    "         how='left',indicator=True)\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "m1_unique.groupby('_merge')[\"_merge\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "to_remove_ = m1_unique.loc[lambda x: x['_merge'].isin(['both'])]['siren'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress = test_adress.loc[lambda x: ~x['siren'].isin(to_remove_)]\n",
    "#subset_insee_count = subset_insee_count.loc[lambda x: ~x['siren'].isin(to_remove_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "siren_unique(df = test_adress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "siren_unique(df = subset_insee_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Exemple de SIREN qui ont seulement une ligne dans l'INPI mais plusieurs SIRET dans l'INSEE.\n",
    "\n",
    "- 813543063\n",
    "- 800897092"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress.loc[lambda x: x['count'] ==1].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_insee_count.loc[lambda x: x['siren'].isin(['813543063'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_insee_count.loc[lambda x: x['siren'].isin(['800897092'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_insee_count.isna().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress.isna().sum().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Step 2: Merging \n",
    "\n",
    "Dans cette partie, on va merger sur plusieurs candidats. La plupart des SIREN peuvent être matché via le code postal, code commune, ou ville directement. Si un SIREN a plusieurs SIRET dans la même ville ou code postal, il fera l'objet d'une recherche plus poussée.\n",
    "\n",
    "Trois cas de figure découle du merge:\n",
    "\n",
    "- 1) Merge forte pertinence\n",
    "- 2) merge pertinence moyenne -> plusieurs SIRET pour un même candidat\n",
    "- 3) Unmerge\n",
    "\n",
    "#### 1:  merge sur siren et Ville\n",
    "\n",
    "- Merge sur siren & libelleCommuneEtablissement|Ville_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def merge(df_insee, df_inpi, left_on, right_on):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # match\n",
    "    data_merged_1 = (df_insee\n",
    "                     .merge(\n",
    "                         df_inpi,\n",
    "                         how='right',\n",
    "                         left_on=left_on,\n",
    "                         right_on=right_on,\n",
    "                         indicator=True,\n",
    "                         suffixes=['_insee', '_inpi'])\n",
    "                     )\n",
    "\n",
    "    # count\n",
    "    count_ = (data_merged_1\n",
    "              .loc[lambda x: x['_merge'].isin(['both'])]\n",
    "              .groupby(['siren', 'ncc'])['siren']\n",
    "              .count()\n",
    "              .rename('count')\n",
    "              .reset_index()\n",
    "              .groupby('count')['count']\n",
    "              .count()\n",
    "              .reset_index(name='total_count')\n",
    "              .set_index('count')\n",
    "              .assign(pct=lambda x: x/x.sum())\n",
    "              .iloc[:10, :]\n",
    "              .style\n",
    "              .format('{:,.2%}', subset=['pct'])\n",
    "              )\n",
    "\n",
    "    # detail match\n",
    "    detail = data_merged_1.groupby('_merge')[\"_merge\"].count()\n",
    "\n",
    "    # cas de figure 2\n",
    "    siren_fig2 = (data_merged_1\n",
    "                  .loc[lambda x: x['_merge'].isin(['both'])]\n",
    "                  .groupby(['siren', 'ncc'])['siren']\n",
    "                  .count()\n",
    "                  .rename('count')\n",
    "                  .loc[lambda x:x > 1]\n",
    "                  .reset_index('ncc')\n",
    "                  .index\n",
    "                  )\n",
    "\n",
    "    # non matche\n",
    "    siren_nmatched = (data_merged_1\n",
    "                      .loc[lambda x: x['_merge'].isin(['right_only'])]['siren']\n",
    "                      .to_list()\n",
    "                      )\n",
    "    new_unmatch = df_inpi.loc[lambda x: x['siren'].isin(siren_nmatched)]\n",
    "\n",
    "    dic_ = {\n",
    "\n",
    "        'count_': count_,\n",
    "        'detail': detail,\n",
    "        'siren_fig': siren_fig2,\n",
    "        'size_fig2': len(siren_fig2),\n",
    "        'new_unmatch': new_unmatch,\n",
    "    }\n",
    "\n",
    "    return dic_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_city = merge(df_insee =subset_insee_count,\n",
    "      df_inpi =test_adress,\n",
    "      left_on=['siren', 'libelleCommuneEtablissement'],\n",
    "      right_on=['siren', 'ncc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_city['detail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_city['size_fig2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_city['count_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_city['new_unmatch'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Exemple de cas de figure 2: merge pertinence moyenne -> plusieurs SIRET pour un même candidat:\n",
    "\n",
    "- 200000560"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_insee_count.loc[lambda x: x['siren'].isin(['200000560'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress.loc[lambda x: x['siren'].isin(['200000560'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "siren_unique(df = test_city['new_unmatch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### 2:  merge sur siren et code postal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_cp = merge(df_insee =subset_insee_count,\n",
    "      df_inpi = test_city['new_unmatch'],\n",
    "      left_on= ['siren', 'codePostalEtablissement'],\n",
    "      right_on= ['siren', 'Code_Postal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_cp['detail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_cp['size_fig2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_cp['count_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "siren_unique(df = test_cp['new_unmatch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 3:  merge sur siren et code commune\n",
    "\n",
    "- Merge sur siren & codeCommuneEtablissement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_com = merge(df_insee =subset_insee_count,\n",
    "      df_inpi = test_cp['new_unmatch'],\n",
    "      left_on= ['siren', 'codeCommuneEtablissement'],\n",
    "      right_on= ['siren', 'Code_Commune'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_com['detail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_com['size_fig2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_com['count_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "siren_unique(df = test_com['new_unmatch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## A Verifier\n",
    "\n",
    "Il reste a véfifier les cas de figure 2 et les unmatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "### Total a matcher avant ville/code postal/commune\n",
    "test_adress.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "### total cas de figure 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_city['size_fig2'] + test_cp['size_fig2']+ test_com['size_fig2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "### total unmatch \n",
    "test_com['new_unmatch'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "### nombres totals SIREN a matcher\n",
    "\n",
    "test_city['size_fig2'] + test_cp['size_fig2']+ test_com['size_fig2'] + test_com['new_unmatch'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Verification le nombre a matcher correspond bien a 2M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    [\n",
    "        df_siren_to_find.loc[lambda x: x['siren'].isin(test_city['siren_fig'])],\n",
    "        df_siren_to_find.loc[lambda x: x['siren'].isin(test_cp['siren_fig'])],\n",
    "        df_siren_to_find.loc[lambda x: x['siren'].isin(test_com['siren_fig'])],\n",
    "        test_com['new_unmatch'] \n",
    "    ]\n",
    "\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_city['size_fig2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_city['size_fig2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "(866618 / df_siren_to_find.shape[0]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "### Match avec ville/code postal/commune\n",
    "test_adress.shape[0] - test_city['size_fig2'] + test_cp['size_fig2'] + \\\n",
    "test_com['size_fig2'] - test_com['new_unmatch'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress.loc[lambda x : x['siren'].isin(['200000560'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_insee_count.loc[lambda x : x['siren'].isin(['200000560'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Match avec adresse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "On selectionne uniquement ceux pas matché.\n",
    "Pour accélerer la recherche, on utilise que le sous ensemble de siren a vérifier dans le fichier INSEE\n",
    "\n",
    "Verifier si on peut matcher avec le numéro de l'adresse -> au cas ou principal et secondaire dans le même endroit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Il faut retravailler les adresses:\n",
    "\n",
    "- Upper case\n",
    "\n",
    "La recherche se fait sur le libellé adresse. Dans l'INSEE, pas de numéro de voie, ni de typologie (rue, avenue, etc)\n",
    "\n",
    "ALL: Allée\n",
    "AV: Avenue\n",
    "BD: Boulevard\n",
    "CAR: Carrefour\n",
    "CHE: Chemin\n",
    "CHS: Chaussée\n",
    "CITE: Cité\n",
    "COR: Corniche\n",
    "CRS: Cours\n",
    "DOM: Domaine\n",
    "DSC: Descente\n",
    "ECA: Ecart\n",
    "ESP: Esplanade\n",
    "FG: Faubourg\n",
    "GR: Grande Rue\n",
    "HAM: Hameau\n",
    "HLE: Halle\n",
    "IMP: Impasse\n",
    "LD: Lieu dit\n",
    "LOT: Lotissement\n",
    "MAR: Marché\n",
    "MTE: Montée\n",
    "PAS: Passage\n",
    "PL: Place\n",
    "PLN: Plaine\n",
    "PLT: Plateau\n",
    "PRO: Promenade\n",
    "PRV: Parvis\n",
    "QUA: Quartier\n",
    "QUAI: Quai\n",
    "RES: Résidence\n",
    "RLE: Ruelle\n",
    "ROC: Rocade\n",
    "RPT: Rond Point\n",
    "RTE: Route\n",
    "RUE: Rue\n",
    "SEN: Sente - Sentier\n",
    "SQ: Square\n",
    "TPL: Terre-plein\n",
    "TRA: Traverse\n",
    "VLA: Villa\n",
    "VLGE: Village"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "additional = [\"Avenue\",\n",
    "\"Boulevard\",\n",
    "\"Carrefour\",\n",
    "\"Chemin\",\n",
    "\"Chaussee\",\n",
    "\"Cite\",\n",
    "\"Corniche\",\n",
    "\"Cours\",\n",
    "\"Domaine\",\n",
    "\"Descente\",\n",
    "\"Ecart\",\n",
    "\"Esplanade\",\n",
    "\"Faubourg\",\n",
    "\"Grande Rue\",\n",
    "\"Hameau\",\n",
    "\"Halle\",\n",
    "\"Impasse\",\n",
    "\"Lieu dit\",\n",
    "\"Lotissement\",\n",
    "\"Marche\",\n",
    "\"Montee\",\n",
    "\"Passage\",\n",
    "\"Place\",\n",
    "\"Plaine\",\n",
    "\"Plateau\",\n",
    "\"Promenade\",\n",
    "\"Parvis\",\n",
    "\"Quartier\",\n",
    "\"Quai\",\n",
    "\"Residence\",\n",
    "\"Ruelle\",\n",
    "\"Rocade\",\n",
    "\"Rond Point\",\n",
    "\"Route\",\n",
    "\"Rue\",\n",
    "\"Sentier\",\n",
    "\"Square\",\n",
    "\"Terre plein\",\n",
    "\"Traverse\",\n",
    "\"Villa\",\n",
    "\"Village\"\n",
    "'bp', 'cedex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('french')\n",
    "stop_words.extend(additional)\n",
    "upper_stop = [i.upper() for i in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def create_split_adress(x):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    split_ = x.str.split().to_list()\n",
    "    \n",
    "    #split_ = ''.join(str(e) for e in split_)\n",
    "    #reg = '|'.join(split_)\n",
    "    return  split_\n",
    "\n",
    "\n",
    "def create_regex_adress(x):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        split_ = [i + \"$\" for i in x]\n",
    "        reg = '|'.join(split_)\n",
    "    except:\n",
    "        reg = np.nan\n",
    "    return  reg\n",
    "\n",
    "import re\n",
    "\n",
    "def find_regex(regex, test_str, siret):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        matches = re.search(regex, test_str)\n",
    "        if matches:\n",
    "            return siret\n",
    "        else:\n",
    "            return np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def prepare_adress(df):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    #temp_adresse = m3['unmerged'].loc[lambda x: ~\n",
    "    #                                  x['siren'].isin(siren_count_1_found)].copy()\n",
    "    #sous_ensemble_insee = subset_insee_count.loc[lambda x: x['siren'].isin(\n",
    "    #    temp_adresse['siren'].to_list())]\n",
    "\n",
    "    temp_adresse = df.assign(\n",
    "        Adresse_Ligne1_clean=lambda x: x['Adresse_Ligne1'].str.normalize(\n",
    "            'NFKD')\n",
    "        .str.encode('ascii', errors='ignore')\n",
    "        .str.decode('utf-8')\n",
    "        .str.replace('[^\\w\\s]|\\d+', '')\n",
    "        .str.upper(),\n",
    "        Adresse_Ligne2_clean=lambda x: x['Adresse_Ligne2'].str.normalize(\n",
    "            'NFKD')\n",
    "        .str.encode('ascii', errors='ignore')\n",
    "        .str.decode('utf-8')\n",
    "        .str.replace('[^\\w\\s]|\\d+', '')\n",
    "        .str.upper(),\n",
    "        Adresse_Ligne3_clean=lambda x: x['Adresse_Ligne3'].str.normalize(\n",
    "            'NFKD')\n",
    "        .str.encode('ascii', errors='ignore')\n",
    "        .str.decode('utf-8')\n",
    "        .str.replace('[^\\w\\s]|\\d+', '')\n",
    "        .str.upper()\n",
    "    )\n",
    "    temp_adresse['Adresse_Ligne1_clean'] = (temp_adresse['Adresse_Ligne1_clean']\n",
    "                                            .apply(lambda x:\n",
    "                                                   ' '.join([word for word in\n",
    "                                                             str(x).split() if\n",
    "                                                             word not in \n",
    "                                                             (upper_stop)]))\n",
    "                                            )\n",
    "\n",
    "    temp_adresse['Adresse_Ligne2_clean'] = (temp_adresse['Adresse_Ligne2_clean']\n",
    "                                            .apply(lambda x:\n",
    "                                                   ' '.join([word for word in\n",
    "                                                             str(x).split() if\n",
    "                                                             word not in \n",
    "                                                             (upper_stop)]))\n",
    "                                           )\n",
    "                                            \n",
    "\n",
    "    temp_adresse['Adresse_Ligne3_clean'] = (temp_adresse['Adresse_Ligne3_clean']\n",
    "                                            .apply(lambda x:\n",
    "                                                   ' '.join([word for word in\n",
    "                                                             str(x).split() if\n",
    "                                                             word not in \n",
    "                                                             (upper_stop)]))\n",
    "                                           )\n",
    "                                            \n",
    "\n",
    "    temp_adresse = temp_adresse.assign(\n",
    "        Adresse_Ligne1_clean_split=lambda x:\n",
    "        create_split_adress(x['Adresse_Ligne1_clean']),\n",
    "        Adresse_Ligne2_clean_split=lambda x:\n",
    "        create_split_adress(x['Adresse_Ligne2_clean']),\n",
    "        Adresse_Ligne3_clean_split=lambda x:\n",
    "        create_split_adress(x['Adresse_Ligne3_clean'])\n",
    "    )\n",
    "\n",
    "    temp_adresse['Adresse_Ligne1_clean_reg'] = temp_adresse['Adresse_Ligne1_clean_split'].apply(lambda x:\n",
    "                                                                                                create_regex_adress(x))\n",
    "    temp_adresse['Adresse_Ligne2_clean_reg'] = temp_adresse['Adresse_Ligne2_clean_split'].apply(lambda x:\n",
    "                                                                                                create_regex_adress(x))\n",
    "    temp_adresse['Adresse_Ligne3_clean_reg'] = temp_adresse['Adresse_Ligne3_clean_split'].apply(lambda x:\n",
    "                                                                                                create_regex_adress(x))\n",
    "\n",
    "    return temp_adresse\n",
    "\n",
    "#def lookupInseeInpi(df_insee, siren, regex_):\n",
    "#    \"\"\"\n",
    "#    \"\"\"\n",
    "#    try:\n",
    "#        siret_ = df_insee.loc[lambda x: \n",
    "#                                  x['siren'].isin([siren])\n",
    "#                      & x['libelleVoieEtablissement'].str.contains(\n",
    "#                          regex_, \n",
    "#                          case = False, \n",
    "#                          regex = True)\n",
    "#                      ]['siret']\n",
    "#        return siret_.values[0]\n",
    "#    except:\n",
    "#        return np.nan "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Test sur `test_city`\n",
    "\n",
    "On fait le test seulement sur le sous ensemble `test_city`. Cela évite d'avoir un immense dataframe avec le merge de l'insee\n",
    "\n",
    "On peut faire le matching sur:\n",
    "\n",
    "- Adresse_Ligne1_clean_reg\n",
    "- Adresse_Ligne2_clean_reg\n",
    "- Adresse_Ligne3_clean_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#test1 = prepare_adress(\n",
    "#    df_siren_to_find.loc[lambda x: x['siren'].isin(test_city['siren_fig'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar\n",
    "from dask.multiprocessing import get\n",
    "import re\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pbar = ProgressBar()\n",
    "pbar.register()\n",
    "\n",
    "# load data into dataframes\n",
    "subset_insee_count = pd.read_csv('subset_insee_count.csv',\n",
    "                          usecols=['siren',\n",
    "            'siret',\n",
    "            'libelleCommuneEtablissement',\n",
    "            'libelleVoieEtablissement',\n",
    "            'numeroVoieEtablissement'\n",
    "                                   ],\n",
    "                          dtype={'siren': 'object',\n",
    "                                 'siret': 'object',\n",
    "                                 \"libelleCommuneEtablissement\":'object',\n",
    "                                   \"libelleVoieEtablissement\":'object',\n",
    "                                   \"numeroVoieEtablissement\":'object'\n",
    "                                 }\n",
    "                          )\n",
    "\n",
    "\n",
    "\n",
    "def find_regex(regex, test_str, siret):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        matches = re.search(regex, test_str)\n",
    "        if matches:\n",
    "            return siret\n",
    "        else:\n",
    "            return np.nan\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test1 = (pd.read_csv('test_city.csv',\n",
    "                         usecols=[\n",
    "                             'siren', 'Type', 'Code_Postal', 'Ville',\n",
    "                     'Adresse_Ligne1_clean_reg'\n",
    "                         ],\n",
    "                         dtype={\n",
    "                             'siren': 'object',\n",
    "                             'Type': 'object',\n",
    "                             'Code_Postal': 'object',\n",
    "                             'Ville': 'object',\n",
    "                             'Adresse_Ligne1_clean_reg': 'object',\n",
    "                         },\n",
    "                         chunksize=250000,\n",
    "                         #low_memory=False\n",
    "                         )\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### test_1: `Adresse_Ligne1_clean_reg`\n",
    "\n",
    "Pour accelerer le code, on utilise uniquement les adresses sans les na et on filtre l'insee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#test_inpi_1 = test1.loc[lambda x: ~x['Adresse_Ligne1_clean_reg'].isin(['nan$'])]\n",
    "#test_inpi_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#test_insee= (subset_insee_count\n",
    "#             .loc[lambda x: x['siren'].isin([test_inpi_1['siren']])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#subset_insee_count.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "POur acceleter le calcul, on convertit la df en Dask et on fait un map partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "len(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for chunk in tqdm(pd.read_csv('test_city.csv',\n",
    "                         usecols=[\n",
    "                             'siren', 'Type', 'Code_Postal', 'Ville',\n",
    "                     'Adresse_Ligne1_clean_reg'\n",
    "                         ],\n",
    "                         dtype={\n",
    "                             'siren': 'object',\n",
    "                             'Type': 'object',\n",
    "                             'Code_Postal': 'object',\n",
    "                             'Ville': 'object',\n",
    "                             'Adresse_Ligne1_clean_reg': 'object',\n",
    "                         },\n",
    "                         chunksize=1000000,\n",
    "                         #low_memory=False\n",
    "                         )):\n",
    "    print('merge')\n",
    "    temp = (chunk.loc[~chunk['Adresse_Ligne1_clean_reg'].isin(['nan$'])]\n",
    "        .merge(\n",
    "        subset_insee_count,\n",
    "        on='siren')\n",
    "        )\n",
    "    print('apply')\n",
    "    if not temp.empty:\n",
    "        temp['siret_test1'] = (temp.apply(lambda x:\n",
    "                 find_regex(\n",
    "                     x['Adresse_Ligne1_clean_reg'],\n",
    "                     x['libelleVoieEtablissement'],\n",
    "                     x['siret']), axis=1)\n",
    "    \n",
    "    )\n",
    "        temp = temp.loc[lambda x: ~x['siret_test1'].isin([np.nan])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "chunk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_insee_count.loc[lambda x: x['siren'].isin(['712980432'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#test_insee = dd.from_pandas(\n",
    "#    subset_insee_count[[\n",
    "#            'siren',\n",
    "#            'siret',\n",
    "#            'libelleCommuneEtablissement',\n",
    "#            'libelleVoieEtablissement',\n",
    "#            'numeroVoieEtablissement']],\n",
    "#    npartitions=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "temp = (test1.loc[~test1['Adresse_Ligne1_clean_reg'].isin(['nan$'])]\n",
    "        .merge(\n",
    "        subset_insee_count,\n",
    "        on='siren')\n",
    "        )\n",
    "\n",
    "temp['siret_test1'] = temp.map_partitions(\n",
    "        lambda df:\n",
    "        df.apply(lambda x:\n",
    "                 find_regex(\n",
    "                     x['Adresse_Ligne1_clean_reg'],\n",
    "                     x['libelleVoieEtablissement'],\n",
    "                     x['siret']), axis=1)\n",
    "    .dropna()\n",
    "    ).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def merge_adresse(df_insee, df_inpi):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    temp = (df_inpi\n",
    "            .merge(\n",
    "        df_insee,\n",
    "        on='siren')\n",
    "    )\n",
    "\n",
    "    ddata['siret_test1'] = ddata.map_partitions(\n",
    "        lambda df:\n",
    "        df.apply(lambda x:\n",
    "                 find_regex(\n",
    "                     x['Adresse_Ligne1_clean_reg'],\n",
    "                     x['libelleVoieEtablissement'],\n",
    "                     x['siret']), axis=1)\n",
    "    ).compute(scheduler='threads')\n",
    "    # cas de figure 2\n",
    "    fig2 = (ddata\n",
    "            .compute()\n",
    "            .loc[lambda x: ~x['siret_test1'].isin([np.nan])]\n",
    "            .groupby(['siren', 'libelleVoieEtablissement'])['siren']\n",
    "            .count()\n",
    "            .rename('count')\n",
    "            .loc[lambda x:x > 1]\n",
    "            .reset_index('libelleVoieEtablissement')\n",
    "            .index\n",
    "            )\n",
    "\n",
    "    # Unmatched\n",
    "    list_unmatch = (ddata\n",
    "                    .compute()\n",
    "                    .loc[lambda x: x['siret_test1'].isin([np.nan])]['siren']\n",
    "                    .drop_duplicates())\n",
    "\n",
    "    # df match\n",
    "\n",
    "    df_match = (ddata\n",
    "                .compute()\n",
    "                .loc[lambda x: ~x['siret_test1'].isin([np.nan])]\n",
    "                .drop(columns=['siret_test1'])\n",
    "                )\n",
    "    \n",
    "    ### perc matched\n",
    "    pct_match = df_match.shape[0]/len(ddata)\n",
    "\n",
    "    dic_ = {\n",
    "\n",
    "        'count_': df_match.shape[0],\n",
    "        'detail': pct_match,\n",
    "        'siren_fig': fig2,\n",
    "        'size_fig2': len(fig2),\n",
    "        'new_unmatch': list_unmatch,\n",
    "    }\n",
    "    \n",
    "    return dic_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test_adresse1=  merge_adresse(df_insee= subset_insee_count,\n",
    "              df_inpi= test_inpi_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adresse1['size_fig2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ddata = dd.from_pandas(temp.head(1000), npartitions=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ddata.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "\n",
    "ddata['siret_test1'] = ddata.map_partitions(lambda df:\n",
    "                     df.apply(lambda x:\n",
    "                              find_regex(\n",
    "                                  x['Adresse_Ligne1_clean_reg'],\n",
    "                                  x['libelleVoieEtablissement'],\n",
    "                                  x['siret']), axis=1)\n",
    "                            ).compute(scheduler='threads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "(ddata\n",
    " .compute()\n",
    " .loc[lambda x: ~x['siret_test1'].isin([np.nan])]\n",
    " .drop(columns = ['siret_test1'])\n",
    ").shape[0]/len(ddata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "len(ddata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Subset les SIREN avec la même adresses pour faire une vérification plus poussée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "(ddata\n",
    " .compute()\n",
    " .loc[lambda x: ~x['siret_test1'].isin([np.nan])]\n",
    " .groupby(['siren', 'libelleVoieEtablissement'])['siren']\n",
    " .count()\n",
    " .rename('count')\n",
    " .loc[lambda x:x > 1]\n",
    " .reset_index('libelleVoieEtablissement')\n",
    " .index )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "((300504 * 0.620) /1000)/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test_2 = temp_adresse.loc[lambda x: ~x['test_2'].isin(['nan'])]\n",
    "test_2['siret_2'] = test_1.apply(lambda x: lookupInseeInpi(\n",
    "    siren = x['siren'],\n",
    "    regex_ = x['test_2']),\n",
    "    axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_2['siret_2'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_2.loc[lambda x : ~x['siret_2'].isin([np.nan])].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_2.loc[lambda x : ~x['siret_2'].isin([np.nan])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "(sous_ensemble_insee\n",
    " .loc[lambda x: x['siren'].isin([\"394674881\"])]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "#### test_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test_3 = temp_adresse.loc[lambda x: ~x['test_3'].isin(['nan'])]\n",
    "test_3['siret_3'] = test_1.apply(lambda x: lookupInseeInpi(\n",
    "    siren = x['siren'],\n",
    "    regex_ = x['test_3']),\n",
    "    axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_3.loc[lambda x : ~x['siret_3'].isin([np.nan])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_3.loc[lambda x : ~x['siret_3'].isin([np.nan])].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "(sous_ensemble_insee\n",
    " .loc[lambda x: x['siren'].isin([\"302556832\"])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "lookupInseeInpi(siren = '302556832',\n",
    "                regex_ = '^AVE$|^MICHEL$|^JOURDAN$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "temp1.head("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove('communes.xlsx')\n",
    "temp1.loc[lambda x: x['_merge'].isin(['left_only'])].drop_duplicates('ville2').to_excel('communes.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "temp.assign(url = lambda x :\n",
    "            'https://data.inpi.fr/entreprises/' + x[\"Siren\"] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
