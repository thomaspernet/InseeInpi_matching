{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Programme de Matching\n",
    "\n",
    "Regarder si l'établissement est fermé ou pas\n",
    "\n",
    "## Moteur de recherche TEST\n",
    "\n",
    "* Insee\n",
    "  * http://avis-situation-sirene.insee.fr/IdentificationListeSiret.action\n",
    "* INPI/TC\n",
    "  * https://data.inpi.fr/\n",
    "* Infogreffe\n",
    "  * https://www.infogreffe.fr/\n",
    "\n",
    "## Preparation fichier\n",
    "\n",
    "### Variable Ville\n",
    "\n",
    "- process:\n",
    "    - creer variables avec numeric seulement\n",
    "    - recreer ville 2 si test pas NAN pour avoir l'arrondissement\n",
    "    - virer les differentes informations dans ville via regex\n",
    "    \n",
    "### Step 1: Match uniquement les 1 dans INSEE/INPI\n",
    "\n",
    "Les siren qui ont uniquement un seul établissement a l'INSEE et à l'INPI.\n",
    "\n",
    "### Step 2: match Ville/CP/CC\n",
    "\n",
    "### Step 3: Match adresse\n",
    "\n",
    "## Description Algorithm\n",
    "\n",
    "## Description Input\n",
    "\n",
    "## Description Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PERNETTH\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "from inpi_insee import siretisation\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "    'insee': r'data\\input\\insee_2017_7627977.gz',\n",
    "    'inpi_etb': r'data\\input\\inpi_etb_stock_7552898.gz',\n",
    "}\n",
    "# 4824158 SIREN a trouver!\n",
    "al_siret = siretisation.siretisation_inpi(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from itertools import compress, product\n",
    "\n",
    "def combinations(items):\n",
    "    return ( set(compress(items,mask)) for \n",
    "            mask in product(*[[0,1]]*len(items)))\n",
    "\n",
    "all_list = ['ncc', 'Code_Postal', 'Code_Commune']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Match 1-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Merge ville/code postale/ code commune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inpi_col = ['siren',\n",
    "            'index',\n",
    "            'Type',\n",
    "            'Code_Postal',\n",
    "            'Ville',\n",
    "            'Code_Commune',\n",
    "            'Pays',\n",
    "            'count_initial_inpi',\n",
    "            'ncc',\n",
    "            'Adresse_new_clean_reg',\n",
    "           'INSEE',\n",
    "           'Date_Début_Activité',\n",
    "           'digit_inpi']\n",
    "\n",
    "inpi_dtype = {\n",
    "    'siren': 'object',\n",
    "    'index': 'int',\n",
    "    'Type': 'object',\n",
    "    'Code_Postal': 'object',\n",
    "    'Ville': 'object',\n",
    "    'Code_Commune': 'object',\n",
    "    'Pays': 'object',\n",
    "    'count_initial_inpi': 'int',\n",
    "    'ncc': 'object',\n",
    "    'Adresse_new_clean_reg': 'object',\n",
    "    'INSEE':'object',\n",
    "    'Date_Début_Activité':'object',\n",
    "    'digit_inpi':'object'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "\n",
    "Variable INSEE -> etablissementSiege\n",
    "Variable INPI -> Type\n",
    "\n",
    "- PRI    3004262 -> False\n",
    "- SIE    2362691 -> True\n",
    "- SEP    1670220 -> True\n",
    "- SEC     515725 -> False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_ets = r'data\\input\\inpi_etb_stock_7552898.gz'\n",
    "inpi = al_siret.import_dask(file=df_ets,\n",
    "                            usecols=inpi_col,\n",
    "                            dtype=inpi_dtype,\n",
    "                            parse_dates = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  2min 11.7s\n"
     ]
    }
   ],
   "source": [
    "df_no_duplication, df_duplication = al_siret.create_test(\n",
    "    df_input=inpi,\n",
    "    left_on=['siren','ncc',\n",
    "             'Code_Postal','Code_Commune',\n",
    "             'INSEE','digit_inpi'],\n",
    "    right_on=['siren','libelleCommuneEtablissement',\n",
    "              'codePostalEtablissement', 'codeCommuneEtablissement',\n",
    "             'typeVoieEtablissement','numeroVoieEtablissement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "origin\n",
       "test_1_no_duplication    4312255\n",
       "test_2_no_duplication      24910\n",
       "test_3_no_duplication       3184\n",
       "Name: origin, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_duplication.groupby('origin')['origin'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "origin\n",
       "test_2_duplication    16580\n",
       "test_3_duplication    10732\n",
       "Name: origin, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_duplication.groupby('origin')['origin'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "On regarde le nombre de doublons -> meme variables de matching mais plusieurs possibilité a l'INSEE:\n",
    "\n",
    "- Plusieurs siret pour un meme endroit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Process temporaire -> on sauvegarde les fichiers avec indication des tests:\n",
    "\n",
    "- Après le merge full\n",
    "    - Test 1: doublon\n",
    "        - non: Save-> test1_nodup_{size}\n",
    "        - oui:\n",
    "            - Test 2: Date equal\n",
    "                - oui:\n",
    "                    - Test 2 bis: doublon\n",
    "                        - non: Save-> test2_nodup_{size}\n",
    "                        - oui: Save-> test2_dup_{size}\n",
    "                - non:\n",
    "                    - Test 3: Date sup\n",
    "                        - oui:\n",
    "                            - Test 2 bis: doublon\n",
    "                                - non: Save-> test3_nodup_{size}\n",
    "                                - oui: Save-> test3_dup_{size}\n",
    "                        - non: Save-> test3_specialtreat_{size}\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "## test\n",
    "doublou_sur['index'].nunique()\n",
    "doublou_passur['index'].nunique()\n",
    "doublon.shape[0] - ( doublou_sur.shape[0] + doublou_passur.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Test sur pas doublon\n",
    "\n",
    "On applique 5 tests sur les champs des possibles afin d'avoir une meilleure visibilité \n",
    "\n",
    "- Test 1: address libelle\n",
    "    - Si mots dans inpi est contenu dans INSEE, True\n",
    "- Test 1 bis: address complement\n",
    "    - Si mots dans inpi est contenu dans INSEE, True\n",
    "- Test 2: Date\n",
    "    - dateCreationEtablissement >= Date_Début_Activité OR Date_Début_Activité = NaN OR (nombre SIREN a l'INSEE = 1 AND nombre SIREN des variables de matching = 1), True\n",
    "- Test 3: siege\n",
    "    - Type = ['SEP', 'SIE'] AND siege = true, True\n",
    "- Test 4: voie\n",
    "    - Type voie INPI = Type voie INSEE, True\n",
    "- Test 5: numero voie\n",
    "    - Numero voie INPI = Numero voie INSEE, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4340349, 34)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_duplication.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  5min 30.3s\n",
      "[########################################] | 100% Completed |  5min 30.4s\n",
      "[########################################] | 100% Completed |  1.4s\n",
      "[########################################] | 100% Completed |  1.5s\n"
     ]
    }
   ],
   "source": [
    "pure_match = al_siret.assess_test(df = df_no_duplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pure_match.to_csv(r'data\\output\\pure_match_{}.gz'.format(pure_match.shape[0]),\n",
    "                  compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4340349\n",
       "Name: count_duplicates_final, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pure_match['count_duplicates_final'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  2.1s\n",
      "[########################################] | 100% Completed |  2.1s\n",
      "[########################################] | 100% Completed |  2.2s\n",
      "[########################################] | 100% Completed |  2.2s\n",
      "[########################################] | 100% Completed |  2.3s\n",
      "[########################################] | 100% Completed |  2.3s\n",
      "[########################################] | 100% Completed |  2.4s\n",
      "[########################################] | 100% Completed |  2.4s\n",
      "[########################################] | 100% Completed |  2.5s\n",
      "[########################################] | 100% Completed |  2.6s\n",
      "[########################################] | 100% Completed |  2.7s\n",
      "[########################################] | 100% Completed |  2.7s\n",
      "[########################################] | 100% Completed |  2.1s\n",
      "[########################################] | 100% Completed |  2.2s\n",
      "[########################################] | 100% Completed |  2.3s\n",
      "[########################################] | 100% Completed |  2.3s\n",
      "[########################################] | 100% Completed |  2.4s\n",
      "[########################################] | 100% Completed |  2.4s\n",
      "[########################################] | 100% Completed |  2.4s\n",
      "[########################################] | 100% Completed |  2.5s\n",
      "[########################################] | 100% Completed |  2.6s\n",
      "[########################################] | 100% Completed |  2.6s\n",
      "[########################################] | 100% Completed |  2.7s\n",
      "[########################################] | 100% Completed |  2.8s\n",
      "[########################################] | 100% Completed |  0.4s\n",
      "[########################################] | 100% Completed |  0.5s\n",
      "[########################################] | 100% Completed |  0.5s\n",
      "[########################################] | 100% Completed |  0.5s\n",
      "[########################################] | 100% Completed |  0.5s\n",
      "[########################################] | 100% Completed |  0.6s\n",
      "[########################################] | 100% Completed |  0.6s\n",
      "[########################################] | 100% Completed |  0.6s\n",
      "[########################################] | 100% Completed |  0.7s\n",
      "[########################################] | 100% Completed |  0.7s\n",
      "[########################################] | 100% Completed |  0.7s\n",
      "[########################################] | 100% Completed |  0.8s\n"
     ]
    }
   ],
   "source": [
    "al_siret.test_doublon(df_duplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27312, 34)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_duplication.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11168"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_duplication['index'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  1.9s\n",
      "[########################################] | 100% Completed |  2.0s\n",
      "[########################################] | 100% Completed |  2.1s\n",
      "[########################################] | 100% Completed |  2.2s\n",
      "[########################################] | 100% Completed |  2.2s\n",
      "[########################################] | 100% Completed |  2.2s\n",
      "[########################################] | 100% Completed |  2.3s\n",
      "[########################################] | 100% Completed |  2.4s\n",
      "[########################################] | 100% Completed |  2.1s\n",
      "[########################################] | 100% Completed |  2.2s\n",
      "[########################################] | 100% Completed |  2.3s\n",
      "[########################################] | 100% Completed |  2.4s\n",
      "[########################################] | 100% Completed |  2.5s\n",
      "[########################################] | 100% Completed |  2.6s\n",
      "[########################################] | 100% Completed |  2.7s\n",
      "[########################################] | 100% Completed |  2.8s\n",
      "[########################################] | 100% Completed |  0.2s\n",
      "[########################################] | 100% Completed |  0.3s\n",
      "[########################################] | 100% Completed |  0.4s\n",
      "[########################################] | 100% Completed |  0.4s\n",
      "[########################################] | 100% Completed |  0.4s\n",
      "[########################################] | 100% Completed |  0.4s\n",
      "[########################################] | 100% Completed |  0.4s\n",
      "[########################################] | 100% Completed |  0.5s\n"
     ]
    }
   ],
   "source": [
    "duplicates_ = al_siret.assess_test(df = df_duplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27312, 44)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11168"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates_['index'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_not_duplicate = pd.DataFrame()\n",
    "copy_duplicate = duplicates_.copy()\n",
    "\n",
    "for i in ['test_join_address','test_address_libelle', 'test_address_complement']:\n",
    "    ### split duplication\n",
    "    test_1 = al_siret.split_duplication(\n",
    "        copy_duplicate[\n",
    "            copy_duplicate[i].isin([True])]\n",
    "    )\n",
    "    \n",
    "    ### append unique\n",
    "    df_not_duplicate = (\n",
    "        df_not_duplicate\n",
    "        .append(test_1['not_duplication']\n",
    "                .assign(test = i)\n",
    "               )\n",
    "    )\n",
    "    \n",
    "    copy_duplicate = (copy_duplicate\n",
    "                   .loc[~copy_duplicate['index'].isin(\n",
    "                       pd.concat([\n",
    "                           test_1['duplication'],\n",
    "                           test_1['not_duplication']\n",
    "                       ], axis = 0)['index']\n",
    "                       .drop_duplicates())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5045, 45)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_not_duplicate.to_csv(r'data\\output\\not_duplicate_{}.gz'.format(df_not_duplicate.shape[0]),\n",
    "                  compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15440, 44)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Special treatment\n",
    "(duplicates_[\n",
    "    ~duplicates_['index']\n",
    "    .isin(df_not_duplicate['index'])]\n",
    " .to_csv(r'data\\output\\not_duplicate_{}.gz'.format(df_not_duplicate.shape[0]),\n",
    "                  compression = 'gzip'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_ets = r'data\\input\\inpi_etb_stock_7552898.gz'\n",
    "inpi = al_siret.import_dask(file=df_ets,\n",
    "                       usecols=inpi_col, dtype=inpi_dtype)\n",
    "\n",
    "df_nomatch = pd.DataFrame()\n",
    "df_input = inpi\n",
    "  \n",
    "total_match = pd.DataFrame()\n",
    "for i in [\n",
    "        ['ncc', 'libelleCommuneEtablissement'],\n",
    "        ['Code_Postal', 'codePostalEtablissement'],\n",
    "        ['Code_Commune', 'codeCommuneEtablissement']\n",
    "    ]:\n",
    "    df_input_ = al_siret.merge_siren_candidat(df_input=df_input,\n",
    "                                  option=i)\n",
    "\n",
    "    df_input = df_input_['unmatch']\n",
    "    total_match = total_match.append(df_input_['true_match'])\n",
    "\n",
    "    \n",
    "al_siret.match_unmatch(\n",
    "        df_inpi_initial= inpi.compute(),\n",
    "        df_inpi_mergeboth=total_match.drop(columns = '_merge'),\n",
    "        step='1_ville_cp_cc',\n",
    "        to_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "inpi_col = ['siren',\n",
    "            'index',\n",
    "            'Type',\n",
    "            'Adresse_Ligne1',\n",
    "            'Adresse_Ligne2',\n",
    "            'Adresse_Ligne3',\n",
    "            'Code_Postal',\n",
    "            'Ville',\n",
    "            'Code_Commune',\n",
    "            'Pays',\n",
    "            'count_initial_inpi',\n",
    "            'ncc',\n",
    "            'Adress_new',\n",
    "            'Adresse_new_clean_reg']\n",
    "\n",
    "inpi_dtype = {\n",
    "    'siren': 'object',\n",
    "    'index': 'int',\n",
    "    'Type': 'object',\n",
    "    'Adresse_Ligne1': 'object',\n",
    "    'Adresse_Ligne2': 'object',\n",
    "    'Adresse_Ligne3': 'object',\n",
    "    'Code_Postal': 'object',\n",
    "    'Ville': 'object',\n",
    "    'Code_Commune': 'object',\n",
    "    'Pays': 'object',\n",
    "    'count_initial_inpi': 'int',\n",
    "    'ncc': 'object',\n",
    "    'Adress_new': 'object',\n",
    "    'Adresse_new_clean_reg': 'object'\n",
    "}\n",
    "\n",
    "\n",
    "#df_nomatch = pd.DataFrame()\n",
    "df_match = pd.DataFrame()\n",
    "for chunk in [0,1\n",
    "              ,2,3,4,5,6,7,8,9, 10,11,12\n",
    "             ]:\n",
    "    csv_file = r'data\\input\\unmatched\\chunk\\chunk_{}.gz'.format(chunk)\n",
    "    inpi = al_siret.import_dask(file=csv_file,\n",
    "                       usecols=inpi_col, dtype=inpi_dtype)\n",
    "    df_input = inpi\n",
    "    total_match = pd.DataFrame()\n",
    "    for i in [\n",
    "        ['ncc', 'libelleCommuneEtablissement'],\n",
    "        ['Code_Postal', 'codePostalEtablissement'],\n",
    "        ['Code_Commune', 'codeCommuneEtablissement']\n",
    "    ]:\n",
    "        df_input_ = al_siret.merge_siren_candidat(df_input=df_input,\n",
    "                                      option=i,\n",
    "                                      regex_go = True)\n",
    "\n",
    "        df_input = df_input_['unmatch']\n",
    "        total_match = total_match.append(df_input_['true_match']) \n",
    "    #df_nomatch = df_nomatch.append(df_input)\n",
    "    df_match = df_match.append(total_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_temp = pd.DataFrame()\n",
    "for i in range(0,13):\n",
    "    csv_file = r'data\\input\\unmatched\\chunk\\chunk_{}.gz'.format(i)\n",
    "    df_temp = df_temp.append(pd.read_csv(csv_file,\n",
    "                                         dtype= inpi_dtype)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "299986 / 4979272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "al_siret.match_unmatch(\n",
    "        df_inpi_initial=df_temp,\n",
    "        df_inpi_mergeboth=df_match.drop(columns = '_merge'),\n",
    "        step='3_adress',\n",
    "        to_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### Matching voie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "inpi_col = ['siren',\n",
    "            'index',\n",
    "            'Type',\n",
    "            'Adresse_Ligne1',\n",
    "            'Adresse_Ligne2',\n",
    "            'Adresse_Ligne3',\n",
    "            'Code_Postal',\n",
    "            'Ville',\n",
    "            'Code_Commune',\n",
    "            'Pays',\n",
    "            'count_initial_inpi',\n",
    "            'ncc',\n",
    "            'Adress_new',\n",
    "            'Adresse_new_clean_reg']\n",
    "\n",
    "inpi_dtype = {\n",
    "    'siren': 'object',\n",
    "    'index': 'int',\n",
    "    'Type': 'object',\n",
    "    'Adresse_Ligne1': 'object',\n",
    "    'Adresse_Ligne2': 'object',\n",
    "    'Adresse_Ligne3': 'object',\n",
    "    'Code_Postal': 'object',\n",
    "    'Ville': 'object',\n",
    "    'Code_Commune': 'object',\n",
    "    'Pays': 'object',\n",
    "    'count_initial_inpi': 'int',\n",
    "    'ncc': 'object',\n",
    "    'Adress_new': 'object',\n",
    "    'Adresse_new_clean_reg': 'object'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#temp = al_siret.merge_siren_candidat(df_input=inpi,\n",
    "#                              regex_go=True, \n",
    "#                              matching_voie=True,\n",
    "#                              option=['ncc', 'libelleCommuneEtablissement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "inpi = al_siret.import_dask(file=r'data\\input\\unmatched\\unmatch_3_adress_299986.gz',\n",
    "                       usecols=inpi_col, dtype=inpi_dtype)\n",
    "df_input = inpi\n",
    "  \n",
    "total_match = pd.DataFrame()\n",
    "for i in [\n",
    "        ['ncc', 'libelleCommuneEtablissement'],\n",
    "        ['Code_Postal', 'codePostalEtablissement'],\n",
    "        ['Code_Commune', 'codeCommuneEtablissement']\n",
    "    ]:\n",
    "    df_input_ = al_siret.merge_siren_candidat(\n",
    "        df_input=df_input,\n",
    "        regex_go=True,\n",
    "        matching_voie=True,\n",
    "        option=i)\n",
    "\n",
    "    df_input = df_input_['unmatch']\n",
    "    total_match = total_match.append(df_input_['true_match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "al_siret.match_unmatch(\n",
    "        df_inpi_initial= inpi.compute(),\n",
    "        df_inpi_mergeboth=total_match.drop(columns = '_merge'),\n",
    "        step='4_voie',\n",
    "        to_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### Relax contrainte Regex\n",
    "\n",
    "Sans numero de voie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "inpi = al_siret.import_dask(file=r'data\\input\\unmatched\\unmatch_4_voie_167801.gz',\n",
    "                       usecols=inpi_col, dtype=inpi_dtype)\n",
    "df_input = inpi\n",
    "  \n",
    "total_match = pd.DataFrame()\n",
    "for i in [\n",
    "        ['ncc', 'libelleCommuneEtablissement'],\n",
    "        ['Code_Postal', 'codePostalEtablissement'],\n",
    "        ['Code_Commune', 'codeCommuneEtablissement']\n",
    "    ]:\n",
    "    df_input_ = al_siret.merge_siren_candidat(\n",
    "        df_input=df_input,\n",
    "        regex_go=True,\n",
    "        matching_voie=False,\n",
    "        relax_regex = True,\n",
    "        option=i)\n",
    "\n",
    "    df_input = df_input_['unmatch']\n",
    "    total_match = total_match.append(df_input_['true_match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "al_siret.match_unmatch(\n",
    "        df_inpi_initial= inpi.compute(),\n",
    "        df_inpi_mergeboth=total_match.drop(columns = '_merge'),\n",
    "        step='5_voie_relax',\n",
    "        to_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Avec la voie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "inpi_col = ['siren',\n",
    "            'index',\n",
    "            'Type',\n",
    "            'Adresse_Ligne1',\n",
    "            'Adresse_Ligne2',\n",
    "            'Adresse_Ligne3',\n",
    "            'Code_Postal',\n",
    "            'Ville',\n",
    "            'Code_Commune',\n",
    "            'Pays',\n",
    "            'count_initial_inpi',\n",
    "            'ncc',\n",
    "            'Adress_new',\n",
    "            'Adresse_new_clean_reg']\n",
    "\n",
    "inpi_dtype = {\n",
    "    'siren': 'object',\n",
    "    'index': 'int',\n",
    "    'Type': 'object',\n",
    "    'Adresse_Ligne1': 'object',\n",
    "    'Adresse_Ligne2': 'object',\n",
    "    'Adresse_Ligne3': 'object',\n",
    "    'Code_Postal': 'object',\n",
    "    'Ville': 'object',\n",
    "    'Code_Commune': 'object',\n",
    "    'Pays': 'object',\n",
    "    'count_initial_inpi': 'int',\n",
    "    'ncc': 'object',\n",
    "    'Adress_new': 'object',\n",
    "    'Adresse_new_clean_reg': 'object'\n",
    "}\n",
    "\n",
    "inpi = al_siret.import_dask(file=r'data\\input\\unmatched\\unmatch_5_relax_116575.gz',\n",
    "                       usecols=inpi_col, dtype=inpi_dtype)\n",
    "df_input = inpi\n",
    "  \n",
    "total_match = pd.DataFrame()\n",
    "for i in [\n",
    "        ['ncc', 'libelleCommuneEtablissement'],\n",
    "        ['Code_Postal', 'codePostalEtablissement'],\n",
    "        ['Code_Commune', 'codeCommuneEtablissement']\n",
    "    ]:\n",
    "    df_input_ = al_siret.merge_siren_candidat(\n",
    "        df_input=df_input,\n",
    "        regex_go=True,\n",
    "        matching_voie=True,\n",
    "        relax_regex = True,\n",
    "        option=i)\n",
    "\n",
    "    df_input = df_input_['unmatch']\n",
    "    total_match = total_match.append(df_input_['true_match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "inpi = al_siret.import_dask(file=r'data\\input\\unmatched\\unmatch_5_relax_116575.gz',\n",
    "                       usecols=inpi_col, dtype=inpi_dtype)\n",
    "check = al_siret.match_unmatch(\n",
    "        df_inpi_initial= inpi.compute(),\n",
    "        df_inpi_mergeboth=total_match.drop(columns = '_merge'),\n",
    "        step='6_voie_relax',\n",
    "        to_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "check['count_initial_inpi'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### Match etablissement principal ouvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "inpi_col = ['siren',\n",
    "            'index',\n",
    "            'Type',\n",
    "            'Adresse_Ligne1',\n",
    "            'Adresse_Ligne2',\n",
    "            'Adresse_Ligne3',\n",
    "            'Code_Postal',\n",
    "            'Ville',\n",
    "            'Code_Commune',\n",
    "            'Pays',\n",
    "            'count_initial_inpi',\n",
    "            'ncc',\n",
    "            'Adress_new',\n",
    "            'Adresse_new_clean_reg']\n",
    "\n",
    "inpi_dtype = {\n",
    "    'siren': 'object',\n",
    "    'index': 'int',\n",
    "    'Type': 'object',\n",
    "    'Adresse_Ligne1': 'object',\n",
    "    'Adresse_Ligne2': 'object',\n",
    "    'Adresse_Ligne3': 'object',\n",
    "    'Code_Postal': 'object',\n",
    "    'Ville': 'object',\n",
    "    'Code_Commune': 'object',\n",
    "    'Pays': 'object',\n",
    "    'count_initial_inpi': 'int',\n",
    "    'ncc': 'object',\n",
    "    'Adress_new': 'object',\n",
    "    'Adresse_new_clean_reg': 'object'\n",
    "}\n",
    "inpi = al_siret.import_dask(file=r'data\\input\\unmatched\\unmatch_6_voie_relax_112847.gz',\n",
    "                       usecols=inpi_col, dtype=inpi_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_input = inpi\n",
    "  \n",
    "total_match = pd.DataFrame()\n",
    "for i in [\n",
    "        ['ncc', 'libelleCommuneEtablissement'],\n",
    "        ['Code_Postal', 'codePostalEtablissement'],\n",
    "        ['Code_Commune', 'codeCommuneEtablissement']\n",
    "    ]:\n",
    "    df_input_ = al_siret.merge_siren_candidat(\n",
    "        df_input=df_input,\n",
    "        regex_go=True,\n",
    "        matching_voie=False,\n",
    "        relax_regex = True,\n",
    "        siege_etat=True,\n",
    "        option=i)\n",
    "\n",
    "    df_input = df_input_['unmatch']\n",
    "    total_match = total_match.append(df_input_['true_match'])\n",
    "    \n",
    "al_siret.match_unmatch(\n",
    "        df_inpi_initial= inpi.compute(),\n",
    "        df_inpi_mergeboth=total_match.drop(columns = '_merge'),\n",
    "        step='7_siege_ouvert',\n",
    "        to_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### Complement d adresse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "inpi_col = ['siren',\n",
    "            'index',\n",
    "            'Type',\n",
    "            'Adresse_Ligne1',\n",
    "            'Adresse_Ligne2',\n",
    "            'Adresse_Ligne3',\n",
    "            'Code_Postal',\n",
    "            'Ville',\n",
    "            'Code_Commune',\n",
    "            'Pays',\n",
    "            'count_initial_inpi',\n",
    "            'ncc',\n",
    "            'Adress_new',\n",
    "            'Adresse_new_clean_reg']\n",
    "\n",
    "inpi_dtype = {\n",
    "    'siren': 'object',\n",
    "    'index': 'int',\n",
    "    'Type': 'object',\n",
    "    'Adresse_Ligne1': 'object',\n",
    "    'Adresse_Ligne2': 'object',\n",
    "    'Adresse_Ligne3': 'object',\n",
    "    'Code_Postal': 'object',\n",
    "    'Ville': 'object',\n",
    "    'Code_Commune': 'object',\n",
    "    'Pays': 'object',\n",
    "    'count_initial_inpi': 'int',\n",
    "    'ncc': 'object',\n",
    "    'Adress_new': 'object',\n",
    "    'Adresse_new_clean_reg': 'object'\n",
    "}\n",
    "\n",
    "\n",
    "inpi = al_siret.import_dask(file=r'data\\input\\unmatched\\unmatch_7_siege_ouvert_85312.gz',\n",
    "                       usecols=inpi_col, dtype=inpi_dtype)\n",
    "df_input = inpi\n",
    "  \n",
    "total_match = pd.DataFrame()\n",
    "for i in [\n",
    "        ['ncc', 'libelleCommuneEtablissement'],\n",
    "        ['Code_Postal', 'codePostalEtablissement'],\n",
    "        ['Code_Commune', 'codeCommuneEtablissement']\n",
    "    ]:\n",
    "    df_input_ = al_siret.merge_siren_candidat(\n",
    "        df_input=df_input,\n",
    "        regex_go=True,\n",
    "        matching_voie=False,\n",
    "        relax_regex = True,\n",
    "        siege_etat=True,\n",
    "        option=i,\n",
    "        var_adress_insee = 'complementAdresseEtablissement')\n",
    "\n",
    "    df_input = df_input_['unmatch']\n",
    "    total_match = total_match.append(df_input_['true_match'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "al_siret.match_unmatch(\n",
    "        df_inpi_initial= inpi.compute(),\n",
    "        df_inpi_mergeboth=total_match.drop(columns = '_merge'),\n",
    "        step='8_siege_ouvert_complement',\n",
    "        to_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "1- (80474/4979272)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Test sans regex mais siege_etat\n",
    "\n",
    "ie si principale-ouvert dans la ville/CP/CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "inpi_col = ['siren',\n",
    "            'index',\n",
    "            'Type',\n",
    "            'Adresse_Ligne1',\n",
    "            'Adresse_Ligne2',\n",
    "            'Adresse_Ligne3',\n",
    "            'Code_Postal',\n",
    "            'Ville',\n",
    "            'Code_Commune',\n",
    "            'Pays',\n",
    "            'count_initial_inpi',\n",
    "            'ncc',\n",
    "            'Adress_new',\n",
    "            'Adresse_new_clean_reg']\n",
    "\n",
    "inpi_dtype = {\n",
    "    'siren': 'object',\n",
    "    'index': 'int',\n",
    "    'Type': 'object',\n",
    "    'Adresse_Ligne1': 'object',\n",
    "    'Adresse_Ligne2': 'object',\n",
    "    'Adresse_Ligne3': 'object',\n",
    "    'Code_Postal': 'object',\n",
    "    'Ville': 'object',\n",
    "    'Code_Commune': 'object',\n",
    "    'Pays': 'object',\n",
    "    'count_initial_inpi': 'int',\n",
    "    'ncc': 'object',\n",
    "    'Adress_new': 'object',\n",
    "    'Adresse_new_clean_reg': 'object'\n",
    "}\n",
    "\n",
    "\n",
    "inpi = al_siret.import_dask(file=r'data\\input\\unmatched\\unmatch_8_siege_ouvert_complement_80474.gz',\n",
    "                       usecols=inpi_col, dtype=inpi_dtype)\n",
    "df_input = inpi\n",
    "  \n",
    "total_match = pd.DataFrame()\n",
    "for i in [\n",
    "        ['ncc', 'libelleCommuneEtablissement'],\n",
    "        ['Code_Postal', 'codePostalEtablissement'],\n",
    "        ['Code_Commune', 'codeCommuneEtablissement']\n",
    "    ]:\n",
    "    df_input_ = al_siret.merge_siren_candidat(\n",
    "        df_input=df_input,\n",
    "        regex_go=False,\n",
    "        matching_voie=False,\n",
    "        relax_regex = False,\n",
    "        siege_etat=True,\n",
    "        option=i,\n",
    "        var_adress_insee = 'libelleVoieEtablissement')\n",
    "\n",
    "    df_input = df_input_['unmatch']\n",
    "    total_match = total_match.append(df_input_['true_match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "al_siret.match_unmatch(\n",
    "        df_inpi_initial= inpi.compute(),\n",
    "        df_inpi_mergeboth=total_match.drop(columns = '_merge'),\n",
    "        step='9_siege_ouvert_no_regex',\n",
    "        to_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "round(1 - (68131 / 4979272),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "# Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "inpi_col = ['siren',\n",
    "            'index',\n",
    "            'Type',\n",
    "            'Adresse_Ligne1',\n",
    "            'Adresse_Ligne2',\n",
    "            'Adresse_Ligne3',\n",
    "            'Code_Postal',\n",
    "            'Ville',\n",
    "            'Code_Commune',\n",
    "            'Pays',\n",
    "            'count_initial_inpi',\n",
    "            'ncc',\n",
    "            'Adress_new',\n",
    "            'Adresse_new_clean_reg']\n",
    "\n",
    "inpi_dtype = {\n",
    "    'siren': 'object',\n",
    "    'index': 'int',\n",
    "    'Type': 'object',\n",
    "    'Adresse_Ligne1': 'object',\n",
    "    'Adresse_Ligne2': 'object',\n",
    "    'Adresse_Ligne3': 'object',\n",
    "    'Code_Postal': 'object',\n",
    "    'Ville': 'object',\n",
    "    'Code_Commune': 'object',\n",
    "    'Pays': 'object',\n",
    "    'count_initial_inpi': 'int',\n",
    "    'ncc': 'object',\n",
    "    'Adress_new': 'object',\n",
    "    'Adresse_new_clean_reg': 'object'\n",
    "}\n",
    "\n",
    "\n",
    "inpi = al_siret.import_dask(file=r'data\\output\\match_9_siege_ouvert_no_regex_12343.gz',\n",
    "                       usecols=inpi_col, dtype=inpi_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "inpi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "inpi['Adresse_new_clean_reg'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Amelioration matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "insee_dtype = {\n",
    "    'siren': 'object',\n",
    "    'siret': 'object',\n",
    "    'dateCreationEtablissement': 'object',\n",
    "    \"etablissementSiege\": \"object\",\n",
    "    \"etatAdministratifEtablissement\": \"object\",\n",
    "    'complementAdresseEtablissement': 'object',\n",
    "    'numeroVoieEtablissement': 'object',\n",
    "    'indiceRepetitionEtablissement': 'object',\n",
    "    'typeVoieEtablissement': 'object',\n",
    "    'libelleVoieEtablissement': 'object',\n",
    "    'codePostalEtablissement': 'object',\n",
    "    'libelleCommuneEtablissement': 'object',\n",
    "    'libelleCommuneEtrangerEtablissement': 'object',\n",
    "    'distributionSpecialeEtablissement': 'object',\n",
    "    'codeCommuneEtablissement': 'object',\n",
    "    'codeCedexEtablissement': 'object',\n",
    "    'libelleCedexEtablissement': 'object',\n",
    "    'codePaysEtrangerEtablissement': 'object',\n",
    "    'libellePaysEtrangerEtablissement': 'object',\n",
    "    'count_initial_insee': 'int'\n",
    "}\n",
    "\n",
    "insee_col = ['siren',\n",
    "             'siret',\n",
    "             'dateCreationEtablissement',\n",
    "             \"etablissementSiege\",\n",
    "             \"etatAdministratifEtablissement\",\n",
    "             'complementAdresseEtablissement',\n",
    "             'numeroVoieEtablissement',\n",
    "             'indiceRepetitionEtablissement',\n",
    "             'typeVoieEtablissement',\n",
    "             'libelleVoieEtablissement',\n",
    "             'codePostalEtablissement',\n",
    "             'libelleCommuneEtablissement',\n",
    "             'libelleCommuneEtrangerEtablissement',\n",
    "             'distributionSpecialeEtablissement',\n",
    "             'codeCommuneEtablissement',\n",
    "             'codeCedexEtablissement',\n",
    "             'libelleCedexEtablissement',\n",
    "             'codePaysEtrangerEtablissement',\n",
    "             'libellePaysEtrangerEtablissement',\n",
    "             'count_initial_insee']\n",
    "inpi_col = ['siren',\n",
    "            'index',\n",
    "            'Type',\n",
    "            'Adresse_Ligne1',\n",
    "            'Adresse_Ligne2',\n",
    "            'Adresse_Ligne3',\n",
    "            'Code_Postal',\n",
    "            'Ville',\n",
    "            'Code_Commune',\n",
    "            'Pays',\n",
    "            'count_initial_inpi',\n",
    "            'ncc',\n",
    "            'Adress_new',\n",
    "            'Adresse_new_clean_reg']\n",
    "\n",
    "inpi_dtype = {\n",
    "    'siren': 'object',\n",
    "    'index': 'int',\n",
    "    'Type': 'object',\n",
    "    'Adresse_Ligne1': 'object',\n",
    "    'Adresse_Ligne2': 'object',\n",
    "    'Adresse_Ligne3': 'object',\n",
    "    'Code_Postal': 'object',\n",
    "    'Ville': 'object',\n",
    "    'Code_Commune': 'object',\n",
    "    'Pays': 'object',\n",
    "    'count_initial_inpi': 'int',\n",
    "    'ncc': 'object',\n",
    "    'Adress_new': 'object',\n",
    "    'Adresse_new_clean_reg': 'object'\n",
    "}\n",
    "\n",
    "insee = al_siret.import_dask(file=r'data\\input\\insee_2017_7480120.gz',\n",
    "                             usecols=insee_col, dtype=insee_dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "list(insee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#insee['etatAdministratifEtablissement'].value_counts().compute()\n",
    "inpi = al_siret.import_dask(file=r'data\\input\\unmatched\\unmatch_8_siege_ouvert_complement_80474.gz',\n",
    "                       usecols=inpi_col, dtype=inpi_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "inpi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "insee[\n",
    "    (insee['siren'].isin(['515226462']))\n",
    "#& (insee['libelleVoieEtablissement'].isin(['JACQUARD']))\n",
    "].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "inpi[inpi['siren'].isin(['515226462'])].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "inpi.loc[inpi['count_initial_inpi'].isin([1])].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "inpi.loc[inpi['siren'].isin(['322385949'])].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "inpi['Type'].value_counts().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "insee[insee['siren'].isin(['322385949'])].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Verification conservative:\n",
    "\n",
    "- A l'INSEE, si etatAdministratifEtablissement == A & etablissementSiege == True, alors on fait le sous ensemle\n",
    "- Verifier avec les dates de création de l'établissement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "insee.loc[\n",
    "            (insee['etablissementSiege'].isin(['true'])) \n",
    "            & (insee['etatAdministratifEtablissement'].isin(['A']))\n",
    "            ].compute() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "1 - (112847 / 4979272)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "amelioration possible:\n",
    "    \n",
    "- 381980788 -> Zone Artisanale du Creusât ->transformer en ZA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
