{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Programme de Matching\n",
    "\n",
    "Regarder si l'établissement est fermé ou pas\n",
    "\n",
    "## Moteur de recherche TEST\n",
    "\n",
    "* Insee\n",
    "  * http://avis-situation-sirene.insee.fr/IdentificationListeSiret.action\n",
    "* INPI/TC\n",
    "  * https://data.inpi.fr/\n",
    "* Infogreffe\n",
    "  * https://www.infogreffe.fr/\n",
    "\n",
    "## Preparation fichier\n",
    "\n",
    "### Variable Ville\n",
    "\n",
    "- process:\n",
    "    - creer variables avec numeric seulement\n",
    "    - recreer ville 2 si test pas NAN pour avoir l'arrondissement\n",
    "    - virer les differentes informations dans ville via regex\n",
    "    \n",
    "### Step 1: Match uniquement les 1 dans INSEE/INPI\n",
    "\n",
    "Les siren qui ont uniquement un seul établissement a l'INSEE et à l'INPI.\n",
    "\n",
    "### Step 2: match Ville/CP/CC\n",
    "\n",
    "### Step 3: Match adresse\n",
    "\n",
    "## Description Algorithm\n",
    "\n",
    "## Description Input\n",
    "\n",
    "## Description Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from inpi_insee import siretisation\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "    'insee': r'data\\input\\insee_2017_7627977.gz'\n",
    "}\n",
    "# 4824158 SIREN a trouver!\n",
    "al_siret = siretisation.siretisation_inpi(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Match 1-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Merge ville/code postale/ code commune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Process temporaire -> on sauvegarde les fichiers avec indication des tests:\n",
    "\n",
    "## First Step:\n",
    "\n",
    "- Après le merge full\n",
    "    - Test 1: doublon\n",
    "        - non: Save-> `test_1['not_duplication']`\n",
    "        - oui:\n",
    "            - Test 2: Date equal\n",
    "                - oui:\n",
    "                    - Test 2 bis: doublon\n",
    "                        - non: Save-> `test_2_bis['not_duplication']`\n",
    "                        - oui: Save-> `test_2_bis['duplication']`\n",
    "                - non:\n",
    "                    - Test 3: Date sup\n",
    "                        - oui:\n",
    "                            - Test 2 bis: doublon\n",
    "                                - non: Save-> `test_3_oui_bis['not_duplication']`\n",
    "                                - oui: Save-> `test_3_oui_bis['duplication']`\n",
    "                        - non: Save-> `test_3_non`\n",
    "                        \n",
    "## Second Step:\n",
    "\n",
    "On applique 5 tests sur les champs des possibles afin d'avoir une meilleure visibilitée \n",
    "\n",
    "- Test 1: address libelle\n",
    "    - Si mots dans inpi est contenu dans INSEE, True\n",
    "- Test 1 bis: address complement\n",
    "    - Si mots dans inpi est contenu dans INSEE, True\n",
    "- Test 2: Date\n",
    "    - dateCreationEtablissement >= Date_Début_Activité OR Date_Début_Activité = NaN OR (nombre SIREN a l'INSEE = 1 AND nombre SIREN des variables de matching = 1), True\n",
    "- Test 3: siege\n",
    "    - Type = ['SEP', 'SIE'] AND siege = true, True\n",
    "- Test 4: voie\n",
    "    - Type voie INPI = Type voie INSEE, True\n",
    "- Test 5: numero voie\n",
    "    - Numero voie INPI = Numero voie INSEE, True\n",
    "    \n",
    "### Second Steps: not on dupplication: df_no_duplication\n",
    "\n",
    "- On applique simplement les tests, mais on recupère toute la df car considérée comme matchée\n",
    "\n",
    "### Second Steps: on dupplication: df_duplication\n",
    "\n",
    "- On applique  les tests, mais on effectue les tests suivants:\n",
    "\n",
    "- Si test_join_address = True:\n",
    "    - Test 1: doublon:\n",
    "        - Oui: append-> `df_not_duplicate`\n",
    "        - Non: Pass\n",
    "        - Exclue les `index` de df_duplication\n",
    "        - then go next\n",
    "    - Si test_address_libelle = True:\n",
    "        - Test 1: doublon:\n",
    "            - Oui: append-> `df_not_duplicate`\n",
    "            - Non: Pass\n",
    "            - Exclue les `index` de df_duplication\n",
    "            - then go next\n",
    "    - Si test_address_complement = True:\n",
    "        - Test 1: doublon:\n",
    "            - Oui: append-> `df_not_duplicate`\n",
    "            - Non: Pass\n",
    "            - Exclue les `index` de df_duplication\n",
    "\n",
    "On peut sauvegarder le `df_not_duplicate` et le restant en tant que `special_treatment`\n",
    "\n",
    "Retourne au début, et on réduit les variables de matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#from itertools import compress, product\n",
    "\n",
    "#def combinations(items):\n",
    "#    return ( set(compress(items,mask)) for \n",
    "#            mask in product(*[[0,1]]*len(items)))\n",
    "\n",
    "#all_list = ['ncc',\n",
    "#             'Code_Postal','Code_Commune',\n",
    "#             'INSEE','digit_inpi']\n",
    "#test = list(combinations(items = all_list))[1:]\n",
    "#sort_list = sorted(test[1:], key=lambda k: len(k), reverse=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "list_inpi = ['ncc','Code_Postal','Code_Commune','INSEE','digit_inpi']\n",
    "list_insee = ['libelleCommuneEtablissement',\n",
    "            'codePostalEtablissement', 'codeCommuneEtablissement',\n",
    "            'typeVoieEtablissement','numeroVoieEtablissement']\n",
    "\n",
    "sort_list = [\n",
    " {'ncc', 'Code_Postal', 'Code_Commune', 'INSEE', 'digit_inpi'},\n",
    " {'ncc', 'Code_Postal', 'Code_Commune', 'INSEE'},\n",
    " {'ncc', 'Code_Postal', 'Code_Commune', 'digit_inpi'},\n",
    " {'ncc', 'Code_Postal', 'Code_Commune'},   \n",
    " {'ncc', 'Code_Postal'},\n",
    " {'ncc'},\n",
    " {'Code_Postal'},\n",
    " {'Code_Commune'}\n",
    "]\n",
    "len(sort_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "list_possibilities = []\n",
    "for i in sort_list:\n",
    "    left =[]\n",
    "    right = []\n",
    "    for j in i:\n",
    "        left.append(j)\n",
    "        right.append(list_insee[list_inpi.index(j)])\n",
    "    left.insert(0,'siren')\n",
    "    right.insert(0,'siren')\n",
    "    \n",
    "    dic_ = {\n",
    "    'match':{\n",
    "        'inpi':left,\n",
    "        'insee':right,\n",
    "    }\n",
    "}\n",
    "    list_possibilities.append(dic_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import json\n",
    "inpi_col = ['siren',\n",
    "            'index',\n",
    "            'Type',\n",
    "            'Code_Postal',\n",
    "            'Ville',\n",
    "            'Code_Commune',\n",
    "            'Pays',\n",
    "            'count_initial_inpi',\n",
    "            'ncc',\n",
    "            'Adresse_new_clean_reg',\n",
    "            'Adress_new',\n",
    "            'INSEE',\n",
    "            'Date_Début_Activité',\n",
    "            'digit_inpi',\n",
    "            'len_digit_address_inpi',\n",
    "            'list_digit_inpi'\n",
    "            ]\n",
    "\n",
    "inpi_dtype = {\n",
    "    'siren': 'object',\n",
    "    'index': 'int',\n",
    "    'Type': 'object',\n",
    "    'Code_Postal': 'object',\n",
    "    'Ville': 'object',\n",
    "    'Code_Commune': 'object',\n",
    "    'Pays': 'object',\n",
    "    'count_initial_inpi': 'int',\n",
    "    'ncc': 'object',\n",
    "    'Adresse_new_clean_reg': 'object',\n",
    "    'Adress_new':'object',\n",
    "    'INSEE': 'object',\n",
    "    'Date_Début_Activité': 'object',\n",
    "    'digit_inpi': 'object',\n",
    "    'len_digit_address_inpi':'object'\n",
    "}\n",
    "\n",
    "for key, values in enumerate(list_possibilities):\n",
    "    df_ets = r'data\\input\\INPI\\inpi_etb_stock_{}.gz'.format(key)\n",
    "\n",
    "    inpi = al_siret.import_dask(file=df_ets,\n",
    "                                usecols=inpi_col,\n",
    "                                dtype=inpi_dtype,\n",
    "                                parse_dates=False)\n",
    "\n",
    "    df_no_duplication, df_duplication = al_siret.step_one(\n",
    "        df_input=inpi,\n",
    "        left_on=values['match']['inpi'],\n",
    "        right_on=values['match']['insee']\n",
    "    )\n",
    "\n",
    "    # Step 2: No duplication\n",
    "    pure_match = al_siret.step_two_assess_test(df=df_no_duplication,\n",
    "                                               var_group=values['match']['inpi'])\n",
    "\n",
    "    pure_match.to_csv(r'data\\output\\{}_pure_match.gz'.format(key),\n",
    "                      compression='gzip', index= False)\n",
    "    # Step 2: duplication\n",
    "    df_not_duplicate, sp = al_siret.step_two_duplication(df_duplication,\n",
    "                                                        var_group = values['match']['inpi'])\n",
    "    \n",
    "    (df_not_duplicate\n",
    "        .to_csv(r'data\\output\\{}_not_duplicate.gz'.format(key),\n",
    "                compression='gzip', index= False))\n",
    "\n",
    "    (sp.to_csv(r'data\\input\\INPI\\special_treatment\\{}_special_treatment.gz'.format(\n",
    "        key),compression='gzip', index= False))\n",
    "\n",
    "    # Input -> Save for the next loop \n",
    "    inpi.loc[\n",
    "        (~inpi['index'].isin(pure_match['index'].unique()))\n",
    "        & (~inpi['index'].isin(df_not_duplicate['index'].unique()))\n",
    "        & (~inpi['index'].isin(sp['index'].unique()))\n",
    "    ].compute().to_csv(r'data\\input\\INPI\\inpi_etb_stock_{}.gz'.format(key+1),\n",
    "                       compression='gzip', index= False)\n",
    "\n",
    "    #### Creation LOG\n",
    "    if key ==0:\n",
    "        total_to_siret_intial = inpi.compute().shape[0]\n",
    "        total_siren_initial = inpi.compute()['siren'].nunique()\n",
    "    \n",
    "    ### Total rows in df inpi to match\n",
    "    total_to_siret_current = inpi.compute().shape[0]\n",
    "    total_siren_current = inpi.compute()['siren'].nunique() # unique siren \n",
    "    \n",
    "    ### DF with no duplication after merge INSEE\n",
    "    total_rows_no_dup = df_no_duplication[\"index\"].nunique()\n",
    "    total_rows_no_dup_unique_siren = df_no_duplication['siren'].nunique()\n",
    "    \n",
    "    ### DF with duplication after merge INSEE\n",
    "    total_rows_dup = df_duplication[\"index\"].nunique() # total duplication\n",
    "    total_rows_dup_unique_siren = df_duplication[\"siren\"].nunique()\n",
    "    \n",
    "    total_rows_dup_matched = df_not_duplicate[\"index\"].nunique() #no duplication\n",
    "    total_rows_dup_matched_unique_siren = df_not_duplicate[\"siren\"].nunique()\n",
    "    \n",
    "    total_rows_dup_not_matched = sp[\"index\"].nunique() # special treatmnent\n",
    "    total_rows_dup_not_matched_unique_siren = sp[\"siren\"].nunique()\n",
    "    \n",
    "    ### compare with initial\n",
    "    total_match_rows_current = total_rows_no_dup + total_rows_dup_matched\n",
    "    perc_total_match_rows_initial = total_match_rows_current / \\\n",
    "    total_to_siret_intial\n",
    "    \n",
    "    total_match_siren_current = total_rows_no_dup_unique_siren + \\\n",
    "    total_rows_dup_matched_unique_siren\n",
    "    \n",
    "    perc_total_match_siren_initial = total_match_siren_current / \\\n",
    "    total_siren_initial \n",
    "    \n",
    "    ### compare with current\n",
    "    perc_total_match_rows_current = total_match_rows_current / \\\n",
    "    total_to_siret_current\n",
    "\n",
    "    perc_total_match_siren_current = total_match_siren_current / \\\n",
    "    total_siren_current\n",
    "    \n",
    "    \n",
    "    dic_ = {\n",
    "        'key':key,\n",
    "        'total_to_siret_intial':total_to_siret_intial,\n",
    "        'total_stotal_siren_initialiren': total_siren_initial,\n",
    "        'total_to_siret_current':total_to_siret_current,\n",
    "        'total_siren_current': total_siren_current,\n",
    "        'total_match_rows_current':total_match_rows_current,\n",
    "        'perc_total_match_rows_initial':perc_total_match_rows_initial,\n",
    "        'total_match_siren_current':total_match_siren_current,\n",
    "        'perc_total_match_siren_initial':perc_total_match_siren_initial,\n",
    "        'perc_total_match_rows_current':perc_total_match_rows_current,\n",
    "        'perc_total_match_siren_current':perc_total_match_siren_current,\n",
    "        'df_no_duplication': {\n",
    "            'nb_index': total_rows_no_dup,\n",
    "            'unique_siren':total_rows_no_dup_unique_siren\n",
    "        },\n",
    "        'df_duplication': {\n",
    "            'nb_index': total_rows_dup,\n",
    "            'unique_siren':total_rows_dup_unique_siren,\n",
    "            'df_not_duplicate_index': {\n",
    "                'nb_index':total_rows_dup_matched,\n",
    "               'unique_siren':total_rows_dup_unique_siren\n",
    "            },\n",
    "            'df_sp_index': {\n",
    "                'nb_index':total_rows_dup_not_matched,\n",
    "               'unique_siren':total_rows_dup_not_matched_unique_siren\n",
    "            }\n",
    "        },\n",
    "        'check': total_to_siret_current -\n",
    "        total_rows_no_dup +\n",
    "        total_rows_dup\n",
    "    }\n",
    "\n",
    "    with open(r'data\\logs\\{}_logs.json'.format(key), 'w') as f:\n",
    "        json.dump(dic_, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### temp test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "sp.head().to_excel('test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "inpi_col = ['siren',\n",
    "            'index',\n",
    "            'Type',\n",
    "            'Code_Postal',\n",
    "            'Ville',\n",
    "            'Code_Commune',\n",
    "            'Pays',\n",
    "            'count_initial_inpi',\n",
    "            'ncc',\n",
    "            'Adresse_new_clean_reg',\n",
    "            'INSEE',\n",
    "            'Date_Début_Activité',\n",
    "            'digit_inpi',\n",
    "            'len_digit_address_inpi',\n",
    "            'list_digit_inpi'\n",
    "            ]\n",
    "\n",
    "inpi_dtype = {\n",
    "    'siren': 'object',\n",
    "    'index': 'int',\n",
    "    'Type': 'object',\n",
    "    'Code_Postal': 'object',\n",
    "    'Ville': 'object',\n",
    "    'Code_Commune': 'object',\n",
    "    'Pays': 'object',\n",
    "    'count_initial_inpi': 'int',\n",
    "    'ncc': 'object',\n",
    "    'Adresse_new_clean_reg': 'object',\n",
    "    'INSEE': 'object',\n",
    "    'Date_Début_Activité': 'object',\n",
    "    'digit_inpi': 'object',\n",
    "    'len_digit_address_inpi':'object'\n",
    "}\n",
    "df_ets = r'data\\input\\INPI\\inpi_etb_stock_{}.gz'.format(4)\n",
    "\n",
    "inpi = al_siret.import_dask(file=df_ets,\n",
    "                                usecols=inpi_col,\n",
    "                                dtype=inpi_dtype,\n",
    "                                parse_dates=False)\n",
    "inpi[inpi['siren'].isin(['752085324'])].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "inpi.compute().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "inpi.compute()['siren'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Open Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import glob, os, json\n",
    "data = []\n",
    "#os.chdir(r\"data\\logs\\\")\n",
    "for file in glob.glob(r\"data\\logs\\*.json\"):\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#from pandas.io.json import json_normalize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "logs = pd.json_normalize(data)\n",
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "logs[['total_match_rows_current']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "logs[['perc_total_match_rows_initial']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "logs[['perc_total_match_siren_initial']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "logs[['perc_total_match_rows_initial',\n",
    "      'perc_total_match_siren_initial']].plot.bar(stacked=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "logs[['total_match_rows_current']].plot.bar(stacked=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Special Treatment\n",
    "\n",
    "exemple:\n",
    "\n",
    "- 752085324\n",
    "- 342122546: libelle type dans l'adresse complementaire a l'insee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Recuperation via list_digit_ INPI/INSEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for i in range(0,8):\n",
    "    test = pd.read_csv(\n",
    "        r'data\\input\\INPI\\special_treatment\\{}_special_treatment.gz'.format(i),\n",
    "                   low_memory=False)\n",
    "    print((test\n",
    " .loc[lambda x:\n",
    "      (x['list_digit_inpi'] == x['list_digit_insee'])\n",
    "     ]\n",
    "     )['siren'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#.assign(special_digit = lambda x:x['libelleVoieEtablissement'].str.findall(r\"(\\d+)\").apply(\n",
    "#        lambda x:'&'.join([i for i in x])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "inpi_col = ['siren',\n",
    "            'index',\n",
    "            'Type',\n",
    "            'Code_Postal',\n",
    "            'Ville',\n",
    "            'Code_Commune',\n",
    "            'Pays',\n",
    "            'count_initial_inpi',\n",
    "            'ncc',\n",
    "            'Adresse_new_clean_reg',\n",
    "           'INSEE',\n",
    "           'Date_Début_Activité',\n",
    "           'digit_inpi']\n",
    "\n",
    "inpi_dtype = {\n",
    "    'siren': 'object',\n",
    "    'index': 'int',\n",
    "    'Type': 'object',\n",
    "    'Code_Postal': 'object',\n",
    "    'Ville': 'object',\n",
    "    'Code_Commune': 'object',\n",
    "    'Pays': 'object',\n",
    "    'count_initial_inpi': 'int',\n",
    "    'ncc': 'object',\n",
    "    'Adresse_new_clean_reg': 'object',\n",
    "    'INSEE':'object',\n",
    "    'Date_Début_Activité':'object',\n",
    "    'digit_inpi':'object'\n",
    "}\n",
    "\n",
    "df_ets = r'data\\input\\inpi_etb_stock_{}.gz'.format(0)\n",
    "inpi = al_siret.import_dask(file=df_ets,\n",
    "                            usecols=inpi_col,\n",
    "                            dtype=inpi_dtype,\n",
    "                            parse_dates = False)\n",
    "    \n",
    "df_no_duplication, df_duplication = al_siret.step_one(\n",
    "    df_input=inpi,\n",
    "    left_on=list_possibilities[0]['match']['inpi'],\n",
    "    right_on=list_possibilities[0]['match']['insee']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_not_duplicate, sp = al_siret.step_two_duplication(df_duplication,\n",
    "                                                    var_group=list_possibilities[0]['match']['inpi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "sp[\"index\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dic_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "##### POUR LOG\n",
    "df_no_duplication.groupby('origin')['origin'].count()\n",
    "df_duplication.groupby('origin')['origin'].count()\n",
    "doublou_sur['index'].nunique()\n",
    "doublou_passur['index'].nunique()\n",
    "doublon.shape[0] - ( doublou_sur.shape[0] + doublou_passur.shape[0])\n",
    "pure_match['count_duplicates_final'].value_counts()\n",
    "pure_match['index'].nunique() + df_not_duplicate['index'].nunique() + sp['index'].nunique()\n",
    "inpi['index'].compute().nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_ets = r'data\\input\\inpi_etb_stock_7552898.gz'\n",
    "inpi = al_siret.import_dask(file=df_ets,\n",
    "                       usecols=inpi_col, dtype=inpi_dtype)\n",
    "\n",
    "df_nomatch = pd.DataFrame()\n",
    "df_input = inpi\n",
    "  \n",
    "total_match = pd.DataFrame()\n",
    "for i in [\n",
    "        ['ncc', 'libelleCommuneEtablissement'],\n",
    "        ['Code_Postal', 'codePostalEtablissement'],\n",
    "        ['Code_Commune', 'codeCommuneEtablissement']\n",
    "    ]:\n",
    "    df_input_ = al_siret.merge_siren_candidat(df_input=df_input,\n",
    "                                  option=i)\n",
    "\n",
    "    df_input = df_input_['unmatch']\n",
    "    total_match = total_match.append(df_input_['true_match'])\n",
    "\n",
    "    \n",
    "al_siret.match_unmatch(\n",
    "        df_inpi_initial= inpi.compute(),\n",
    "        df_inpi_mergeboth=total_match.drop(columns = '_merge'),\n",
    "        step='1_ville_cp_cc',\n",
    "        to_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "inpi_col = ['siren',\n",
    "            'index',\n",
    "            'Type',\n",
    "            'Adresse_Ligne1',\n",
    "            'Adresse_Ligne2',\n",
    "            'Adresse_Ligne3',\n",
    "            'Code_Postal',\n",
    "            'Ville',\n",
    "            'Code_Commune',\n",
    "            'Pays',\n",
    "            'count_initial_inpi',\n",
    "            'ncc',\n",
    "            'Adress_new',\n",
    "            'Adresse_new_clean_reg']\n",
    "\n",
    "inpi_dtype = {\n",
    "    'siren': 'object',\n",
    "    'index': 'int',\n",
    "    'Type': 'object',\n",
    "    'Adresse_Ligne1': 'object',\n",
    "    'Adresse_Ligne2': 'object',\n",
    "    'Adresse_Ligne3': 'object',\n",
    "    'Code_Postal': 'object',\n",
    "    'Ville': 'object',\n",
    "    'Code_Commune': 'object',\n",
    "    'Pays': 'object',\n",
    "    'count_initial_inpi': 'int',\n",
    "    'ncc': 'object',\n",
    "    'Adress_new': 'object',\n",
    "    'Adresse_new_clean_reg': 'object'\n",
    "}\n",
    "\n",
    "\n",
    "#df_nomatch = pd.DataFrame()\n",
    "df_match = pd.DataFrame()\n",
    "for chunk in [0,1\n",
    "              ,2,3,4,5,6,7,8,9, 10,11,12\n",
    "             ]:\n",
    "    csv_file = r'data\\input\\unmatched\\chunk\\chunk_{}.gz'.format(chunk)\n",
    "    inpi = al_siret.import_dask(file=csv_file,\n",
    "                       usecols=inpi_col, dtype=inpi_dtype)\n",
    "    df_input = inpi\n",
    "    total_match = pd.DataFrame()\n",
    "    for i in [\n",
    "        ['ncc', 'libelleCommuneEtablissement'],\n",
    "        ['Code_Postal', 'codePostalEtablissement'],\n",
    "        ['Code_Commune', 'codeCommuneEtablissement']\n",
    "    ]:\n",
    "        df_input_ = al_siret.merge_siren_candidat(df_input=df_input,\n",
    "                                      option=i,\n",
    "                                      regex_go = True)\n",
    "\n",
    "        df_input = df_input_['unmatch']\n",
    "        total_match = total_match.append(df_input_['true_match']) \n",
    "    #df_nomatch = df_nomatch.append(df_input)\n",
    "    df_match = df_match.append(total_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_temp = pd.DataFrame()\n",
    "for i in range(0,13):\n",
    "    csv_file = r'data\\input\\unmatched\\chunk\\chunk_{}.gz'.format(i)\n",
    "    df_temp = df_temp.append(pd.read_csv(csv_file,\n",
    "                                         dtype= inpi_dtype)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "299986 / 4979272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "al_siret.match_unmatch(\n",
    "        df_inpi_initial=df_temp,\n",
    "        df_inpi_mergeboth=df_match.drop(columns = '_merge'),\n",
    "        step='3_adress',\n",
    "        to_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### Matching voie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "inpi_col = ['siren',\n",
    "            'index',\n",
    "            'Type',\n",
    "            'Adresse_Ligne1',\n",
    "            'Adresse_Ligne2',\n",
    "            'Adresse_Ligne3',\n",
    "            'Code_Postal',\n",
    "            'Ville',\n",
    "            'Code_Commune',\n",
    "            'Pays',\n",
    "            'count_initial_inpi',\n",
    "            'ncc',\n",
    "            'Adress_new',\n",
    "            'Adresse_new_clean_reg']\n",
    "\n",
    "inpi_dtype = {\n",
    "    'siren': 'object',\n",
    "    'index': 'int',\n",
    "    'Type': 'object',\n",
    "    'Adresse_Ligne1': 'object',\n",
    "    'Adresse_Ligne2': 'object',\n",
    "    'Adresse_Ligne3': 'object',\n",
    "    'Code_Postal': 'object',\n",
    "    'Ville': 'object',\n",
    "    'Code_Commune': 'object',\n",
    "    'Pays': 'object',\n",
    "    'count_initial_inpi': 'int',\n",
    "    'ncc': 'object',\n",
    "    'Adress_new': 'object',\n",
    "    'Adresse_new_clean_reg': 'object'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#temp = al_siret.merge_siren_candidat(df_input=inpi,\n",
    "#                              regex_go=True, \n",
    "#                              matching_voie=True,\n",
    "#                              option=['ncc', 'libelleCommuneEtablissement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "inpi = al_siret.import_dask(file=r'data\\input\\unmatched\\unmatch_3_adress_299986.gz',\n",
    "                       usecols=inpi_col, dtype=inpi_dtype)\n",
    "df_input = inpi\n",
    "  \n",
    "total_match = pd.DataFrame()\n",
    "for i in [\n",
    "        ['ncc', 'libelleCommuneEtablissement'],\n",
    "        ['Code_Postal', 'codePostalEtablissement'],\n",
    "        ['Code_Commune', 'codeCommuneEtablissement']\n",
    "    ]:\n",
    "    df_input_ = al_siret.merge_siren_candidat(\n",
    "        df_input=df_input,\n",
    "        regex_go=True,\n",
    "        matching_voie=True,\n",
    "        option=i)\n",
    "\n",
    "    df_input = df_input_['unmatch']\n",
    "    total_match = total_match.append(df_input_['true_match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "al_siret.match_unmatch(\n",
    "        df_inpi_initial= inpi.compute(),\n",
    "        df_inpi_mergeboth=total_match.drop(columns = '_merge'),\n",
    "        step='4_voie',\n",
    "        to_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### Relax contrainte Regex\n",
    "\n",
    "Sans numero de voie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "inpi = al_siret.import_dask(file=r'data\\input\\unmatched\\unmatch_4_voie_167801.gz',\n",
    "                       usecols=inpi_col, dtype=inpi_dtype)\n",
    "df_input = inpi\n",
    "  \n",
    "total_match = pd.DataFrame()\n",
    "for i in [\n",
    "        ['ncc', 'libelleCommuneEtablissement'],\n",
    "        ['Code_Postal', 'codePostalEtablissement'],\n",
    "        ['Code_Commune', 'codeCommuneEtablissement']\n",
    "    ]:\n",
    "    df_input_ = al_siret.merge_siren_candidat(\n",
    "        df_input=df_input,\n",
    "        regex_go=True,\n",
    "        matching_voie=False,\n",
    "        relax_regex = True,\n",
    "        option=i)\n",
    "\n",
    "    df_input = df_input_['unmatch']\n",
    "    total_match = total_match.append(df_input_['true_match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "al_siret.match_unmatch(\n",
    "        df_inpi_initial= inpi.compute(),\n",
    "        df_inpi_mergeboth=total_match.drop(columns = '_merge'),\n",
    "        step='5_voie_relax',\n",
    "        to_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Avec la voie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "inpi_col = ['siren',\n",
    "            'index',\n",
    "            'Type',\n",
    "            'Adresse_Ligne1',\n",
    "            'Adresse_Ligne2',\n",
    "            'Adresse_Ligne3',\n",
    "            'Code_Postal',\n",
    "            'Ville',\n",
    "            'Code_Commune',\n",
    "            'Pays',\n",
    "            'count_initial_inpi',\n",
    "            'ncc',\n",
    "            'Adress_new',\n",
    "            'Adresse_new_clean_reg']\n",
    "\n",
    "inpi_dtype = {\n",
    "    'siren': 'object',\n",
    "    'index': 'int',\n",
    "    'Type': 'object',\n",
    "    'Adresse_Ligne1': 'object',\n",
    "    'Adresse_Ligne2': 'object',\n",
    "    'Adresse_Ligne3': 'object',\n",
    "    'Code_Postal': 'object',\n",
    "    'Ville': 'object',\n",
    "    'Code_Commune': 'object',\n",
    "    'Pays': 'object',\n",
    "    'count_initial_inpi': 'int',\n",
    "    'ncc': 'object',\n",
    "    'Adress_new': 'object',\n",
    "    'Adresse_new_clean_reg': 'object'\n",
    "}\n",
    "\n",
    "inpi = al_siret.import_dask(file=r'data\\input\\unmatched\\unmatch_5_relax_116575.gz',\n",
    "                       usecols=inpi_col, dtype=inpi_dtype)\n",
    "df_input = inpi\n",
    "  \n",
    "total_match = pd.DataFrame()\n",
    "for i in [\n",
    "        ['ncc', 'libelleCommuneEtablissement'],\n",
    "        ['Code_Postal', 'codePostalEtablissement'],\n",
    "        ['Code_Commune', 'codeCommuneEtablissement']\n",
    "    ]:\n",
    "    df_input_ = al_siret.merge_siren_candidat(\n",
    "        df_input=df_input,\n",
    "        regex_go=True,\n",
    "        matching_voie=True,\n",
    "        relax_regex = True,\n",
    "        option=i)\n",
    "\n",
    "    df_input = df_input_['unmatch']\n",
    "    total_match = total_match.append(df_input_['true_match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "inpi = al_siret.import_dask(file=r'data\\input\\unmatched\\unmatch_5_relax_116575.gz',\n",
    "                       usecols=inpi_col, dtype=inpi_dtype)\n",
    "check = al_siret.match_unmatch(\n",
    "        df_inpi_initial= inpi.compute(),\n",
    "        df_inpi_mergeboth=total_match.drop(columns = '_merge'),\n",
    "        step='6_voie_relax',\n",
    "        to_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "check['count_initial_inpi'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### Match etablissement principal ouvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "inpi_col = ['siren',\n",
    "            'index',\n",
    "            'Type',\n",
    "            'Adresse_Ligne1',\n",
    "            'Adresse_Ligne2',\n",
    "            'Adresse_Ligne3',\n",
    "            'Code_Postal',\n",
    "            'Ville',\n",
    "            'Code_Commune',\n",
    "            'Pays',\n",
    "            'count_initial_inpi',\n",
    "            'ncc',\n",
    "            'Adress_new',\n",
    "            'Adresse_new_clean_reg']\n",
    "\n",
    "inpi_dtype = {\n",
    "    'siren': 'object',\n",
    "    'index': 'int',\n",
    "    'Type': 'object',\n",
    "    'Adresse_Ligne1': 'object',\n",
    "    'Adresse_Ligne2': 'object',\n",
    "    'Adresse_Ligne3': 'object',\n",
    "    'Code_Postal': 'object',\n",
    "    'Ville': 'object',\n",
    "    'Code_Commune': 'object',\n",
    "    'Pays': 'object',\n",
    "    'count_initial_inpi': 'int',\n",
    "    'ncc': 'object',\n",
    "    'Adress_new': 'object',\n",
    "    'Adresse_new_clean_reg': 'object'\n",
    "}\n",
    "inpi = al_siret.import_dask(file=r'data\\input\\unmatched\\unmatch_6_voie_relax_112847.gz',\n",
    "                       usecols=inpi_col, dtype=inpi_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_input = inpi\n",
    "  \n",
    "total_match = pd.DataFrame()\n",
    "for i in [\n",
    "        ['ncc', 'libelleCommuneEtablissement'],\n",
    "        ['Code_Postal', 'codePostalEtablissement'],\n",
    "        ['Code_Commune', 'codeCommuneEtablissement']\n",
    "    ]:\n",
    "    df_input_ = al_siret.merge_siren_candidat(\n",
    "        df_input=df_input,\n",
    "        regex_go=True,\n",
    "        matching_voie=False,\n",
    "        relax_regex = True,\n",
    "        siege_etat=True,\n",
    "        option=i)\n",
    "\n",
    "    df_input = df_input_['unmatch']\n",
    "    total_match = total_match.append(df_input_['true_match'])\n",
    "    \n",
    "al_siret.match_unmatch(\n",
    "        df_inpi_initial= inpi.compute(),\n",
    "        df_inpi_mergeboth=total_match.drop(columns = '_merge'),\n",
    "        step='7_siege_ouvert',\n",
    "        to_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### Complement d adresse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "inpi_col = ['siren',\n",
    "            'index',\n",
    "            'Type',\n",
    "            'Adresse_Ligne1',\n",
    "            'Adresse_Ligne2',\n",
    "            'Adresse_Ligne3',\n",
    "            'Code_Postal',\n",
    "            'Ville',\n",
    "            'Code_Commune',\n",
    "            'Pays',\n",
    "            'count_initial_inpi',\n",
    "            'ncc',\n",
    "            'Adress_new',\n",
    "            'Adresse_new_clean_reg']\n",
    "\n",
    "inpi_dtype = {\n",
    "    'siren': 'object',\n",
    "    'index': 'int',\n",
    "    'Type': 'object',\n",
    "    'Adresse_Ligne1': 'object',\n",
    "    'Adresse_Ligne2': 'object',\n",
    "    'Adresse_Ligne3': 'object',\n",
    "    'Code_Postal': 'object',\n",
    "    'Ville': 'object',\n",
    "    'Code_Commune': 'object',\n",
    "    'Pays': 'object',\n",
    "    'count_initial_inpi': 'int',\n",
    "    'ncc': 'object',\n",
    "    'Adress_new': 'object',\n",
    "    'Adresse_new_clean_reg': 'object'\n",
    "}\n",
    "\n",
    "\n",
    "inpi = al_siret.import_dask(file=r'data\\input\\unmatched\\unmatch_7_siege_ouvert_85312.gz',\n",
    "                       usecols=inpi_col, dtype=inpi_dtype)\n",
    "df_input = inpi\n",
    "  \n",
    "total_match = pd.DataFrame()\n",
    "for i in [\n",
    "        ['ncc', 'libelleCommuneEtablissement'],\n",
    "        ['Code_Postal', 'codePostalEtablissement'],\n",
    "        ['Code_Commune', 'codeCommuneEtablissement']\n",
    "    ]:\n",
    "    df_input_ = al_siret.merge_siren_candidat(\n",
    "        df_input=df_input,\n",
    "        regex_go=True,\n",
    "        matching_voie=False,\n",
    "        relax_regex = True,\n",
    "        siege_etat=True,\n",
    "        option=i,\n",
    "        var_adress_insee = 'complementAdresseEtablissement')\n",
    "\n",
    "    df_input = df_input_['unmatch']\n",
    "    total_match = total_match.append(df_input_['true_match'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "al_siret.match_unmatch(\n",
    "        df_inpi_initial= inpi.compute(),\n",
    "        df_inpi_mergeboth=total_match.drop(columns = '_merge'),\n",
    "        step='8_siege_ouvert_complement',\n",
    "        to_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "1- (80474/4979272)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Test sans regex mais siege_etat\n",
    "\n",
    "ie si principale-ouvert dans la ville/CP/CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "inpi_col = ['siren',\n",
    "            'index',\n",
    "            'Type',\n",
    "            'Adresse_Ligne1',\n",
    "            'Adresse_Ligne2',\n",
    "            'Adresse_Ligne3',\n",
    "            'Code_Postal',\n",
    "            'Ville',\n",
    "            'Code_Commune',\n",
    "            'Pays',\n",
    "            'count_initial_inpi',\n",
    "            'ncc',\n",
    "            'Adress_new',\n",
    "            'Adresse_new_clean_reg']\n",
    "\n",
    "inpi_dtype = {\n",
    "    'siren': 'object',\n",
    "    'index': 'int',\n",
    "    'Type': 'object',\n",
    "    'Adresse_Ligne1': 'object',\n",
    "    'Adresse_Ligne2': 'object',\n",
    "    'Adresse_Ligne3': 'object',\n",
    "    'Code_Postal': 'object',\n",
    "    'Ville': 'object',\n",
    "    'Code_Commune': 'object',\n",
    "    'Pays': 'object',\n",
    "    'count_initial_inpi': 'int',\n",
    "    'ncc': 'object',\n",
    "    'Adress_new': 'object',\n",
    "    'Adresse_new_clean_reg': 'object'\n",
    "}\n",
    "\n",
    "\n",
    "inpi = al_siret.import_dask(file=r'data\\input\\unmatched\\unmatch_8_siege_ouvert_complement_80474.gz',\n",
    "                       usecols=inpi_col, dtype=inpi_dtype)\n",
    "df_input = inpi\n",
    "  \n",
    "total_match = pd.DataFrame()\n",
    "for i in [\n",
    "        ['ncc', 'libelleCommuneEtablissement'],\n",
    "        ['Code_Postal', 'codePostalEtablissement'],\n",
    "        ['Code_Commune', 'codeCommuneEtablissement']\n",
    "    ]:\n",
    "    df_input_ = al_siret.merge_siren_candidat(\n",
    "        df_input=df_input,\n",
    "        regex_go=False,\n",
    "        matching_voie=False,\n",
    "        relax_regex = False,\n",
    "        siege_etat=True,\n",
    "        option=i,\n",
    "        var_adress_insee = 'libelleVoieEtablissement')\n",
    "\n",
    "    df_input = df_input_['unmatch']\n",
    "    total_match = total_match.append(df_input_['true_match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "al_siret.match_unmatch(\n",
    "        df_inpi_initial= inpi.compute(),\n",
    "        df_inpi_mergeboth=total_match.drop(columns = '_merge'),\n",
    "        step='9_siege_ouvert_no_regex',\n",
    "        to_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "round(1 - (68131 / 4979272),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "# Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "inpi_col = ['siren',\n",
    "            'index',\n",
    "            'Type',\n",
    "            'Adresse_Ligne1',\n",
    "            'Adresse_Ligne2',\n",
    "            'Adresse_Ligne3',\n",
    "            'Code_Postal',\n",
    "            'Ville',\n",
    "            'Code_Commune',\n",
    "            'Pays',\n",
    "            'count_initial_inpi',\n",
    "            'ncc',\n",
    "            'Adress_new',\n",
    "            'Adresse_new_clean_reg']\n",
    "\n",
    "inpi_dtype = {\n",
    "    'siren': 'object',\n",
    "    'index': 'int',\n",
    "    'Type': 'object',\n",
    "    'Adresse_Ligne1': 'object',\n",
    "    'Adresse_Ligne2': 'object',\n",
    "    'Adresse_Ligne3': 'object',\n",
    "    'Code_Postal': 'object',\n",
    "    'Ville': 'object',\n",
    "    'Code_Commune': 'object',\n",
    "    'Pays': 'object',\n",
    "    'count_initial_inpi': 'int',\n",
    "    'ncc': 'object',\n",
    "    'Adress_new': 'object',\n",
    "    'Adresse_new_clean_reg': 'object'\n",
    "}\n",
    "\n",
    "\n",
    "inpi = al_siret.import_dask(file=r'data\\output\\match_9_siege_ouvert_no_regex_12343.gz',\n",
    "                       usecols=inpi_col, dtype=inpi_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "inpi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "inpi['Adresse_new_clean_reg'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Amelioration matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "insee_dtype = {\n",
    "    'siren': 'object',\n",
    "    'siret': 'object',\n",
    "    'dateCreationEtablissement': 'object',\n",
    "    \"etablissementSiege\": \"object\",\n",
    "    \"etatAdministratifEtablissement\": \"object\",\n",
    "    'complementAdresseEtablissement': 'object',\n",
    "    'numeroVoieEtablissement': 'object',\n",
    "    'indiceRepetitionEtablissement': 'object',\n",
    "    'typeVoieEtablissement': 'object',\n",
    "    'libelleVoieEtablissement': 'object',\n",
    "    'codePostalEtablissement': 'object',\n",
    "    'libelleCommuneEtablissement': 'object',\n",
    "    'libelleCommuneEtrangerEtablissement': 'object',\n",
    "    'distributionSpecialeEtablissement': 'object',\n",
    "    'codeCommuneEtablissement': 'object',\n",
    "    'codeCedexEtablissement': 'object',\n",
    "    'libelleCedexEtablissement': 'object',\n",
    "    'codePaysEtrangerEtablissement': 'object',\n",
    "    'libellePaysEtrangerEtablissement': 'object',\n",
    "    'count_initial_insee': 'int'\n",
    "}\n",
    "\n",
    "insee_col = ['siren',\n",
    "             'siret',\n",
    "             'dateCreationEtablissement',\n",
    "             \"etablissementSiege\",\n",
    "             \"etatAdministratifEtablissement\",\n",
    "             'complementAdresseEtablissement',\n",
    "             'numeroVoieEtablissement',\n",
    "             'indiceRepetitionEtablissement',\n",
    "             'typeVoieEtablissement',\n",
    "             'libelleVoieEtablissement',\n",
    "             'codePostalEtablissement',\n",
    "             'libelleCommuneEtablissement',\n",
    "             'libelleCommuneEtrangerEtablissement',\n",
    "             'distributionSpecialeEtablissement',\n",
    "             'codeCommuneEtablissement',\n",
    "             'codeCedexEtablissement',\n",
    "             'libelleCedexEtablissement',\n",
    "             'codePaysEtrangerEtablissement',\n",
    "             'libellePaysEtrangerEtablissement',\n",
    "             'count_initial_insee']\n",
    "inpi_col = ['siren',\n",
    "            'index',\n",
    "            'Type',\n",
    "            'Adresse_Ligne1',\n",
    "            'Adresse_Ligne2',\n",
    "            'Adresse_Ligne3',\n",
    "            'Code_Postal',\n",
    "            'Ville',\n",
    "            'Code_Commune',\n",
    "            'Pays',\n",
    "            'count_initial_inpi',\n",
    "            'ncc',\n",
    "            'Adress_new',\n",
    "            'Adresse_new_clean_reg']\n",
    "\n",
    "inpi_dtype = {\n",
    "    'siren': 'object',\n",
    "    'index': 'int',\n",
    "    'Type': 'object',\n",
    "    'Adresse_Ligne1': 'object',\n",
    "    'Adresse_Ligne2': 'object',\n",
    "    'Adresse_Ligne3': 'object',\n",
    "    'Code_Postal': 'object',\n",
    "    'Ville': 'object',\n",
    "    'Code_Commune': 'object',\n",
    "    'Pays': 'object',\n",
    "    'count_initial_inpi': 'int',\n",
    "    'ncc': 'object',\n",
    "    'Adress_new': 'object',\n",
    "    'Adresse_new_clean_reg': 'object'\n",
    "}\n",
    "\n",
    "insee = al_siret.import_dask(file=r'data\\input\\insee_2017_7480120.gz',\n",
    "                             usecols=insee_col, dtype=insee_dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "list(insee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#insee['etatAdministratifEtablissement'].value_counts().compute()\n",
    "inpi = al_siret.import_dask(file=r'data\\input\\unmatched\\unmatch_8_siege_ouvert_complement_80474.gz',\n",
    "                       usecols=inpi_col, dtype=inpi_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "inpi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "insee[\n",
    "    (insee['siren'].isin(['515226462']))\n",
    "#& (insee['libelleVoieEtablissement'].isin(['JACQUARD']))\n",
    "].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "inpi[inpi['siren'].isin(['515226462'])].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "inpi.loc[inpi['count_initial_inpi'].isin([1])].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "inpi.loc[inpi['siren'].isin(['322385949'])].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "inpi['Type'].value_counts().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "insee[insee['siren'].isin(['322385949'])].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Verification conservative:\n",
    "\n",
    "- A l'INSEE, si etatAdministratifEtablissement == A & etablissementSiege == True, alors on fait le sous ensemle\n",
    "- Verifier avec les dates de création de l'établissement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "insee.loc[\n",
    "            (insee['etablissementSiege'].isin(['true'])) \n",
    "            & (insee['etatAdministratifEtablissement'].isin(['A']))\n",
    "            ].compute() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "1 - (112847 / 4979272)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "amelioration possible:\n",
    "    \n",
    "- 381980788 -> Zone Artisanale du Creusât ->transformer en ZA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
