{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Test Matching Insee/ETS\n",
    "\n",
    "## INSEE\n",
    "\n",
    "- https://s3.console.aws.amazon.com/s3/object/calfdata/INSEE/Stock/ETS/\n",
    "        - INSEE/Stock/ETS/StockEtablissement_utf8.csv\n",
    "        \n",
    "```\n",
    "['siren', 'siret']\n",
    "```\n",
    "\n",
    "## INPI\n",
    "\n",
    "- https://s3.console.aws.amazon.com/s3/buckets/calfdata/INPI/TC_1/Stock_processed/\n",
    "    - INPI/TC_1/Stock_processed/initial_ETS.gz\n",
    "    - INPI/TC_1/Stock_processed/initial_ETS.json\n",
    "    \n",
    "Colonnes test:\n",
    "\n",
    "```\n",
    "[\"Siren\",\"Date_Immatriculation\", \"Date_Clôture\", \"Date_Greffe\"]\n",
    "```\n",
    "\n",
    "## Sauvegarde\n",
    "\n",
    "* La liste des SIREN matchés sera sauvegardée selon leur nature et origine\n",
    "  * nature → ACTES/COMPTES/ETS/etc\n",
    "  * origine → initial/partiel/new/evt\n",
    "\n",
    "Les matchés seront sauvegardé dans calfdata/SIRETISATION/matche/ au format suivant:\n",
    "\n",
    "* insee_nature_origine_matche.gz\n",
    "    * ex: insee_pm_initial_matche.gz\n",
    "    \n",
    "    \n",
    "\n",
    "## Moteur de recherche TEST\n",
    "\n",
    "* Insee\n",
    "  * http://avis-situation-sirene.insee.fr/IdentificationListeSiret.action\n",
    "* INPI/TC\n",
    "  * https://data.inpi.fr/\n",
    "* Infogreffe\n",
    "  * https://www.infogreffe.fr/\n",
    "\n",
    "\n",
    "Le siège ne donne pas de nouveau SIRET, il indique seulement le lieu de la juridiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import boto3, json\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "#import Match_inpi_insee.aws_connectors as aws\n",
    "#from tqdm.notebook import tqdm\n",
    "#import tqdm\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#instance_aws = 'https://calfdata.s3.eu-west-3.amazonaws.com'\n",
    "#bucket = 'calfdata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# instanciate AWS connection\n",
    "#AWS_connection = aws.aws_instantiate(instance_aws, bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Preparation fichiers\n",
    "\n",
    "## Matching établissement principal\n",
    "\n",
    "Ici, on filtre les variables communes pour l'INSEE & INPI établissements secondaires.\n",
    "\n",
    "### Candidats\n",
    "\n",
    "**INSEE**\n",
    "\n",
    "https://www.sirene.fr/sirene/public/static/liste-variables\n",
    "\n",
    "- numeroVoieEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/numeroVoieEtablissement\n",
    "- indiceRepetitionEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/indiceRepetitionEtablissement\n",
    "- typeVoieEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/typeVoieEtablissement\n",
    "- libelleVoieEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/libelleVoieEtablissement\n",
    "- complementAdresseEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/complementAdresseEtablissement\n",
    "- codeCommuneEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/codeCommuneEtablissement\n",
    "- libelleCommuneEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/libelleCommuneEtablissement\n",
    "- codePostalEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/codePostalEtablissement\n",
    "- codeCedexEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/codeCedexEtablissement\n",
    "- libelleCedexEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/libelleCedexEtablissement\n",
    "- distributionSpecialeEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/distributionSpecialeEtablissement\n",
    "- libelleCommuneEtrangerEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/libelleCommuneEtrangerEtablissement\n",
    "- codePaysEtrangerEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/codePaysEtrangerEtablissement\n",
    "- libellePaysEtrangerEtablissement: https://www.sirene.fr/sirene/public/static/liste-variables/libellePaysEtrangerEtablissement\n",
    "\n",
    "**INPI**\n",
    "\n",
    "- Adresse_Ligne1/Adresse_Ligne2/Adresse_Ligne3: Selon les greffes, l’adresse (n°+ voie) sera présente soit en ligne1 adresse, soit en ligne2 adresse.\n",
    "Toutes les lignes d’adresse ne sont pas nécessairement renseignées.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Créer fichier toutes les possibilités communes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "communes = (pd.read_csv('temp_local\\communes-01012019.csv')\n",
    "            .set_index('ncc').reindex(columns = ['nccenr', 'libelle']))#.unstack()\n",
    "communes.loc[lambda x: x['libelle'].isin(['Châtillon-sur-Chalaronne'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "communes = (pd.read_csv('temp_local\\communes-01012019.csv')\n",
    "            .set_index('ncc')\n",
    "            .reindex(columns=['nccenr', 'libelle'])\n",
    "            .assign(\n",
    "    noaccent=lambda x: x['nccenr'].str.normalize('NFKD')\n",
    "    .str.encode('ascii', errors='ignore')\n",
    "    .str.decode('utf-8'),\n",
    "    nccenr_noponc=lambda x: x['nccenr'].str.replace('[^\\w\\s]', ' '),\n",
    "    libelle_noponc=lambda x: x['libelle'].str.replace('[^\\w\\s]', ' '),\n",
    "    noaccent_noponc=lambda x: x['noaccent'].str.replace('[^\\w\\s]', ' '),\n",
    "    uppercase=lambda x: x.index,\n",
    "    nccenr_uppercase=lambda x: x['nccenr'].str.upper(),\n",
    "    libelle_uppercase=lambda x: x['libelle'].str.upper(),\n",
    "    noaccent_uppercase=lambda x: x['noaccent'].str.upper(),\n",
    "    nccenr_noponc_uppercase=lambda x: x['nccenr_noponc'].str.upper(),\n",
    "    libelle_noponc_uppercase=lambda x: x['libelle_noponc'].str.upper(),\n",
    "    noaccent_noponc_uppercase=lambda x: x['noaccent_noponc'].str.upper(),\n",
    "    nccenr_lowercase=lambda x: x['nccenr'].str.lower(),\n",
    "    libelle_lowercase=lambda x: x['libelle'].str.lower(),\n",
    "    noaccent_lowercase=lambda x: x['noaccent'].str.lower(),\n",
    "    nccenr_noponc_lowercase=lambda x: x['nccenr_noponc'].str.lower(),\n",
    "    libelle_noponc_lowercase=lambda x: x['libelle_noponc'].str.lower(),\n",
    "    noaccent_noponc_lowercase=lambda x: x['noaccent_noponc'].str.lower(),\n",
    "    nccenr_noarrond1=lambda x: x['nccenr'].str.replace(\n",
    "        'er Arrondissement', ''),\n",
    "    uppercase_noarrond1=lambda x: x['uppercase'].str.replace(\n",
    "        'ER ARRONDISSEMENT', ''),\n",
    "    lowercase_noarrond1=lambda x: x['nccenr_lowercase'].str.replace(\n",
    "        'er arrondissement', ''),\n",
    "    nccenr_noarrond=lambda x: x['nccenr'].str.replace('e Arrondissement', ''),\n",
    "    uppercase_noarrond=lambda x: x['uppercase'].str.replace(\n",
    "        'E ARRONDISSEMENT', ''),\n",
    "    lowercase_noarrond=lambda x: x['nccenr_lowercase'].str.replace(\n",
    "        'e arrondissement', ''),\n",
    ")\n",
    ")\n",
    "\n",
    "for n in communes.columns:\n",
    "    var_ = '{}_ST'.format(n)\n",
    "    var_1 = '{}_st'.format(n)\n",
    "    var_2 = '{}_St'.format(n)\n",
    "    \n",
    "    communes[var_] = communes[n].str.replace('SAINT', 'ST')\n",
    "    communes[var_1] = communes[n].str.replace('Saint', 'st')\n",
    "    communes[var_2] = communes[n].str.replace('Saint', 'St')\n",
    "    \n",
    "    var_ = '{}_Sbar'.format(n)\n",
    "    var_1 = '{}_sbar'.format(n)\n",
    "    \n",
    "    communes[var_] = communes[n].str.replace('SUR', 'S/')\n",
    "    communes[var_1] = communes[n].str.replace('sur', 's/')\n",
    "    \n",
    "communes = (communes\n",
    "            .stack()\n",
    "            .rename('possibilite')\n",
    "            .reset_index()\n",
    "            .drop(columns='level_1')\n",
    "            .drop_duplicates(subset=['possibilite']))\n",
    "communes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "communes.to_csv('data\\input\\communes_france.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#insee = AWS_connection.url_instance_bucket(path_file = 'INSEE/Stock/ETS/StockEtablissement_utf8.csv')\n",
    "#ets = AWS_connection.url_instance_bucket(path_file = 'INPI/TC_1/Stock_processed/initial_ETS.gz')\n",
    "#ets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "insee = r\"\\temp_local\\StockEtablissement_utf8.csv\"\n",
    "ets = r\"\\temp_local\\initial_ETS.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# load data into dataframes\n",
    "data_insee_ = dd.read_csv(insee,\n",
    "                          usecols=['siren',\n",
    "                                   'siret',\n",
    "                                   \"numeroVoieEtablissement\",\n",
    "                                   \"indiceRepetitionEtablissement\",\n",
    "                                   \"typeVoieEtablissement\",\n",
    "                                   \"libelleVoieEtablissement\",\n",
    "                                   \"complementAdresseEtablissement\",\n",
    "                                   \"codeCommuneEtablissement\",\n",
    "                                   \"libelleCommuneEtablissement\",\n",
    "                                   \"codePostalEtablissement\",\n",
    "                                   \"codeCedexEtablissement\",\n",
    "                                   \"libelleCedexEtablissement\",\n",
    "                                   \"distributionSpecialeEtablissement\",\n",
    "                                   \"libelleCommuneEtrangerEtablissement\",\n",
    "                                   \"codePaysEtrangerEtablissement\",\n",
    "                                   \"libellePaysEtrangerEtablissement\",\n",
    "                                   \"dateCreationEtablissement\"\n",
    "                                   ],\n",
    "                          dtype={'siren': 'object',\n",
    "                                 'siret': 'object',\n",
    "                                 \"numeroVoieEtablissement\":'object',\n",
    "                                   \"indiceRepetitionEtablissement\":'object',\n",
    "                                   \"typeVoieEtablissement\":'object',\n",
    "                                   \"libelleVoieEtablissement\":'object',\n",
    "                                   \"complementAdresseEtablissement\":'object',\n",
    "                                   \"codeCommuneEtablissement\":'object',\n",
    "                                   \"libelleCommuneEtablissement\":'object',\n",
    "                                   \"codePostalEtablissement\":'object',\n",
    "                                   \"codeCedexEtablissement\":'object',\n",
    "                                   \"libelleCedexEtablissement\":'object',\n",
    "                                   \"distributionSpecialeEtablissement\":'object',\n",
    "                                   \"libelleCommuneEtrangerEtablissement\":'object',\n",
    "                                   \"codePaysEtrangerEtablissement\":'object',\n",
    "                                   \"libellePaysEtrangerEtablissement\":'object'\n",
    "                                 }\n",
    "                          )\n",
    "\n",
    "data_ets_ = (dd.read_csv(ets,\n",
    "                         usecols=[\n",
    "                             'Type',\n",
    "                             'Siren',\n",
    "                             'Code_Postal',\n",
    "                             'Code_Commune',\n",
    "                             'Adresse_Ligne1',\n",
    "                             'Adresse_Ligne2',\n",
    "                             'Adresse_Ligne3',\n",
    "                             'Ville',\n",
    "                             'Pays'\n",
    "                         ],\n",
    "                         dtype={\n",
    "                             'Type': 'object',\n",
    "                             'Siren': 'object',\n",
    "                             'Code_Postal': 'object',\n",
    "                             'Code_Commune': 'object',\n",
    "                             'Adresse_Ligne1': 'object',\n",
    "                             'Adresse_Ligne2': 'object',\n",
    "                             'Adresse_Ligne3': 'object',\n",
    "                             'Ville':'object',\n",
    "                             'Pays':'object'\n",
    "                         },\n",
    "                         compression='gzip',\n",
    "                         blocksize=None,\n",
    "                         low_memory=False\n",
    "                         )\n",
    "             .compute()\n",
    "             .rename(columns={\"Siren\": \"siren\"})\n",
    "             .loc[lambda x: ~x['Type'].isin(['SIE'])]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data_insee_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data_ets_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "siren_inpi = data_ets_['siren'].drop_duplicates()\n",
    "len(siren_inpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "len(siren_inpi)/data_ets_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_insee = (data_insee_\n",
    "                .loc[data_insee_['siren'].isin(siren_inpi.to_list())]\n",
    "                .loc[data_insee_['dateCreationEtablissement'] <= \"2018-01-01\"]\n",
    "                .assign(\n",
    "                libelleCommuneEtablissement = lambda x:\n",
    "                    x['libelleCommuneEtablissement'].str.replace('-', ' ')\n",
    "                )\n",
    "                .compute()\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Siren INPI mais pas INSEE -> Cette entreprise a exercé son droit d'opposition auprès de l'INSEE. Ses données ne peuvent pas être diffusées publiquement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "temp insee - > gagner du temps pendant la periode de dév\n",
    "temp inpi - > gagner du temps pendant la periode de dév"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "siren_to_remove = siren_inpi.loc[lambda x : ~x.isin(subset_insee['siren'])]\n",
    "len(siren_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_siren_to_find = data_ets_.loc[lambda x:\n",
    "                                 (~x['siren'].isin(siren_to_remove))    \n",
    "                                 ]\n",
    "len(df_siren_to_find)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_siren_to_find.to_csv('temp_inpi.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Nan variables matching \n",
    "\n",
    "on exclue les variables avec que des nan dans les variables candidates\n",
    "\n",
    "-> on les traitera après"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "siren_fullna = df_siren_to_find.loc[lambda x:\n",
    "                      (x['Adresse_Ligne1'].isin([np.nan]))\n",
    "                     & (x['Adresse_Ligne2'].isin([np.nan]))\n",
    "                     & (x['Adresse_Ligne3'].isin([np.nan]))\n",
    "                     & (x['Code_Postal'].isin([np.nan]))\n",
    "                     & (x['Ville'].isin([np.nan]))\n",
    "                     & (x['Code_Commune'].isin([np.nan]))\n",
    "                     ]['siren']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_siren_to_find = df_siren_to_find.loc[lambda x:\n",
    "                                 (~x['siren'].isin(siren_fullna))\n",
    "                                 ]\n",
    "len(siren_fullna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Nombres d'ets par SIREN INSEE\n",
    "\n",
    "On calcule le nombre d'etb pour le fichier INSEE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_insee_count = subset_insee.merge(\n",
    "    (subset_insee\n",
    "     .groupby('siren')['siren']\n",
    "     .count()\n",
    "     .rename('count')\n",
    "     .reset_index())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_siren_to_find = df_siren_to_find.merge(\n",
    "    (df_siren_to_find\n",
    "     .groupby('siren')['siren']\n",
    "     .count()\n",
    "     .rename('count')\n",
    "     .reset_index()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_siren_to_find.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Insee enlever les tirets dans la ville"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def siren_unique(df):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    print(\"Nombre total obs: {}\".format(len(df)))\n",
    "    count_ = (df\n",
    "              .groupby('siren')['siren']\n",
    "              .count()\n",
    "              .rename('count')\n",
    "              .reset_index()\n",
    "              .groupby('count')['count']\n",
    "              .count()\n",
    "              .reset_index(name='total_count')\n",
    "              .set_index('count')\n",
    "              # .compute()\n",
    "              .assign(pct=lambda x: x/x.sum())\n",
    "              .iloc[:10, :]\n",
    "              .style\n",
    "              .format('{:,.2%}', subset=['pct'])\n",
    "              )\n",
    "    return count_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### SAuvegarde fichier pour test class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_siren_to_find = df_siren_to_find.rename(columns = \n",
    "                                           {'count': 'count_initial_inpi'})\n",
    "df_siren_to_find.assign(index = lambda x:x.index).to_csv('data\\input\\inpi_etb_{}.gz'.format(\n",
    "    df_siren_to_find.shape[0]),\n",
    "                        compression='gzip', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_insee_count = subset_insee_count.rename(columns = \n",
    "                                               {'count': 'count_initial_insee'})\n",
    "subset_insee_count.to_csv('data\\input\\insee_2017_{}.gz'.format(\n",
    "    subset_insee_count.shape[0]),\n",
    "                        compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Quick stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "siren_unique(df = subset_insee_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "siren_unique(df = df_siren_to_find)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 0: Clean ville\n",
    "\n",
    "Ajout matching des communes pour retrouver le libelé commune de l'INSEE\n",
    "\n",
    "ATTENTION, il faut nétoyer la variables ville dans l'INSEE. Veuillez regarder le fichier `communes.xlsx` pour voir les différents problèmes\n",
    "\n",
    "ex: \n",
    "- CEDEX, cedex, digit, (d+), \n",
    "\n",
    "attention, l'arrondissement peut être mis entre parenthèse \n",
    "\n",
    "- MARSEILLE (7E)\n",
    "\n",
    "- process:\n",
    "    - creer variables avec numeric seulement\n",
    "    - recreer ville 2 si test pas NAN pour avoir l'arrondissement\n",
    "    - virer les differentes informations dans ville via regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "regex = 'CEDEX|cedex|Cedex|\\([^)]*\\)|/\\s\\s+/|^\\d+\\s|\\s\\d+\\s|\\s\\d+$|\\d+|\\.|\\--|COMMUNE DE |COMMUNE DE|commune de |commune de|Commune de |Commune de |\\s$'\n",
    "test_adress = df_siren_to_find.copy()\n",
    "test_adress['test'] =test_adress['Ville'].str.extract(r'(\\d+)')\n",
    "test_adress['Ville_clean'] = test_adress['Ville'].str.replace(regex,'')\n",
    "test_adress['Ville_clean'] = test_adress['Ville_clean'].str.replace('\\s$|\\s^',\n",
    "                                                                    '')\n",
    "\n",
    "### arrondissement\n",
    "test_adress['ville2'] = np.where(\n",
    "    np.logical_and(\n",
    "         ~test_adress['test'].isin([np.nan]),\n",
    "        test_adress['test'].str.len() <=2\n",
    "    )\n",
    "   ,\n",
    "    test_adress['Ville_clean'] + '' + test_adress['test'].astype(str),\n",
    "    test_adress['Ville_clean']\n",
    ")\n",
    "\n",
    "test_adress['Ville_upper'] = test_adress['Ville_clean'].str.upper()\n",
    "\n",
    "test_adress = test_adress.merge(communes,\n",
    "                         left_on='ville2',\n",
    "                         right_on='possibilite',\n",
    "                         how='left',\n",
    "                         indicator=True)\n",
    "\n",
    "test_adress = pd.concat([\n",
    "    test_adress.loc[lambda x: x['_merge'].isin(['both'])],\n",
    "    (test_adress\n",
    "     .loc[lambda x: x['_merge'].isin(['left_only'])]\n",
    "     .drop(columns=['ncc', 'possibilite', '_merge'])\n",
    "     .merge(communes,\n",
    "            left_on='Ville_upper',\n",
    "            right_on='possibilite',\n",
    "            how='left',\n",
    "            indicator=True)\n",
    "     )\n",
    "])\n",
    "\n",
    "test_adress = pd.concat([\n",
    "    test_adress.loc[lambda x: x['_merge'].isin(['both'])],\n",
    "    (test_adress\n",
    "     .loc[lambda x: x['_merge'].isin(['left_only'])]\n",
    "     .drop(columns=['ncc', 'possibilite', '_merge'])\n",
    "     .assign(\n",
    "         noaccent=lambda x: x['Ville_clean'].str.normalize('NFKD')\n",
    "         .str.encode('ascii', errors='ignore')\n",
    "         .str.decode('utf-8'))\n",
    "     ).merge(communes,\n",
    "             left_on='noaccent',\n",
    "             right_on='possibilite',\n",
    "             how='left',\n",
    "             indicator=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "log_commune = {\n",
    "    \n",
    "    'total_match':[int(test_adress['_merge'].value_counts()['both']),\n",
    "                   float(test_adress['_merge'].value_counts()['both']/test_adress.shape[0])\n",
    "                  ],\n",
    "    'total_unmatch':[int(test_adress['_merge'].value_counts()['left_only']),\n",
    "                   float(test_adress['_merge'].value_counts()['left_only']/test_adress.shape[0])\n",
    "                  ],\n",
    "    'details_unmatch': {\n",
    "        'Code_Postal':int(test_adress.loc[lambda x: x['_merge'].isin(['left_only'])].isna().sum()[['Code_Postal']][0]),\n",
    "        'Code_Commune':int(test_adress.loc[lambda x: x['_merge'].isin(['left_only'])].isna().sum()[['Code_Commune']][0]),\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "log_commune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "with open(r'data\\logs\\commune.json', 'w') as outfile:\n",
    "                json.dump(log_commune, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "log_commune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress['_merge'].value_counts()['left_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress.loc[lambda x: x['_merge'].isin(['left_only'])].isna().sum()[['Code_Postal', 'Code_Commune']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress.loc[lambda x: (x['_merge'].isin(['left_only']) )\n",
    "               & (x['Code_Postal'].isin([np.nan]))\n",
    "               & (~x['Ville'].isin([np.nan]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "communes.loc[lambda x : x['possibilite'].isin(['NURIEUX'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "communes[communes['possibilite'].str.contains('LA VARENNE')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "communes[communes['ncc'].str.contains('SAINT RAMBERT EN BUGEY')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress = test_adress.drop(columns = '_merge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_insee_count.to_csv('subset_insee_count.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": false
   },
   "source": [
    "## Process\n",
    "\n",
    "On ne match que les SIREN dont la date de création est inférieur a 2018\n",
    "\n",
    "1) ~Step : Calculer le nombre de `nan` dans les colonnes de matching~\n",
    "\n",
    "2) ~Step : Compter le nombre de SIRET by SIREN~\n",
    "\n",
    "2) Step 2:  merge sur siren et code postal\n",
    "\n",
    "3) Step 3:  merge sur siren et code commune\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Step 1: Match uniquement les 1 dans INSEE/INPI\n",
    "\n",
    "On enlève les matches du dataframe `df_siren_to_find` et on ajoute les `left_only`.\n",
    "\n",
    "Pareil pour l'INSEE pour gagner en mémoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress = test_adress.drop(columns = ['test', 'Ville_clean', 'ville2', 'Ville_upper',\n",
    "        'possibilite', '_merge', 'noaccent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress[lambda x:x['ncc'].isin([np.nan])]['Ville'].drop_duplicates().to_excel('ville_pas_insee.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress.to_csv('data\\input\\inpi_etb_cleaned_{}.gz'.format(\n",
    "    test_adress.shape[0]),\n",
    "                        compression='gzip', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "## Il y a 4312053 établissements uniques dans l'INPI\n",
    "siren_unique(df = test_adress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar\n",
    "from dask.multiprocessing import get\n",
    "import re\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pbar = ProgressBar()\n",
    "pbar.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "insee_col = ['siren',\n",
    " 'siret',\n",
    " 'dateCreationEtablissement',\n",
    " 'complementAdresseEtablissement',\n",
    " 'numeroVoieEtablissement',\n",
    " 'indiceRepetitionEtablissement',\n",
    " 'typeVoieEtablissement',\n",
    " 'libelleVoieEtablissement',\n",
    " 'codePostalEtablissement',\n",
    " 'libelleCommuneEtablissement',\n",
    " 'libelleCommuneEtrangerEtablissement',\n",
    " 'distributionSpecialeEtablissement',\n",
    " 'codeCommuneEtablissement',\n",
    " 'codeCedexEtablissement',\n",
    " 'libelleCedexEtablissement',\n",
    " 'codePaysEtrangerEtablissement',\n",
    " 'libellePaysEtrangerEtablissement',\n",
    " 'count_initial_insee']\n",
    "\n",
    "inpi_col =['siren',\n",
    "           'index',\n",
    " 'Type',\n",
    " 'Adresse_Ligne1',\n",
    " 'Adresse_Ligne2',\n",
    " 'Adresse_Ligne3',\n",
    " 'Code_Postal',\n",
    " 'Ville',\n",
    " 'Code_Commune',\n",
    " 'Pays',\n",
    " 'count_initial_inpi',\n",
    " 'ncc']\n",
    "insee_dtype = {\n",
    "    'siren': 'object',\n",
    "    'siret': 'object',\n",
    "    'dateCreationEtablissement': 'object',\n",
    "    'complementAdresseEtablissement': 'object',\n",
    "    'numeroVoieEtablissement': 'object',\n",
    "    'indiceRepetitionEtablissement': 'object',\n",
    "    'typeVoieEtablissement': 'object',\n",
    "    'libelleVoieEtablissement': 'object',\n",
    "    'codePostalEtablissement': 'object',\n",
    "    'libelleCommuneEtablissement': 'object',\n",
    "    'libelleCommuneEtrangerEtablissement': 'object',\n",
    "    'distributionSpecialeEtablissement': 'object',\n",
    "    'codeCommuneEtablissement': 'object',\n",
    "    'codeCedexEtablissement': 'object',\n",
    "    'libelleCedexEtablissement': 'object',\n",
    "    'codePaysEtrangerEtablissement': 'object',\n",
    "    'libellePaysEtrangerEtablissement': 'object',\n",
    "    'count_initial_insee': 'int'\n",
    "}\n",
    "\n",
    "inpi_dtype = {\n",
    "    'siren': 'object',\n",
    "    'index':'int',\n",
    " 'Type': 'object',\n",
    " 'Adresse_Ligne1': 'object',\n",
    " 'Adresse_Ligne2': 'object',\n",
    " 'Adresse_Ligne3': 'object',\n",
    " 'Code_Postal': 'object',\n",
    " 'Ville': 'object',\n",
    " 'Code_Commune': 'object',\n",
    " 'Pays': 'object',\n",
    " 'count_initial_inpi': 'int',\n",
    " 'ncc': 'object',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def import_dask(file, usecols = None, dtype=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        dd_df = dd.read_csv(file, usecols = usecols, dtype = dtype,\n",
    "        blocksize=None,compression='gzip')\n",
    "\n",
    "        return dd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def match_unmatch(df_inpi_initial, df_inpi_mergeboth, step = '1_unique_siren',\n",
    "                  to_csv = True):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    merge_ = (\n",
    "        df_inpi_mergeboth\n",
    "        .merge(df_inpi_initial,\n",
    "               how='right',\n",
    "               indicator=True)\n",
    "    )\n",
    "    \n",
    "    match_ = merge_.loc[lambda x: \n",
    "                       x['_merge'].isin(['both'])].drop(columns = '_merge')\n",
    "    \n",
    "    unmatch_ = merge_.loc[lambda x: \n",
    "                       ~x['_merge'].isin(['both'])].drop(columns = ['_merge',\n",
    "                                                                    'siret'])\n",
    "    \n",
    "    \n",
    "    if to_csv:\n",
    "        name_match = 'data/output/match_{}_{}.gz'.format(step, match_.shape[0])\n",
    "        name_unmatch = 'data/input/unmatched/unmatch_{}_{}.gz'.format(\n",
    "            step, unmatch_.shape[0])\n",
    "        match_.to_csv(name_match, index = False, compression='gzip',)\n",
    "        unmatch_.to_csv(name_unmatch, index = False,compression='gzip')\n",
    "        \n",
    "    return unmatch_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def log_detail(df_, option = 'left_only'):\n",
    "    \"\"\"\n",
    "    option -> right_only ou left_only\n",
    "    \"\"\"\n",
    "    log_ = {\n",
    "    \n",
    "    'total_match':[int(df_['_merge'].value_counts()['both']),\n",
    "                   float(df_['_merge'].value_counts()['both']/df_.shape[0])\n",
    "                  ],\n",
    "    'total_unmatch':[int(df_['_merge'].value_counts()[option]),\n",
    "                   float(df_['_merge'].value_counts()[option]/df_.shape[0])\n",
    "                  ],\n",
    "    'details_unmatch': {\n",
    "        'Code_Postal':int(df_.loc[lambda x: x['_merge'].isin([option])].isna().sum()[['Code_Postal']][0]),\n",
    "        'Code_Commune':int(df_.loc[lambda x: x['_merge'].isin([option])].isna().sum()[['Code_Commune']][0]),\n",
    "    }\n",
    "}\n",
    "    return log_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def match_unique_etb(list_inpi):\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    insee = import_dask(file=r'data\\input\\insee_2017_7480120.gz',\n",
    "                        usecols=insee_col, dtype=insee_dtype)\n",
    "\n",
    "    inpi = import_dask(file=r'data\\input\\inpi_etb_cleaned_4979272.gz',\n",
    "                       usecols=inpi_col, dtype=inpi_dtype)\n",
    "\n",
    "    m1_unique = (\n",
    "        insee.loc[insee['count_initial_insee'].isin([1])]\n",
    "        .merge(inpi.loc[inpi['count_initial_inpi'].isin([1])],\n",
    "               how='right', indicator=True)\n",
    "    )\n",
    "\n",
    "    unmatched = match_unmatch(\n",
    "        df_inpi_initial=inpi.compute(),\n",
    "        df_inpi_mergeboth=(m1_unique.compute()\n",
    "                       .reindex(columns=list_inpi)\n",
    "                       .loc[lambda x:\n",
    "                            x['_merge'].isin(['both'])]\n",
    "                       .drop(columns=['_merge'])),\n",
    "        step='1_unique_siren',\n",
    "        to_csv=True)\n",
    "    \n",
    "    log_detail(test_adress1, option = 'right_only')\n",
    "    \n",
    "    return unmatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "list_inpi = [\n",
    "        'siren',\n",
    "             'siret',\n",
    "        'index',\n",
    "             'Type',\n",
    "             'Adresse_Ligne1',\n",
    "             'Adresse_Ligne2',\n",
    "             'Adresse_Ligne3',\n",
    "             'Code_Postal',\n",
    "             'Ville',\n",
    "             'Code_Commune',\n",
    "             'Pays',\n",
    "             'ncc',\n",
    "             '_merge']\n",
    "test_adress1 = match_unique_etb(list_inpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "log_detail(test_adress1, option = 'right_only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress1 = match_unmatch(\n",
    "            df_inpi_initial=test_adress,\n",
    "            df_inpi_merge=(test_adress1\n",
    "                           .reindex(columns=list_inpi)\n",
    "                           .loc[lambda x:\n",
    "                                x['_merge'].isin(['both'])]\n",
    "                           .drop(columns=['_merge'])),\n",
    "    step='1_unique_siren',\n",
    "    to_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "m1_unique = (\n",
    "    dd_df_insee.loc[dd_df_insee['count_initial_insee'].isin([1])]\n",
    "    .merge(dd_df_inpi.loc[dd_df_inpi['count_initial_inpi'].isin([1])],\n",
    "           how='right', indicator=True)\n",
    ")\n",
    "m1_unique.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Sur les 4312053 etbs uniques, on match 3009904 correctement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Pour recuperer les matchés, on filtre la base initiale -> a savoir `test_adress`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress1 = match_unmatch(\n",
    "    df_inpi_initial=test_adress,\n",
    "    df_inpi_merge=m1_unique.reindex(columns=list_inpi).loc[lambda x:\n",
    "                                         x['_merge'].isin(['both'])].drop(columns=['_merge']),\n",
    "    step='1_unique_siren',\n",
    "    to_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Conclusion step 1:\n",
    "\n",
    "- matched: 3009904\n",
    "- Unmatched: 1969368"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "siren_unique(df = test_adress1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Exemple de SIREN qui ont seulement une ligne dans l'INPI mais plusieurs SIRET dans l'INSEE.\n",
    "\n",
    "- 813543063\n",
    "- 800897092"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress1.loc[lambda x: x['count'] ==1].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_insee_count.loc[lambda x: x['siren'].isin(['813543063'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_insee_count.loc[lambda x: x['siren'].isin(['800897092'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_insee_count.isna().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress.isna().sum().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Step 2: Merging \n",
    "\n",
    "Dans cette partie, on va merger sur plusieurs candidats. La plupart des SIREN peuvent être matché via le code postal, code commune, ou ville directement. Si un SIREN a plusieurs SIRET dans la même ville ou code postal, il fera l'objet d'une recherche plus poussée.\n",
    "\n",
    "Trois cas de figure découle du merge:\n",
    "\n",
    "- 1) Merge forte pertinence\n",
    "- 2) merge pertinence moyenne -> plusieurs SIRET pour un même candidat\n",
    "- 3) Unmerge\n",
    "\n",
    "#### 1:  merge sur siren et Ville\n",
    "\n",
    "- Merge sur siren & libelleCommuneEtablissement|Ville_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_nomatch = pd.DataFrame()\n",
    "df_input = import_dask(file=r'data\\input\\unmatched\\unmatch_1_unique_siren_1969368.gz',\n",
    "                       usecols=inpi_col, dtype=inpi_dtype)\n",
    "  \n",
    "total_match = pd.DataFrame()\n",
    "for i in [\n",
    "        ['ncc', 'libelleCommuneEtablissement'],\n",
    "        ['Code_Postal', 'codePostalEtablissement'],\n",
    "        ['Code_Commune', 'codeCommuneEtablissement']\n",
    "    ]:\n",
    "    df_input_ = merge_siren_candidat(df_input=df_input,\n",
    "                                  option=i)\n",
    "\n",
    "    df_input = df_input_['unmatch']\n",
    "    total_match = total_match.append(df_input_['true_match'])\n",
    "\n",
    "    \n",
    "match_unmatch(\n",
    "        df_inpi_initial= import_dask(file=r'data\\input\\unmatched\\unmatch_1_unique_siren_1969368.gz',\n",
    "                       usecols=inpi_col, dtype=inpi_dtype).compute(),\n",
    "        df_inpi_mergeboth=total_match.drop(columns = '_merge'),\n",
    "        step='1_ville_cp_cc',\n",
    "        to_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "list(df_input.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "total_match.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "total_match.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "list_inpi = ['siren',\n",
    "                 'siret',\n",
    "                 'Type',\n",
    "                 'Adresse_Ligne1',\n",
    "                 'Adresse_Ligne2',\n",
    "                 'Adresse_Ligne3',\n",
    "                 'Code_Postal',\n",
    "                 'Ville',\n",
    "                 'Code_Commune',\n",
    "                 'Pays',\n",
    "                 'test',\n",
    "                 'Ville_clean',\n",
    "                 'ville2',\n",
    "                 'ncc',\n",
    "                 'possibilite',\n",
    "                 'noaccent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def merge_siren_candidat(df_input, \n",
    "                         option=['ncc', 'libelleCommuneEtablissement']):\n",
    "    \"\"\"\n",
    "    option list can only be one of these:\n",
    "    - ['ncc', 'libelleCommuneEtablissement']\n",
    "    - ['ncc', 'libelleCommuneEtablissement']\n",
    "    - ['ncc', 'libelleCommuneEtablissement']\n",
    "    \"\"\"\n",
    "    insee = import_dask(file=r'data\\input\\insee_2017_7480120.gz',\n",
    "                        usecols=insee_col, dtype=insee_dtype)\n",
    "    \n",
    "    if '_merge' in df_input.columns:\n",
    "        df_input = (df_input\n",
    "                    .drop(columns=['siret',\n",
    "                                   'numeroVoieEtablissement',\n",
    "                                   'libelleVoieEtablissement',\n",
    "                                   'codePostalEtablissement',\n",
    "                                   'libelleCommuneEtablissement',\n",
    "                                   'codeCommuneEtablissement',\n",
    "                                   '_merge']))\n",
    "\n",
    "    temp = df_input.merge(insee,\n",
    "                          how='left',\n",
    "                          left_on=['siren', option[0]],\n",
    "                          right_on=['siren',  option[1]],\n",
    "                          indicator=True,\n",
    "                          suffixes=['_insee', '_inpi'])\n",
    "\n",
    "    to_check = temp[temp['_merge'].isin(['both'])]\n",
    "    nomatch = temp[~temp['_merge'].isin(['both'])]\n",
    "    \n",
    "    to_check = to_check.compute()\n",
    "\n",
    "    # calcul le nombre cas de figure 2 -> très conservative\n",
    "    test_match = (to_check\n",
    "                  .merge(\n",
    "                      (to_check\n",
    "                       .groupby(['siren', option[1]])['siren']\n",
    "                       .count()\n",
    "                       .rename('count')\n",
    "                       .reset_index()\n",
    "                       )\n",
    "                  )\n",
    "                  )\n",
    "\n",
    "    true_match = (test_match\n",
    "                  .loc[lambda x:x['count'] == 1]\n",
    "                  .reindex(columns=list_inpi))\n",
    "\n",
    "    name_csv = r'Data\\output\\{}_true_match_{}.csv'.format(\n",
    "        option[0], true_match.shape[0])\n",
    "\n",
    "    true_match.to_csv(name_csv, index=False)\n",
    "\n",
    "    dic_ = {\n",
    "        'true_match': true_match,\n",
    "        'unmatch': nomatch\n",
    "    }\n",
    "\n",
    "    return dic_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test = test_adress1.merge(subset_insee_count,\n",
    "                   how='left',\n",
    "                   left_on=['siren', 'ncc'],\n",
    "                   right_on=['siren', 'libelleCommuneEtablissement'],\n",
    "                   indicator=True,\n",
    "                   suffixes=['_insee', '_inpi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test['_merge'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "### calcul le nombre cas de figure 2 -> très conservative\n",
    "test_match = (test.loc[lambda x: x['_merge'].isin(['both'])]\n",
    "              .merge(\n",
    "                  (test.loc[lambda x: x['_merge'].isin(['both'])]\n",
    "            .groupby(['siren', 'libelleCommuneEtablissement'])['siren']\n",
    "            .count()\n",
    "            .rename('count')\n",
    "            .reset_index()\n",
    "                  )\n",
    "              )\n",
    ")\n",
    "test_match['count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress2 = match_unmatch(\n",
    "    df_inpi_initial=test_adress1,\n",
    "    df_inpi_mergeboth=(test_match\n",
    "                       .loc[lambda x: x['count'].isin([1])]\n",
    "                   .reindex(columns=list_inpi).loc[lambda x:\n",
    "                                         x['_merge'].isin(['both'])]\n",
    "                   .drop(columns = ['count','_merge'])),\n",
    "    step='2_ville',\n",
    "    to_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress2.shape[0] + test_match['count'].value_counts().loc[1] == test_adress1.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### 2:  merge sur siren et code postal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test = test_adress2.merge(subset_insee_count,\n",
    "                   how='left',\n",
    "                   left_on=['siren', 'Code_Postal'],\n",
    "                   right_on=['siren', 'codePostalEtablissement'],\n",
    "                   indicator=True,\n",
    "                   suffixes=['_insee', '_inpi'])\n",
    "test['_merge'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "### calcul le nombre cas de figure 2 -> très conservative\n",
    "test_match = (test.loc[lambda x: x['_merge'].isin(['both'])]\n",
    "              .merge(\n",
    "                  (test.loc[lambda x: x['_merge'].isin(['both'])]\n",
    "            .groupby(['siren', 'codePostalEtablissement'])['siren']\n",
    "            .count()\n",
    "            .rename('count')\n",
    "            .reset_index()\n",
    "                  )\n",
    "              )\n",
    ")\n",
    "test_match['count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress3 = match_unmatch(\n",
    "    df_inpi_initial=test_adress2,\n",
    "    df_inpi_mergeboth=(test_match\n",
    "                       .loc[lambda x: x['count'].isin([1])]\n",
    "                   .reindex(columns=list_inpi).loc[lambda x:\n",
    "                                         x['_merge'].isin(['both'])]\n",
    "                   .drop(columns = ['count','_merge'])),\n",
    "    step='3_codePostal',\n",
    "    to_csv=True)\n",
    "test_adress3.shape[0] + test_match['count'].value_counts().loc[1] == test_adress2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 3:  merge sur siren et code commune\n",
    "\n",
    "- Merge sur siren & codeCommuneEtablissement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test = test_adress3.merge(subset_insee_count,\n",
    "                   how='left',\n",
    "                   left_on=['siren', 'Code_Commune'],\n",
    "                   right_on=['siren', 'codeCommuneEtablissement'],\n",
    "                   indicator=True,\n",
    "                   suffixes=['_insee', '_inpi'])\n",
    "test['_merge'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "### calcul le nombre cas de figure 2 -> très conservative\n",
    "test_match = (test.loc[lambda x: x['_merge'].isin(['both'])]\n",
    "              .merge(\n",
    "                  (test.loc[lambda x: x['_merge'].isin(['both'])]\n",
    "            .groupby(['siren', 'codeCommuneEtablissement'])['siren']\n",
    "            .count()\n",
    "            .rename('count')\n",
    "            .reset_index()\n",
    "                  )\n",
    "              )\n",
    ")\n",
    "test_match['count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_match['count'].value_counts().loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress4 = match_unmatch(\n",
    "    df_inpi_initial=test_adress3,\n",
    "    df_inpi_mergeboth=(test_match\n",
    "                       .loc[lambda x: x['count'].isin([1])]\n",
    "                   .reindex(columns=list_inpi).loc[lambda x:\n",
    "                                         x['_merge'].isin(['both'])]\n",
    "                   .drop(columns = ['count','_merge'])),\n",
    "    step='4_codecommune',\n",
    "    to_csv=True)\n",
    "test_adress4.shape[0] + test_match['count'].value_counts().loc[1] == test_adress3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress4.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Créer code loop step 1/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Match adresse\n",
    "\n",
    "Il reste 14% des siren a matcher avec l'adresse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "### Total a matcher avant ville/code postal/commune\n",
    "test_adress4.shape[0] / test_adress.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Match avec adresse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "On selectionne uniquement ceux pas matché.\n",
    "Pour accélerer la recherche, on utilise que le sous ensemble de siren a vérifier dans le fichier INSEE\n",
    "\n",
    "Verifier si on peut matcher avec le numéro de l'adresse -> au cas ou principal et secondaire dans le même endroit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Il faut retravailler les adresses:\n",
    "\n",
    "- Upper case\n",
    "\n",
    "La recherche se fait sur le libellé adresse. Dans l'INSEE, pas de numéro de voie, ni de typologie (rue, avenue, etc)\n",
    "\n",
    "ALL: Allée\n",
    "AV: Avenue\n",
    "BD: Boulevard\n",
    "CAR: Carrefour\n",
    "CHE: Chemin\n",
    "CHS: Chaussée\n",
    "CITE: Cité\n",
    "COR: Corniche\n",
    "CRS: Cours\n",
    "DOM: Domaine\n",
    "DSC: Descente\n",
    "ECA: Ecart\n",
    "ESP: Esplanade\n",
    "FG: Faubourg\n",
    "GR: Grande Rue\n",
    "HAM: Hameau\n",
    "HLE: Halle\n",
    "IMP: Impasse\n",
    "LD: Lieu dit\n",
    "LOT: Lotissement\n",
    "MAR: Marché\n",
    "MTE: Montée\n",
    "PAS: Passage\n",
    "PL: Place\n",
    "PLN: Plaine\n",
    "PLT: Plateau\n",
    "PRO: Promenade\n",
    "PRV: Parvis\n",
    "QUA: Quartier\n",
    "QUAI: Quai\n",
    "RES: Résidence\n",
    "RLE: Ruelle\n",
    "ROC: Rocade\n",
    "RPT: Rond Point\n",
    "RTE: Route\n",
    "RUE: Rue\n",
    "SEN: Sente - Sentier\n",
    "SQ: Square\n",
    "TPL: Terre-plein\n",
    "TRA: Traverse\n",
    "VLA: Villa\n",
    "VLGE: Village"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "additional = [\"Avenue\",\n",
    "\"Boulevard\",\n",
    "\"Carrefour\",\n",
    "\"Chemin\",\n",
    "\"Chaussee\",\n",
    "\"Cite\",\n",
    "\"Corniche\",\n",
    "\"Cours\",\n",
    "\"Domaine\",\n",
    "\"Descente\",\n",
    "\"Ecart\",\n",
    "\"Esplanade\",\n",
    "\"Faubourg\",\n",
    "\"Grande Rue\",\n",
    "\"Hameau\",\n",
    "\"Halle\",\n",
    "\"Impasse\",\n",
    "\"Lieu dit\",\n",
    "\"Lotissement\",\n",
    "\"Marche\",\n",
    "\"Montee\",\n",
    "\"Passage\",\n",
    "\"Place\",\n",
    "\"Plaine\",\n",
    "\"Plateau\",\n",
    "\"Promenade\",\n",
    "\"Parvis\",\n",
    "\"Quartier\",\n",
    "\"Quai\",\n",
    "\"Residence\",\n",
    "\"Ruelle\",\n",
    "\"Rocade\",\n",
    "\"Rond Point\",\n",
    "\"Route\",\n",
    "\"Rue\",\n",
    "\"Sentier\",\n",
    "\"Square\",\n",
    "\"Terre plein\",\n",
    "\"Traverse\",\n",
    "\"Villa\",\n",
    "\"Village\", 'Rn',\n",
    "'bp', 'cedex', 'Bis',\n",
    "'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N',\n",
    "'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('french')\n",
    "stop_words.extend(additional)\n",
    "upper_stop = [i.upper() for i in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pd.Series(upper_stop).to_csv('upper_stop.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#pd.read_csv('upper_stop.csv').iloc[:,0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def create_split_adress(x):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    split_ = x.str.split().to_list()\n",
    "    return  split_\n",
    "\n",
    "\n",
    "def create_regex_adress(x):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        split_ = [i + \"$\" for i in x]\n",
    "        reg = '|'.join(split_)\n",
    "    except:\n",
    "        reg = np.nan\n",
    "    return  reg\n",
    "\n",
    "import re\n",
    "\n",
    "def find_regex(regex, test_str, siret):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        matches = re.search(regex, test_str)\n",
    "        if matches:\n",
    "            return siret\n",
    "        else:\n",
    "            return np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def prepare_adress(df):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    temp_adresse = df.compute().assign(\n",
    "    \n",
    "        Adress_new = lambda x: \n",
    "        x['Adresse_Ligne1'].fillna('') + ' '+\\\n",
    "        x['Adresse_Ligne2'].fillna('') + ' '+\\\n",
    "        x['Adresse_Ligne3'].fillna(''),\n",
    "        Adresse_new_clean=lambda x: x['Adress_new'].str.normalize(\n",
    "            'NFKD')\n",
    "        .str.encode('ascii', errors='ignore')\n",
    "        .str.decode('utf-8')\n",
    "        .str.replace('[^\\w\\s]|\\d+', ' ')\n",
    "        .str.upper(),\n",
    "\n",
    "    )\n",
    "    temp_adresse['Adresse_new_clean'] = (temp_adresse['Adresse_new_clean']\n",
    "                                            .apply(lambda x:\n",
    "                                                   ' '.join([word for word in\n",
    "                                                             str(x).split() if\n",
    "                                                             word not in \n",
    "                                                             (upper_stop)]))\n",
    "                                            )\n",
    "                                            \n",
    "    temp_adresse = temp_adresse.assign(\n",
    "        Adresse_new_clean_split=lambda x:\n",
    "        create_split_adress(x['Adresse_new_clean'])\n",
    "    )\n",
    "\n",
    "    temp_adresse['Adresse_new_clean_reg'] = \\\n",
    "    temp_adresse['Adresse_new_clean_split'].apply(lambda x:\n",
    "                                                     create_regex_adress(x))\n",
    "    \n",
    "    temp_adresse = temp_adresse.drop(columns = ['Adresse_new_clean',\n",
    "                                                'Adresse_new_clean_split'])\n",
    "    \n",
    "    chunks = split(city_, 60000)\n",
    "    try:\n",
    "        for i in range(0, 10):\n",
    "            chunks[i].to_csv(\n",
    "            r'Data\\input\\unmatched\\chunk\\chunk_{}.gz'.format(i),\n",
    "                index = False, compression ='gzip')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Creer des fichiers intermediaires pour éviter prob memoire\n",
    "\n",
    "Pour accelerer le code, on utilise uniquement les adresses sans les na et on filtre l'insee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#http://yaoyao.codes/pandas/2018/01/23/pandas-split-a-dataframe-into-chunks\n",
    "def index_marks(nrows, chunk_size):\n",
    "    return range(1 * chunk_size, (nrows // chunk_size + 1) * chunk_size, chunk_size)\n",
    "\n",
    "def split(dfm, chunk_size):\n",
    "    indices = index_marks(dfm.shape[0], chunk_size)\n",
    "    return np.split(dfm, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "POur acceleter le calcul, on convertit la df en Dask et on fait un map partition\n",
    "\n",
    "Penser a garder NCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar\n",
    "from dask.multiprocessing import get\n",
    "import re\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pbar = ProgressBar()\n",
    "pbar.register()\n",
    "\n",
    "\n",
    "\n",
    "# load data into dataframes\n",
    "subset_insee_count = dd.read_csv('subset_insee_count.csv',\n",
    "                          usecols=['siren',\n",
    "            'siret',\n",
    "            'libelleCommuneEtablissement',\n",
    "            'libelleVoieEtablissement',\n",
    "            'numeroVoieEtablissement',\n",
    "                                   'codePostalEtablissement',\n",
    "                                   'codeCommuneEtablissement'\n",
    "                                   ],\n",
    "                          dtype={'siren': 'object',\n",
    "                                 'siret': 'object',\n",
    "                                 \"libelleCommuneEtablissement\":'object',\n",
    "                                   \"libelleVoieEtablissement\":'object',\n",
    "                                   \"numeroVoieEtablissement\":'object',\n",
    "                                 'codePostalEtablissement':'object',\n",
    "                                 'codeCommuneEtablissement':'object'\n",
    "                                 }\n",
    "                          )\n",
    "\n",
    "def find_regex(regex, test_str, siret):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        matches = re.search(regex, test_str)\n",
    "        if matches:\n",
    "            return siret\n",
    "        else:\n",
    "            return np.nan\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "insee = import_dask(file=r'data\\input\\insee_2017_7480120.gz',\n",
    "                        usecols=insee_col, dtype=insee_dtype)\n",
    "\n",
    "inpi = import_dask(file=r'data\\input\\unmatched\\unmatch_1_ville_cp_cc_744141.gz',\n",
    "                       usecols=inpi_col, dtype=inpi_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_adress4 = pd.read_csv(r'data\\Unmatch\\unmatch_4_codecommune_703641.gz',\n",
    "                          compression='gzip',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "prepare_adress(inpi)#.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "chunks = split(city_, 60000)\n",
    "try:\n",
    "    for i in range(0, 10):\n",
    "        chunks[i].to_csv(\n",
    "        r'Data\\Unmatch\\chunk\\chunk_{}.csv'.format(i), index = False)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def prepare_csvAdress(df_input, option=['ncc', 'libelleCommuneEtablissement'],\n",
    "                      chunk=0,constraint_regex = True):\n",
    "    \"\"\"\n",
    "    option list can only be one of these:\n",
    "    - ['ncc', 'libelleCommuneEtablissement']\n",
    "    - ['ncc', 'libelleCommuneEtablissement']\n",
    "    - ['ncc', 'libelleCommuneEtablissement']\n",
    "    \"\"\"\n",
    "\n",
    "    list_inpi = ['siren',\n",
    "                 'siret',\n",
    "                 'Type',\n",
    "                 'Adresse_Ligne1',\n",
    "                 'Adresse_Ligne2',\n",
    "                 'Adresse_Ligne3',\n",
    "                 'Code_Postal',\n",
    "                 'Ville',\n",
    "                 'Code_Commune',\n",
    "                 'Pays',\n",
    "                 'test',\n",
    "                 'Ville_clean',\n",
    "                 'ville2',\n",
    "                 'ncc',\n",
    "                 'possibilite',\n",
    "                 'noaccent']\n",
    "    if '_merge' in df_input.columns:\n",
    "        df_input = (df_input\n",
    "                    .drop(columns=['siret',\n",
    "                                   'numeroVoieEtablissement',\n",
    "                                   'libelleVoieEtablissement',\n",
    "                                   'codePostalEtablissement',\n",
    "                                   'libelleCommuneEtablissement',\n",
    "                                   'codeCommuneEtablissement',\n",
    "                                   '_merge']))\n",
    "\n",
    "    temp = df_input.merge(subset_insee_count,\n",
    "                          how='left',\n",
    "                          left_on=['siren', option[0]],\n",
    "                          right_on=['siren',  option[1]],\n",
    "                          indicator=True,\n",
    "                          suffixes=['_insee', '_inpi'])\n",
    "\n",
    "    to_check = temp[temp['_merge'].isin(['both'])]\n",
    "    nomatch = temp[~temp['_merge'].isin(['both'])]\n",
    "    \n",
    "    if constraint_regex ==False:\n",
    "\n",
    "        to_check['Adresse_new_clean_reg'] = \\\n",
    "        to_check['Adresse_new_clean_reg'].str.replace('$', '')\n",
    "    # test\n",
    "    # to_check = to_check.dropna(subset = ['libelleVoieEtablissement'])\n",
    "    to_check['siret_test1'] = to_check.map_partitions(\n",
    "        lambda df:\n",
    "        df.apply(lambda x:\n",
    "                 find_regex(\n",
    "                     x['Adresse_new_clean_reg'],\n",
    "                     x['libelleVoieEtablissement'],\n",
    "                     x['siret']), axis=1)\n",
    "    )\n",
    "\n",
    "    to_check = to_check.dropna(subset=['siret_test1']).compute()\n",
    "\n",
    "    # calcul le nombre cas de figure 2 -> très conservative\n",
    "    test_match = (to_check\n",
    "                  .merge(\n",
    "                      (to_check\n",
    "                       .groupby(['siren', 'Adress_new'])['siren']\n",
    "                       .count()\n",
    "                       .rename('count')\n",
    "                       .reset_index()\n",
    "                       )\n",
    "                  )\n",
    "                  )\n",
    "    print(test_match['count'].value_counts())\n",
    "    true_match = (test_match\n",
    "                  .loc[lambda x:x['count'] == 1]\n",
    "                  .reindex(columns=list_inpi))\n",
    "\n",
    "    name_csv = r'Data\\\\Match\\chunk\\{}\\{}_true_match_{}.csv'.format(\n",
    "        option[0], chunk, true_match.shape[0])\n",
    "\n",
    "    true_match.to_csv(name_csv, index=False)\n",
    "\n",
    "    dic_ = {\n",
    "        'true_match': true_match,\n",
    "        'unmatch': nomatch\n",
    "    }\n",
    "\n",
    "    return dic_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def merge_siren_candidat(df_input, regex_go = False,\n",
    "                         option=['ncc', 'libelleCommuneEtablissement']):\n",
    "    \"\"\"\n",
    "    option list can only be one of these:\n",
    "    - ['ncc', 'libelleCommuneEtablissement']\n",
    "    - ['ncc', 'libelleCommuneEtablissement']\n",
    "    - ['ncc', 'libelleCommuneEtablissement']\n",
    "    \"\"\"\n",
    "    insee = import_dask(file=r'data\\input\\insee_2017_7480120.gz',\n",
    "                        usecols=insee_col, dtype=insee_dtype)\n",
    "    \n",
    "    if '_merge' in df_input.columns:\n",
    "        df_input = (df_input\n",
    "                    .drop(columns=['siret',\n",
    "                                   'numeroVoieEtablissement',\n",
    "                                   'libelleVoieEtablissement',\n",
    "                                   'codePostalEtablissement',\n",
    "                                   'libelleCommuneEtablissement',\n",
    "                                   'codeCommuneEtablissement',\n",
    "                                   '_merge']))\n",
    "\n",
    "    temp = df_input.merge(insee,\n",
    "                          how='left',\n",
    "                          left_on=['siren', option[0]],\n",
    "                          right_on=['siren',  option[1]],\n",
    "                          indicator=True,\n",
    "                          suffixes=['_insee', '_inpi'])\n",
    "\n",
    "    to_check = temp[temp['_merge'].isin(['both'])]\n",
    "    nomatch = temp[~temp['_merge'].isin(['both'])]\n",
    "    \n",
    "    if regex_go:\n",
    "        to_check['siret_test1'] = to_check.map_partitions(\n",
    "        lambda df:\n",
    "        df.apply(lambda x:\n",
    "                 find_regex(\n",
    "                     x['Adresse_new_clean_reg'],\n",
    "                     x['libelleVoieEtablissement'],\n",
    "                     x['siret']), axis=1)\n",
    "    )\n",
    "        to_check = to_check.dropna(subset=['siret_test1']).compute()\n",
    "        group_option = 'Adress_new'\n",
    "    else:\n",
    "        group_option = option[1]\n",
    "        to_check = to_check.compute()\n",
    "\n",
    "    # calcul le nombre cas de figure 2 -> très conservative\n",
    "    test_match = (to_check\n",
    "                  .merge(\n",
    "                      (to_check\n",
    "                       .groupby(['siren', group_option])['siren']\n",
    "                       .count()\n",
    "                       .rename('count')\n",
    "                       .reset_index()\n",
    "                       )\n",
    "                  )\n",
    "                  )\n",
    "\n",
    "    true_match = (test_match\n",
    "                  .loc[lambda x:x['count'] == 1]\n",
    "                  .reindex(columns=list_inpi))\n",
    "\n",
    "    name_csv = r'Data\\output\\{}_true_match_{}.csv'.format(\n",
    "        option[0], true_match.shape[0])\n",
    "\n",
    "    true_match.to_csv(name_csv, index=False)\n",
    "\n",
    "    dic_ = {\n",
    "        'true_match': true_match,\n",
    "        'unmatch': nomatch\n",
    "    }\n",
    "\n",
    "    return dic_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "insee_col = ['siren',\n",
    "             'siret',\n",
    "             'dateCreationEtablissement',\n",
    "             'complementAdresseEtablissement',\n",
    "             'numeroVoieEtablissement',\n",
    "             'indiceRepetitionEtablissement',\n",
    "             'typeVoieEtablissement',\n",
    "             'libelleVoieEtablissement',\n",
    "             'codePostalEtablissement',\n",
    "             'libelleCommuneEtablissement',\n",
    "             'libelleCommuneEtrangerEtablissement',\n",
    "             'distributionSpecialeEtablissement',\n",
    "             'codeCommuneEtablissement',\n",
    "             'codeCedexEtablissement',\n",
    "             'libelleCedexEtablissement',\n",
    "             'codePaysEtrangerEtablissement',\n",
    "             'libellePaysEtrangerEtablissement',\n",
    "             'count_initial_insee']\n",
    "\n",
    "inpi_col = ['siren',\n",
    "            'index',\n",
    "            'Type',\n",
    "            'Adresse_Ligne1',\n",
    "            'Adresse_Ligne2',\n",
    "            'Adresse_Ligne3',\n",
    "            'Code_Postal',\n",
    "            'Ville',\n",
    "            'Code_Commune',\n",
    "            'Pays',\n",
    "            'count_initial_inpi',\n",
    "            'ncc',\n",
    "            'Adress_new',\n",
    "            'Adresse_new_clean_reg']\n",
    "insee_dtype = {\n",
    "    'siren': 'object',\n",
    "    'siret': 'object',\n",
    "    'dateCreationEtablissement': 'object',\n",
    "    'complementAdresseEtablissement': 'object',\n",
    "    'numeroVoieEtablissement': 'object',\n",
    "    'indiceRepetitionEtablissement': 'object',\n",
    "    'typeVoieEtablissement': 'object',\n",
    "    'libelleVoieEtablissement': 'object',\n",
    "    'codePostalEtablissement': 'object',\n",
    "    'libelleCommuneEtablissement': 'object',\n",
    "    'libelleCommuneEtrangerEtablissement': 'object',\n",
    "    'distributionSpecialeEtablissement': 'object',\n",
    "    'codeCommuneEtablissement': 'object',\n",
    "    'codeCedexEtablissement': 'object',\n",
    "    'libelleCedexEtablissement': 'object',\n",
    "    'codePaysEtrangerEtablissement': 'object',\n",
    "    'libellePaysEtrangerEtablissement': 'object',\n",
    "    'count_initial_insee': 'int'\n",
    "}\n",
    "\n",
    "inpi_dtype = {\n",
    "    'siren': 'object',\n",
    "    'index': 'int',\n",
    "    'Type': 'object',\n",
    "    'Adresse_Ligne1': 'object',\n",
    "    'Adresse_Ligne2': 'object',\n",
    "    'Adresse_Ligne3': 'object',\n",
    "    'Code_Postal': 'object',\n",
    "    'Ville': 'object',\n",
    "    'Code_Commune': 'object',\n",
    "    'Pays': 'object',\n",
    "    'count_initial_inpi': 'int',\n",
    "    'ncc': 'object',\n",
    "    'Adress_new': 'object',\n",
    "    'Adresse_new_clean_reg': 'object'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "csv_file = r'data\\input\\unmatched\\chunk\\chunk_{}.gz'.format(chunk)\n",
    "inpi = import_dask(file=csv_file,\n",
    "                       usecols=inpi_col, dtype=inpi_dtype)\n",
    "merge_siren_candidat(df_input=inpi,\n",
    "                     option=['ncc', 'libelleCommuneEtablissement'],\n",
    "                     regex_go = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "inpi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_nomatch = pd.DataFrame()\n",
    "df_match = pd.DataFrame()\n",
    "for chunk in [0,\n",
    "              1\n",
    "              #,2,3,4,5,6,7,8,9\n",
    "             ]:\n",
    "    csv_file = r'data\\input\\unmatched\\chunk\\chunk_{}.gz'.format(chunk)\n",
    "    inpi = import_dask(file=csv_file,\n",
    "                       usecols=inpi_col, dtype=inpi_dtype)\n",
    "    df_input = inpi\n",
    "    total_match = pd.DataFrame()\n",
    "    for i in [\n",
    "        ['ncc', 'libelleCommuneEtablissement'],\n",
    "        ['Code_Postal', 'codePostalEtablissement'],\n",
    "        ['Code_Commune', 'codeCommuneEtablissement']\n",
    "    ]:\n",
    "        df_input_ = merge_siren_candidat(df_input=df_input,\n",
    "                                      option=i,\n",
    "                                      find_regex = True)\n",
    "\n",
    "        df_input = df_input_['unmatch']\n",
    "        total_match = total_match.append(df_input_['true_match'])\n",
    "    \n",
    "    test_adress2 = match_unmatch(\n",
    "        df_inpi_initial=inpi.computes(),\n",
    "        df_inpi_mergeboth=total_match,\n",
    "        step='3_adress_{}'.format(chunk),\n",
    "        to_csv=False)\n",
    "    \n",
    "    df_nomatch = df_nomatch.append(test_adress2)\n",
    "    df_match = df_match.append(total_match)\n",
    "\n",
    "\n",
    "#name_csv = r'Data\\Unmatch\\chunk\\{}\\{}_to_check.csv'.format(\n",
    "#    'adress_only', 0)\n",
    "#df_input_['unmatch'].compute().to_csv(name_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_nomatch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_nomatch.shape[0] / 4312053"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df_nomatch.loc[lambda x:x['siren'].isin(['388239667'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#subset_insee_count = subset_insee_count.compute()\n",
    "#subset_insee_count.loc[lambda x:x['siren'].isin(['388239667'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#subset_insee_count.loc[lambda x:x['siren'].isin(['388239667'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Match avec numero de rue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_nomatch = df_nomatch.drop(columns = 'digit_inpi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def match_voie(df_input, option=['ncc', 'libelleCommuneEtablissement'],\n",
    "              constraint_regex = True):\n",
    "    \"\"\"\n",
    "    option list can only be one of these:\n",
    "    - ['ncc', 'libelleCommuneEtablissement']\n",
    "    - ['ncc', 'libelleCommuneEtablissement']\n",
    "    - ['ncc', 'libelleCommuneEtablissement']\n",
    "    \"\"\"\n",
    "    \n",
    "    # load data into dataframes\n",
    "    subset_insee_count = dd.read_csv('subset_insee_count.csv',\n",
    "                          usecols=['siren',\n",
    "            'siret',\n",
    "            'libelleCommuneEtablissement',\n",
    "            'libelleVoieEtablissement',\n",
    "            'numeroVoieEtablissement',\n",
    "                                   'codePostalEtablissement',\n",
    "                                   'codeCommuneEtablissement'\n",
    "                                   ],\n",
    "                          dtype={'siren': 'object',\n",
    "                                 'siret': 'object',\n",
    "                                 \"libelleCommuneEtablissement\":'object',\n",
    "                                   \"libelleVoieEtablissement\":'object',\n",
    "                                   \"numeroVoieEtablissement\":'object',\n",
    "                                 'codePostalEtablissement':'object',\n",
    "                                 'codeCommuneEtablissement':'object'\n",
    "                                 }\n",
    "                          )\n",
    "\n",
    "    list_inpi = ['siren',\n",
    "                 'siret',\n",
    "                 'Type',\n",
    "                 'Adresse_Ligne1',\n",
    "                 'Adresse_Ligne2',\n",
    "                 'Adresse_Ligne3',\n",
    "                 'Code_Postal',\n",
    "                 'Ville',\n",
    "                 'Code_Commune',\n",
    "                 'Pays',\n",
    "                 'test',\n",
    "                 'Ville_clean',\n",
    "                 'ville2',\n",
    "                 'ncc',\n",
    "                 'possibilite',\n",
    "                 'noaccent']\n",
    "    if '_merge' in df_input.columns:\n",
    "        df_input = (df_input\n",
    "                    .drop(columns=['siret',\n",
    "                                   'numeroVoieEtablissement',\n",
    "                                   'libelleVoieEtablissement',\n",
    "                                   'codePostalEtablissement',\n",
    "                                   'libelleCommuneEtablissement',\n",
    "                                   'codeCommuneEtablissement',\n",
    "                                    #'count_inpi', \n",
    "                                   #'count',\n",
    "                                   'count_insee',\n",
    "                                   '_merge']))\n",
    "\n",
    "    # Calculer le nombre de SIRET par SIREN a l'INSEE\n",
    "    # Exemple SIREN 750767907\n",
    "    subset_insee_count = subset_insee_count.merge(\n",
    "        (subset_insee_count\n",
    "         .groupby('siren')['siren']\n",
    "         .count()\n",
    "         .rename('count_insee')\n",
    "         .reset_index())\n",
    "    )\n",
    "    \n",
    "    temp = df_input.merge(subset_insee_count,\n",
    "                          how='left',\n",
    "                          left_on=['siren', option[0]],\n",
    "                          right_on=['siren',  option[1]],\n",
    "                          indicator=True,\n",
    "                          suffixes=['_insee', '_inpi'])\n",
    "\n",
    "    to_check = temp[temp['_merge'].isin(['both'])]\n",
    "    nomatch = temp[~temp['_merge'].isin(['both'])]\n",
    "    \n",
    "    if constraint_regex ==False:\n",
    "        to_check['Adresse_new_clean_reg'] = \\\n",
    "        to_check['Adresse_new_clean_reg'].str.replace('$', '')\n",
    "\n",
    "    to_check['siret_test1'] = to_check.map_partitions(\n",
    "        lambda df:\n",
    "        df.apply(lambda x:\n",
    "                 find_regex(\n",
    "                     x['Adresse_new_clean_reg'],\n",
    "                     x['libelleVoieEtablissement'],\n",
    "                     x['siret']), axis=1)\n",
    "    )\n",
    "    \n",
    "   \n",
    "    to_check = to_check.dropna(subset=['siret_test1']).compute()\n",
    "    to_check['digit_inpi'] = to_check['Adress_new'].str.extract(r'(\\d+)')\n",
    "    \n",
    "\n",
    "    # test\n",
    "    # to_check = to_check.dropna(subset = ['libelleVoieEtablissement'])\n",
    "    to_check['test'] = np.where(\n",
    "        to_check['digit_inpi'] ==\n",
    "        to_check['numeroVoieEtablissement'],\n",
    "        True, False\n",
    "    )\n",
    "    \n",
    "    to_check = to_check[to_check['test'].isin([True])]\n",
    "\n",
    "    # calcul le nombre cas de figure 2 -> très conservative\n",
    "    test_match = (to_check\n",
    "                  .merge(\n",
    "                      (to_check\n",
    "                       .groupby(['siren', 'numeroVoieEtablissement'])['siren']\n",
    "                       .count()\n",
    "                       .rename('count_inpi')\n",
    "                       .reset_index()\n",
    "                       )\n",
    "                  )\n",
    "                  )\n",
    "    print(test_match['count_inpi'].value_counts())\n",
    "    ### Si nb siret insee == 1 mais inpi pas 1, c'est tout de meme un SIRET \n",
    "    ### identique\n",
    "    ### test realise sur data 2017\n",
    "    #2    478\n",
    "    #3      9\n",
    "    #6      6\n",
    "    true_match = (test_match\n",
    "                  .loc[lambda x:\n",
    "                       (x['count_inpi'] == 1)\n",
    "                      |\n",
    "                      (x['count_insee'].isin([1])\n",
    "                      & ~x['count_inpi'].isin([1]))]\n",
    "                  .reindex(columns=list_inpi))\n",
    "\n",
    "    name_csv = r'Data\\Match\\numero\\{}\\voie_match_{}_{}.csv'.format(\n",
    "        option[0], str(constraint_regex),true_match.shape[0])\n",
    "\n",
    "    true_match.to_csv(name_csv, index=False)\n",
    "\n",
    "    dic_ = {\n",
    "        'true_match': true_match,\n",
    "        'unmatch': nomatch\n",
    "    }\n",
    "\n",
    "    return dic_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_nomatch.to_csv(r'data\\Unmatch\\06_voie.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "unmatch_adress = dd.read_csv(r'data\\Unmatch\\06_voie.csv',dtype={\n",
    "                    'siren':'object',\n",
    "                                     'Code_Postal':'object',\n",
    "                                     'Adress_new':'object',\n",
    "                                     'Adresse_new_clean_reg':'object',\n",
    "                                     'Type':'object',\n",
    "                                     'Adresse_Ligne1':'object',\n",
    "                                     'Adresse_Ligne2':'object',\n",
    "                                     'Adresse_Ligne3':'object',\n",
    "                                     'Ville':'object',\n",
    "                                     'Code_Commune':'object',\n",
    "                                     'Pays':'object',\n",
    "                                     'test':'object',\n",
    "                                     'Ville_clean':'object',\n",
    "                                     'ville2':'object',\n",
    "                                     'ncc':'object',\n",
    "                                     'possibilite':'object',\n",
    "                                     'noaccent':'object',\n",
    "                                     'Adress_new':'object',\n",
    "                                     'Adresse_new_clean_reg':'object'\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Exemple SIREN/SIRET matché uniquement avec le digit. Pas matché avant a cause des fautes\n",
    "\n",
    "- 798126694"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_nomatch = pd.DataFrame()\n",
    "df_input = unmatch_adress\n",
    "  \n",
    "total_match = pd.DataFrame()\n",
    "for i in [\n",
    "        ['ncc', 'libelleCommuneEtablissement'],\n",
    "        ['Code_Postal', 'codePostalEtablissement'],\n",
    "        ['Code_Commune', 'codeCommuneEtablissement']\n",
    "    ]:\n",
    "    df_input_ = match_voie(df_input=df_input,\n",
    "                                  option=i)\n",
    "\n",
    "    df_input = df_input_['unmatch']\n",
    "    total_match = total_match.append(df_input_['true_match'])\n",
    "    \n",
    "df_nomatch = match_unmatch(\n",
    "        df_inpi_initial=unmatch_adress.drop(columns = ['test', 'count']).compute(),\n",
    "        df_inpi_mergeboth=total_match.drop(columns = 'test'),\n",
    "        step='6_voie_true',\n",
    "        to_csv=True)\n",
    "\n",
    "#name_csv = r'Data\\Unmatch\\chunk\\{}\\{}_to_check.csv'.format(\n",
    "#    'adress_only', 0)\n",
    "#df_input_['unmatch'].compute().to_csv(name_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "list(unmatch_adress.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "list(total_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_nomatch = match_unmatch(\n",
    "        df_inpi_initial=unmatch_adress.drop(columns = ['test', 'count']).compute(),\n",
    "        df_inpi_mergeboth=total_match.drop(columns = 'test'),\n",
    "        step='6_voie_true',\n",
    "        to_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_nomatch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_nomatch.shape[0] / 4312053"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_nomatch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_nomatch['siren'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Exemple amélioration matching\n",
    "\n",
    "enlever la contrainte sur le regex\n",
    "\n",
    "- 306168568"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_insee_count.compute().loc[lambda x:x['siren'].isin(['331455691'])]\n",
    "df_nomatch.loc[lambda x:x['siren'].isin(['331455691'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_nomatch.loc[lambda x:x['siren'].isin(['331455691'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Enlever la contrainte regex\n",
    "\n",
    "Deux tests:\n",
    "\n",
    "- Sans numéro de voie\n",
    "- Avec numéro de voie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Sans numéro de voie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def test_(df_input, option=['ncc', 'libelleCommuneEtablissement'],\n",
    "              constraint_regex = True):\n",
    "    \"\"\"\n",
    "    option list can only be one of these:\n",
    "    - ['ncc', 'libelleCommuneEtablissement']\n",
    "    - ['ncc', 'libelleCommuneEtablissement']\n",
    "    - ['ncc', 'libelleCommuneEtablissement']\n",
    "    \"\"\"\n",
    "    \n",
    "    # load data into dataframes\n",
    "    subset_insee_count = dd.read_csv('subset_insee_count.csv',\n",
    "                          usecols=['siren',\n",
    "            'siret',\n",
    "            'libelleCommuneEtablissement',\n",
    "            'libelleVoieEtablissement',\n",
    "            'numeroVoieEtablissement',\n",
    "                                   'codePostalEtablissement',\n",
    "                                   'codeCommuneEtablissement'\n",
    "                                   ],\n",
    "                          dtype={'siren': 'object',\n",
    "                                 'siret': 'object',\n",
    "                                 \"libelleCommuneEtablissement\":'object',\n",
    "                                   \"libelleVoieEtablissement\":'object',\n",
    "                                   \"numeroVoieEtablissement\":'object',\n",
    "                                 'codePostalEtablissement':'object',\n",
    "                                 'codeCommuneEtablissement':'object'\n",
    "                                 }\n",
    "                          )\n",
    "\n",
    "    list_inpi = ['siren',\n",
    "                 'siret',\n",
    "                 'Type',\n",
    "                 'Adresse_Ligne1',\n",
    "                 'Adresse_Ligne2',\n",
    "                 'Adresse_Ligne3',\n",
    "                 'Code_Postal',\n",
    "                 'Ville',\n",
    "                 'Code_Commune',\n",
    "                 'Pays',\n",
    "                 'test',\n",
    "                 'Ville_clean',\n",
    "                 'ville2',\n",
    "                 'ncc',\n",
    "                 'possibilite',\n",
    "                 'noaccent']\n",
    "    if '_merge' in df_input.columns:\n",
    "        df_input = (df_input\n",
    "                    .drop(columns=['siret',\n",
    "                                   'numeroVoieEtablissement',\n",
    "                                   'libelleVoieEtablissement',\n",
    "                                   'codePostalEtablissement',\n",
    "                                   'libelleCommuneEtablissement',\n",
    "                                   'codeCommuneEtablissement',\n",
    "                                    #'count_inpi', \n",
    "                                   #'count',\n",
    "                                   'count_insee',\n",
    "                                   '_merge']))\n",
    "\n",
    "    # Calculer le nombre de SIRET par SIREN a l'INSEE\n",
    "    # Exemple SIREN 750767907\n",
    "    subset_insee_count = subset_insee_count.merge(\n",
    "        (subset_insee_count\n",
    "         .groupby('siren')['siren']\n",
    "         .count()\n",
    "         .rename('count_insee')\n",
    "         .reset_index())\n",
    "    )\n",
    "    \n",
    "    temp = df_input.merge(subset_insee_count,\n",
    "                          how='left',\n",
    "                          left_on=['siren', option[0]],\n",
    "                          right_on=['siren',  option[1]],\n",
    "                          indicator=True,\n",
    "                          suffixes=['_insee', '_inpi'])\n",
    "    \n",
    "\n",
    "    to_check = temp[temp['_merge'].isin(['both'])]\n",
    "    nomatch = temp[~temp['_merge'].isin(['both'])]\n",
    "    \n",
    "    if constraint_regex ==False:\n",
    "\n",
    "        to_check['Adresse_new_clean_reg'] = \\\n",
    "        to_check['Adresse_new_clean_reg'].str.replace('$', '')\n",
    "        \n",
    "    \n",
    "\n",
    "    to_check['siret_test1'] = to_check.map_partitions(\n",
    "        lambda df:\n",
    "        df.apply(lambda x:\n",
    "                 find_regex(\n",
    "                     x['Adresse_new_clean_reg'],\n",
    "                     x['libelleVoieEtablissement'],\n",
    "                     x['siret']), axis=1)\n",
    "    )\n",
    "    \n",
    "    to_check = to_check.dropna(subset=['siret_test1']).compute()\n",
    "\n",
    "    # test\n",
    "    # calcul le nombre cas de figure 2 -> très conservative\n",
    "    test_match = (to_check\n",
    "                  .merge(\n",
    "                      (to_check\n",
    "                       .groupby(['siren', 'Adress_new'])['siren']\n",
    "                       .count()\n",
    "                       .rename('count_inpi')\n",
    "                       .reset_index()\n",
    "                       )\n",
    "                  )\n",
    "                  )\n",
    "    print(test_match['count_inpi'].value_counts())\n",
    "    ### Si nb siret insee == 1 mais inpi pas 1, c'est tout de meme un SIRET \n",
    "    ### identique\n",
    "    ### test realise sur data 2017\n",
    "    #2    478\n",
    "    #3      9\n",
    "    #6      6\n",
    "    true_match = (test_match\n",
    "                  .loc[lambda x:\n",
    "                       x['count_inpi'] == 1]\n",
    "                  .reindex(columns=list_inpi))\n",
    "\n",
    "    name_csv = r'Data\\Match\\numero\\{}\\voie_match_{}_{}.csv'.format(\n",
    "        option[0], str(constraint_regex),true_match.shape[0])\n",
    "\n",
    "    true_match.to_csv(name_csv, index=False)\n",
    "\n",
    "    dic_ = {\n",
    "        'true_match': true_match,\n",
    "        'unmatch': nomatch\n",
    "    }\n",
    "\n",
    "    return dic_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "unmatch_adress = dd.read_csv(r'C:\\Users\\PERNETTH\\Documents\\Projects\\InseeInpi_matching\\Notebooks_matching\\data\\Unmatch\\unmatch_6_voie_true_105782.gz',dtype={\n",
    "                    'siren':'object',\n",
    "                                     'Code_Postal':'object',\n",
    "                                     'Adress_new':'object',\n",
    "                                     'Adresse_new_clean_reg':'object',\n",
    "                                     'Type':'object',\n",
    "                                     'Adresse_Ligne1':'object',\n",
    "                                     'Adresse_Ligne2':'object',\n",
    "                                     'Adresse_Ligne3':'object',\n",
    "                                     'Ville':'object',\n",
    "                                     'Code_Commune':'object',\n",
    "                                     'Pays':'object',\n",
    "                                     'Ville_clean':'object',\n",
    "                                     'ville2':'object',\n",
    "                                     'ncc':'object',\n",
    "                                     'possibilite':'object',\n",
    "                                     'noaccent':'object',\n",
    "                                     'Adress_new':'object',\n",
    "                                     'Adresse_new_clean_reg':'object'\n",
    "            },compression='gzip', blocksize=None)\n",
    "\n",
    "df_nomatch = pd.DataFrame()\n",
    "df_input = unmatch_adress\n",
    "  \n",
    "total_match = pd.DataFrame()\n",
    "for i in [\n",
    "        ['ncc', 'libelleCommuneEtablissement'],\n",
    "        ['Code_Postal', 'codePostalEtablissement'],\n",
    "        ['Code_Commune', 'codeCommuneEtablissement']\n",
    "    ]:\n",
    "    df_input_ = test_(df_input=df_input,\n",
    "                                  option=i,\n",
    "                          constraint_regex = False)\n",
    "\n",
    "    df_input = df_input_['unmatch']\n",
    "    total_match = total_match.append(df_input_['true_match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "unmatch_adress.compute().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "total_match.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_nomatch = match_unmatch(\n",
    "        df_inpi_initial=unmatch_adress.compute(),\n",
    "        df_inpi_mergeboth=total_match,\n",
    "        step='6_voie_false_1',\n",
    "        to_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_nomatch.shape[0]/4312053"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### avec numero de voie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def test_2(\n",
    "    df_input, option=[\"ncc\", \"libelleCommuneEtablissement\"], constraint_regex=True\n",
    "):\n",
    "    \"\"\"\n",
    "    option list can only be one of these:\n",
    "    - ['ncc', 'libelleCommuneEtablissement']\n",
    "    - ['ncc', 'libelleCommuneEtablissement']\n",
    "    - ['ncc', 'libelleCommuneEtablissement']\n",
    "    \"\"\"\n",
    "\n",
    "    # load data into dataframes\n",
    "    subset_insee_count = dd.read_csv(\n",
    "        \"subset_insee_count.csv\",\n",
    "        usecols=[\n",
    "            \"siren\",\n",
    "            \"siret\",\n",
    "            \"libelleCommuneEtablissement\",\n",
    "            \"libelleVoieEtablissement\",\n",
    "            \"numeroVoieEtablissement\",\n",
    "            \"codePostalEtablissement\",\n",
    "            \"codeCommuneEtablissement\",\n",
    "        ],\n",
    "        dtype={\n",
    "            \"siren\": \"object\",\n",
    "            \"siret\": \"object\",\n",
    "            \"libelleCommuneEtablissement\": \"object\",\n",
    "            \"libelleVoieEtablissement\": \"object\",\n",
    "            \"numeroVoieEtablissement\": \"object\",\n",
    "            \"codePostalEtablissement\": \"object\",\n",
    "            \"codeCommuneEtablissement\": \"object\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    list_inpi = [\n",
    "        \"siren\",\n",
    "        \"siret\",\n",
    "        \"Type\",\n",
    "        \"Adresse_Ligne1\",\n",
    "        \"Adresse_Ligne2\",\n",
    "        \"Adresse_Ligne3\",\n",
    "        \"Code_Postal\",\n",
    "        \"Ville\",\n",
    "        \"Code_Commune\",\n",
    "        \"Pays\",\n",
    "        \"test\",\n",
    "        \"Ville_clean\",\n",
    "        \"ville2\",\n",
    "        \"ncc\",\n",
    "        \"possibilite\",\n",
    "        \"noaccent\",\n",
    "    ]\n",
    "    if \"_merge\" in df_input.columns:\n",
    "        df_input = df_input.drop(\n",
    "            columns=[\n",
    "                \"siret\",\n",
    "                \"numeroVoieEtablissement\",\n",
    "                \"libelleVoieEtablissement\",\n",
    "                \"codePostalEtablissement\",\n",
    "                \"libelleCommuneEtablissement\",\n",
    "                \"codeCommuneEtablissement\",\n",
    "                #'count_inpi',\n",
    "                #'count',\n",
    "                \"count_insee\",\n",
    "                \"_merge\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Calculer le nombre de SIRET par SIREN a l'INSEE\n",
    "    # Exemple SIREN 750767907\n",
    "    subset_insee_count = subset_insee_count.merge(\n",
    "        (\n",
    "            subset_insee_count.groupby(\"siren\")[\"siren\"]\n",
    "            .count()\n",
    "            .rename(\"count_insee\")\n",
    "            .reset_index()\n",
    "        )\n",
    "    )\n",
    "\n",
    "    temp = df_input.merge(\n",
    "        subset_insee_count,\n",
    "        how=\"left\",\n",
    "        left_on=[\"siren\", option[0]],\n",
    "        right_on=[\"siren\", option[1]],\n",
    "        indicator=True,\n",
    "        suffixes=[\"_insee\", \"_inpi\"],\n",
    "    )\n",
    "\n",
    "    to_check = temp[temp[\"_merge\"].isin([\"both\"])]\n",
    "    nomatch = temp[~temp[\"_merge\"].isin([\"both\"])]\n",
    "\n",
    "    if constraint_regex == False:\n",
    "\n",
    "        to_check[\"Adresse_new_clean_reg\"] = to_check[\n",
    "            \"Adresse_new_clean_reg\"\n",
    "        ].str.replace(\"$\", \"\")\n",
    "\n",
    "    to_check[\"siret_test1\"] = to_check.map_partitions(\n",
    "        lambda df: df.apply(\n",
    "            lambda x: find_regex(\n",
    "                x[\"Adresse_new_clean_reg\"], x[\"libelleVoieEtablissement\"], x[\"siret\"]\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    \n",
    "    to_check = to_check.dropna(subset=['siret_test1']).compute()\n",
    "    to_check['digit_inpi'] = to_check['Adress_new'].str.extract(r'(\\d+)')\n",
    "    \n",
    "    \n",
    "    to_check['test'] = np.where(\n",
    "        to_check['digit_inpi'] ==\n",
    "        to_check['numeroVoieEtablissement'],\n",
    "        True, False\n",
    "    )\n",
    "    \n",
    "    to_check = to_check[to_check['test'].isin([True])]\n",
    "    \n",
    "     # test\n",
    "    # calcul le nombre cas de figure 2 -> très conservative\n",
    "    test_match = to_check.merge(\n",
    "        (\n",
    "            to_check.groupby([\"siren\", \"Adress_new\"])[\"siren\"]\n",
    "            .count()\n",
    "            .rename(\"count_inpi\")\n",
    "            .reset_index()\n",
    "        )\n",
    "    )\n",
    "    print(test_match[\"count_inpi\"].value_counts())\n",
    "   \n",
    "    ### Si nb siret insee == 1 mais inpi pas 1, c'est tout de meme un SIRET\n",
    "    ### identique\n",
    "    ### test realise sur data 2017\n",
    "    # 2    478\n",
    "    # 3      9\n",
    "    # 6      6\n",
    "    true_match = test_match.loc[lambda x: x[\"count_inpi\"] == 1].reindex(\n",
    "        columns=list_inpi\n",
    "    )\n",
    "\n",
    "    name_csv = r\"Data\\Match\\numero\\{}\\voie_match_{}_{}.csv\".format(\n",
    "        option[0], str(constraint_regex), true_match.shape[0]\n",
    "    )\n",
    "\n",
    "    true_match.to_csv(name_csv, index=False)\n",
    "\n",
    "    dic_ = {\"true_match\": true_match, \"unmatch\": nomatch}\n",
    "\n",
    "    return dic_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "unmatch_adress = dd.read_csv(r'C:\\Users\\PERNETTH\\Documents\\Projects\\InseeInpi_matching\\Notebooks_matching\\data\\Unmatch\\unmatch_6_voie_false_1_92564.gz',dtype={\n",
    "                    'siren':'object',\n",
    "                                     'Code_Postal':'object',\n",
    "                                     'Adress_new':'object',\n",
    "                                     'Adresse_new_clean_reg':'object',\n",
    "                                     'Type':'object',\n",
    "                                     'Adresse_Ligne1':'object',\n",
    "                                     'Adresse_Ligne2':'object',\n",
    "                                     'Adresse_Ligne3':'object',\n",
    "                                     'Ville':'object',\n",
    "                                     'Code_Commune':'object',\n",
    "                                     'Pays':'object',\n",
    "                                     'Ville_clean':'object',\n",
    "                                     'ville2':'object',\n",
    "                                     'ncc':'object',\n",
    "                                     'possibilite':'object',\n",
    "                                     'noaccent':'object',\n",
    "                                     'Adress_new':'object',\n",
    "                                     'Adresse_new_clean_reg':'object'\n",
    "            },compression='gzip', blocksize=None)\n",
    "\n",
    "df_nomatch = pd.DataFrame()\n",
    "df_input = unmatch_adress\n",
    "  \n",
    "total_match = pd.DataFrame()\n",
    "for i in [\n",
    "        ['ncc', 'libelleCommuneEtablissement'],\n",
    "        ['Code_Postal', 'codePostalEtablissement'],\n",
    "        ['Code_Commune', 'codeCommuneEtablissement']\n",
    "    ]:\n",
    "    df_input_ = test_2(df_input=df_input,\n",
    "                                  option=i,\n",
    "                          constraint_regex = False)\n",
    "\n",
    "    df_input = df_input_['unmatch']\n",
    "    total_match = total_match.append(df_input_['true_match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_nomatch = match_unmatch(\n",
    "        df_inpi_initial=unmatch_adress.compute(),\n",
    "        df_inpi_mergeboth=total_match.drop(columns = 'test'),\n",
    "        step='6_voie_false_2',\n",
    "        to_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "total_match.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_nomatch.shape[0]/4312053"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_nomatch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_insee_count.compute().loc[lambda x:x['siren'].isin(['515226462'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_insee_count.compute().loc[lambda x:x['siren'].isin(['515226462'])]\n",
    "df_nomatch.loc[lambda x:\n",
    "               x['siren'].isin(['515226462'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_nomatch.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Dernier check\n",
    "\n",
    "Verification après\n",
    "\n",
    "- Si le SIREN a l'INSEE pour une adresse donnée à qu'une ligne mais plusieurs a l'INPI\n",
    "    - 515226462"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def test_3(\n",
    "    df_input, option=[\"ncc\", \"libelleCommuneEtablissement\"], constraint_regex=True\n",
    "):\n",
    "    \"\"\"\n",
    "    option list can only be one of these:\n",
    "    - ['ncc', 'libelleCommuneEtablissement']\n",
    "    - ['ncc', 'libelleCommuneEtablissement']\n",
    "    - ['ncc', 'libelleCommuneEtablissement']\n",
    "    \"\"\"\n",
    "\n",
    "    # load data into dataframes\n",
    "    subset_insee_count = dd.read_csv(\n",
    "        \"subset_insee_count.csv\",\n",
    "        usecols=[\n",
    "            \"siren\",\n",
    "            \"siret\",\n",
    "            \"libelleCommuneEtablissement\",\n",
    "            \"libelleVoieEtablissement\",\n",
    "            \"numeroVoieEtablissement\",\n",
    "            \"codePostalEtablissement\",\n",
    "            \"codeCommuneEtablissement\",\n",
    "        ],\n",
    "        dtype={\n",
    "            \"siren\": \"object\",\n",
    "            \"siret\": \"object\",\n",
    "            \"libelleCommuneEtablissement\": \"object\",\n",
    "            \"libelleVoieEtablissement\": \"object\",\n",
    "            \"numeroVoieEtablissement\": \"object\",\n",
    "            \"codePostalEtablissement\": \"object\",\n",
    "            \"codeCommuneEtablissement\": \"object\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    list_inpi = [\n",
    "        \"siren\",\n",
    "        \"siret\",\n",
    "        \"Type\",\n",
    "        \"Adresse_Ligne1\",\n",
    "        \"Adresse_Ligne2\",\n",
    "        \"Adresse_Ligne3\",\n",
    "        \"Code_Postal\",\n",
    "        \"Ville\",\n",
    "        \"Code_Commune\",\n",
    "        \"Pays\",\n",
    "        \"test\",\n",
    "        \"Ville_clean\",\n",
    "        \"ville2\",\n",
    "        \"ncc\",\n",
    "        \"possibilite\",\n",
    "        \"noaccent\",\n",
    "    ]\n",
    "    if \"_merge\" in df_input.columns:\n",
    "        df_input = df_input.drop(\n",
    "            columns=[\n",
    "                \"siret\",\n",
    "                \"numeroVoieEtablissement\",\n",
    "                \"libelleVoieEtablissement\",\n",
    "                \"codePostalEtablissement\",\n",
    "                \"libelleCommuneEtablissement\",\n",
    "                \"codeCommuneEtablissement\",\n",
    "                #'count_inpi',\n",
    "                #'count',\n",
    "                \"count_insee\",\n",
    "                \"_merge\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Calculer le nombre de SIRET par SIREN a l'INSEE\n",
    "    # Exemple SIREN 750767907\n",
    "    subset_insee_count = subset_insee_count.merge(\n",
    "        (\n",
    "            subset_insee_count.groupby([\"siren\", 'libelleVoieEtablissement'])[\"siren\"]\n",
    "            .count()\n",
    "            .rename(\"count_insee\")\n",
    "            .reset_index()\n",
    "        )\n",
    "    )\n",
    "\n",
    "    temp = df_input.merge(\n",
    "        subset_insee_count,\n",
    "        how=\"left\",\n",
    "        left_on=[\"siren\", option[0]],\n",
    "        right_on=[\"siren\", option[1]],\n",
    "        indicator=True,\n",
    "        suffixes=[\"_insee\", \"_inpi\"],\n",
    "    )\n",
    "\n",
    "    to_check = temp[temp[\"_merge\"].isin([\"both\"])]\n",
    "    nomatch = temp[~temp[\"_merge\"].isin([\"both\"])]\n",
    "\n",
    "    if constraint_regex == False:\n",
    "\n",
    "        to_check[\"Adresse_new_clean_reg\"] = to_check[\n",
    "            \"Adresse_new_clean_reg\"\n",
    "        ].str.replace(\"$\", \"\")\n",
    "\n",
    "    to_check[\"siret_test1\"] = to_check.map_partitions(\n",
    "        lambda df: df.apply(\n",
    "            lambda x: find_regex(\n",
    "                x[\"Adresse_new_clean_reg\"], x[\"libelleVoieEtablissement\"], x[\"siret\"]\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    \n",
    "    to_check = to_check.dropna(subset=['siret_test1']).compute()\n",
    "    to_check['digit_inpi'] = to_check['Adress_new'].str.extract(r'(\\d+)')\n",
    "    \n",
    "    \n",
    "    to_check['test'] = np.where(\n",
    "        to_check['digit_inpi'] ==\n",
    "        to_check['numeroVoieEtablissement'],\n",
    "        True, False\n",
    "    )\n",
    "    \n",
    "    to_check = to_check[to_check['test'].isin([True])]\n",
    "    \n",
    "     # test\n",
    "    # calcul le nombre cas de figure 2 -> très conservative\n",
    "    test_match = to_check.merge(\n",
    "        (\n",
    "            to_check.groupby([\"siren\", \"Adress_new\"])[\"siren\"]\n",
    "            .count()\n",
    "            .rename(\"count_inpi\")\n",
    "            .reset_index()\n",
    "        )\n",
    "    )\n",
    "    print(test_match[\"count_insee\"].value_counts())\n",
    "   \n",
    "    ### Si nb siret insee == 1 mais inpi pas 1, c'est tout de meme un SIRET\n",
    "    ### identique\n",
    "    ### test realise sur data 2017\n",
    "    # 2    478\n",
    "    # 3      9\n",
    "    # 6      6\n",
    "    return test_match\n",
    "    true_match = test_match.loc[lambda x: x[\"count_insee\"] == 1].reindex(\n",
    "        columns=list_inpi\n",
    "    )\n",
    "\n",
    "    name_csv = r\"Data\\Match\\numero\\{}\\voie_match_{}_{}.csv\".format(\n",
    "        option[0], str(constraint_regex), true_match.shape[0]\n",
    "    )\n",
    "\n",
    "    true_match.to_csv(name_csv, index=False)\n",
    "\n",
    "    dic_ = {\"true_match\": true_match, \"unmatch\": nomatch}\n",
    "\n",
    "    return dic_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "unmatch_adress = dd.read_csv(r'C:\\Users\\PERNETTH\\Documents\\Projects\\InseeInpi_matching\\Notebooks_matching\\data\\Unmatch\\unmatch_6_voie_false_2_88186.gz',dtype={\n",
    "                    'siren':'object',\n",
    "                                     'Code_Postal':'object',\n",
    "                                     'Adress_new':'object',\n",
    "                                     'Adresse_new_clean_reg':'object',\n",
    "                                     'Type':'object',\n",
    "                                     'Adresse_Ligne1':'object',\n",
    "                                     'Adresse_Ligne2':'object',\n",
    "                                     'Adresse_Ligne3':'object',\n",
    "                                     'Ville':'object',\n",
    "                                     'Code_Commune':'object',\n",
    "                                     'Pays':'object',\n",
    "                                     'Ville_clean':'object',\n",
    "                                     'ville2':'object',\n",
    "                                     'ncc':'object',\n",
    "                                     'possibilite':'object',\n",
    "                                     'noaccent':'object',\n",
    "                                     'Adress_new':'object',\n",
    "                                     'Adresse_new_clean_reg':'object'\n",
    "            },compression='gzip', blocksize=None)\n",
    "\n",
    "df_nomatch = pd.DataFrame()\n",
    "df_input = unmatch_adress\n",
    "  \n",
    "test_ = test_3(\n",
    "    df_input, \n",
    "    option=[\"ncc\", \"libelleCommuneEtablissement\"], constraint_regex=True\n",
    ")#[\"true_match\"].loc[lambda x:\n",
    "#               x['siren'].isin(['515226462'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "subset_insee_count.compute().loc[lambda x:\n",
    "                                 x['siren'].isin(['662043116']) & \n",
    "                                 x['libelleCommuneEtablissement'].isin(['DIJON'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_input.compute().loc[lambda x:\n",
    "               x['siren'].isin(['662043116'])\n",
    "                      & x['Ville'].isin(['Dijon'])\n",
    "                      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_.loc[lambda x:\n",
    "               x['siren'].isin(['662043116'])\n",
    "                      & x['Ville'].isin(['Dijon'])\n",
    "                      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_.loc[lambda x :x['count_insee'].isin([2])].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "total_match = pd.DataFrame()\n",
    "for i in [\n",
    "        ['ncc', 'libelleCommuneEtablissement'],\n",
    "        ['Code_Postal', 'codePostalEtablissement'],\n",
    "        ['Code_Commune', 'codeCommuneEtablissement']\n",
    "    ]:\n",
    "    df_input_ = test_3(df_input=df_input,\n",
    "                                  option=i,\n",
    "                          constraint_regex = False)\n",
    "\n",
    "    df_input = df_input_['unmatch']\n",
    "    total_match = total_match.append(df_input_['true_match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_nomatch = match_unmatch(\n",
    "        df_inpi_initial=unmatch_adress.compute(),\n",
    "        df_inpi_mergeboth=total_match.drop(columns = 'test'),\n",
    "        step='7_last_voie',\n",
    "        to_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
