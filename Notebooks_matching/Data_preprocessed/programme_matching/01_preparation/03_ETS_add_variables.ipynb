{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPI ETS ajout nouvelles variables\n",
    "\n",
    "This notebook has been generated on 18/07/2020\n",
    "\n",
    "L'objectif de ce notebook est de préparer la data de l'INPI en vue de siretiser la séquence siren, code_greffe, nom_greffe, numero_gestion, id_etablissement\n",
    "\n",
    "## Global steps \n",
    "\n",
    "The global steps to construct the dataset are the following:\n",
    "\n",
    "\n",
    " *  Préparer les variables suivantes dans la table de l’INPI:\n",
    "    * enseigne \n",
    "    * ville_matching\n",
    "    * adress_reconstituee_inpi\n",
    "    * adress_distance_inpi \n",
    "    * adress_regex_inpi \n",
    "    * numero_voie_matching \n",
    "    * voie_matching \n",
    "    * last_libelle_evt \n",
    "    * status_admin \n",
    "    * status_ets \n",
    "    * index_id \n",
    "\n",
    "## Input data sources\n",
    "\n",
    "The data source to construct the dataset are the following:\n",
    "\n",
    "- Athena \n",
    "  - region: eu-west-3 \n",
    "  - Database: inpi \n",
    "  -  Table: initial_partiel_evt_new_ets_status_final \n",
    "  -  Notebook construction file (data lineage) \n",
    "      -  md :[01_Athena_concatenate_ETS.md](https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/01_preparation/01_Athena_concatenate_ETS.md)\n",
    "\n",
    "## Output data sources\n",
    "\n",
    "  * Athena: \n",
    "    * region: eu-west-3 \n",
    "    * Database: inpi \n",
    "    * table: ets_final_sql \n",
    "\n",
    "     \n",
    "## Things to know\n",
    "\n",
    "* Programme preparation data:\n",
    "    - [preparation_data.py](https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/inpi_insee/preparation_data.py)\n",
    "* ville_matching: \n",
    "    - [00_prep_ville_2613.md](https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/05_redaction_US/00_prep_ville_2613.md)\n",
    "    - [2613](https://tree.taiga.io/project/olivierlubet-air/us/2613)\n",
    "* adress_regex:\n",
    "    - [03_prep_adresse_2690.md](https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/05_redaction_US/03_prep_adresse_2690.md)\n",
    "* voie_matching: \n",
    "    - [04_prep_voie_num_2697.md](https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/05_redaction_US/04_prep_voie_num_2697.md)\n",
    "* last_libelle_evt/status_admin/status_ets: \n",
    "    - [US 04 Amelioration ETS](https://coda.io/d/CreditAgricole_dCtnoqIftTn/US-04-Amelioration-ETS_sulSU)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametre SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awsPy.aws_authorization import aws_connector\n",
    "from awsPy.aws_athena import service_athena\n",
    "from awsPy.aws_s3 import service_s3\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "bucket = 'calfdata'\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent)\n",
    "path_cred = r\"{}/credential_AWS.json\".format(parent_path)\n",
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = 'eu-west-3')\n",
    "client= con.client_boto()\n",
    "s3 = service_s3.connect_S3(client = client,\n",
    "                      bucket = 'calfdata') \n",
    "athena = service_athena.connect_athena(client = client,\n",
    "                      bucket = 'calfdata') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation json parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ = {\n",
    "    'global':{\n",
    "        'database':'inpi',\n",
    "        'output':'INPI/sql_output',\n",
    "        'output_preparation':'INPI/sql_output_preparation',\n",
    "        'Parameters':{\n",
    "            'stop_word': 's3://calfdata/Parameters/STOP_WORD',\n",
    "            'type_voie':'s3://calfdata/Parameters/TYPE_VOIE_SQL'\n",
    "        }\n",
    "        #'ETS_step4_id':[],\n",
    "        #'table_final_id':{\n",
    "        #    'ETS':{\n",
    "        #    }\n",
    "        #}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation table `ets_final_sql`\n",
    "\n",
    "La query met environ 5 minutes pour s'éxecuter. Il est possible d'améliorer les patterns regex\n",
    "\n",
    "## Etapes\n",
    "\n",
    "* `enseigne`: \n",
    "    - Mise en majuscule\n",
    "* `ville_matching`:\n",
    "    - Nettoyage regex de la ville et suppression des espaces\n",
    "* `adress_reconstituee_inpi`\n",
    "    - Concatenation des champs de l'adresse et suppression des espaces\n",
    "* `adress_distance_inpi`: \n",
    "    - Concatenation des champs de l'adresse, suppression des espaces et des articles\n",
    "* `adress_regex_inpi`: \n",
    "    - Concatenation des champs de l'adresse, suppression des espaces, des articles et des numéros et ajout de `(?:^|(?<= ))(` et `)(?:(?= )|$)`\n",
    "* `numero_voie_matching`: \n",
    "    - Extraction du premier numéro de voie dans l'adresse\n",
    "* `voie_matching`: \n",
    "    - Extration du type de voie dans l'adresse et match avec abbrévation type de voie de l'INSEE\n",
    "* `last_libelle_evt`: \n",
    "    - Extraction du dernier libellé de l'événement connu pour une séquence, et appliquer cette information à l'ensemble de la séquence\n",
    "* `status_admin`: \n",
    "    - Informe du status ouvert/fermé concernant une séquence\n",
    "* `status_ets`: \n",
    "    - Informe du type d'établissement (SIE/PRI.SEC) concernant une séquence\n",
    "* `index_id`: \n",
    "    - Création du numéro de ligne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "/*Table préparée avec nouvelles */\n",
    "CREATE TABLE inpi.ets_final_sql\n",
    "WITH (\n",
    "  format='PARQUET'\n",
    ") AS\n",
    "WITH create_regex AS ( \n",
    "SELECT\n",
    "index_id,\n",
    "sequence_id,\n",
    "siren, \n",
    "    code_greffe, \n",
    "    nom_greffe, \n",
    "    numero_gestion, \n",
    "    id_etablissement, \n",
    "    status, \n",
    "    origin, \n",
    "    date_greffe, \n",
    "    file_timestamp, \n",
    "    libelle_evt, \n",
    "    type, \n",
    "    \"siège_pm\", \n",
    "    rcs_registre, \n",
    "    adresse_ligne1, \n",
    "    adresse_ligne2, \n",
    "    adresse_ligne3,\n",
    "  REGEXP_REPLACE(\n",
    "            REGEXP_REPLACE(\n",
    "              REGEXP_REPLACE(\n",
    "                REGEXP_REPLACE(\n",
    "                  NORMALIZE(\n",
    "                    UPPER(\n",
    "                      CONCAT(\n",
    "                        adresse_ligne1, ' ', adresse_ligne2, \n",
    "                        ' ', adresse_ligne3\n",
    "                      )\n",
    "                    ), \n",
    "                    NFD\n",
    "                  ), \n",
    "                  '\\pM', \n",
    "                  ''\n",
    "                ), \n",
    "                '[^\\w\\s]| +', \n",
    "                ' '\n",
    "              ), \n",
    "            '\\s\\s+', \n",
    "            ' '\n",
    "          ), \n",
    "          '^\\s+|\\s+$', \n",
    "          ''\n",
    "      ) AS adress_reconstituee_inpi,\n",
    "            REGEXP_REPLACE(\n",
    "          REGEXP_REPLACE(\n",
    "            REGEXP_REPLACE(\n",
    "              REGEXP_REPLACE(\n",
    "                REGEXP_REPLACE(\n",
    "                  NORMALIZE(\n",
    "                    UPPER(\n",
    "                      CONCAT(\n",
    "                        adresse_ligne1, ' ', adresse_ligne2, \n",
    "                        ' ', adresse_ligne3\n",
    "                      )\n",
    "                    ), \n",
    "                    NFD\n",
    "                  ), \n",
    "                  '\\pM', \n",
    "                  ''\n",
    "                ), \n",
    "                '[^\\w\\s]| +', \n",
    "                ' '\n",
    "              ), \n",
    "              '(?:^|(?<= ))(AU|AUX|AVEC|CE|CES|DANS|DE|DES|DU|ELLE|EN|ET|EUX|IL|ILS|LA|LE|LES)(?:(?= )|$)', \n",
    "              ''\n",
    "            ), \n",
    "            '\\s\\s+', \n",
    "            ' '\n",
    "          ), \n",
    "          '^\\s+|\\s+$', \n",
    "          ''\n",
    "      ) AS adress_distance_inpi,\n",
    "    CONCAT(\n",
    "      '(?:^|(?<= ))(', \n",
    "      -- debut regex\n",
    "      REGEXP_REPLACE(\n",
    "        REGEXP_REPLACE(\n",
    "          REGEXP_REPLACE(\n",
    "            REGEXP_REPLACE(\n",
    "              REGEXP_REPLACE(\n",
    "                REGEXP_REPLACE(\n",
    "                  NORMALIZE(\n",
    "                    UPPER(\n",
    "                      CONCAT(\n",
    "                        adresse_ligne1, ' ', adresse_ligne2, \n",
    "                        ' ', adresse_ligne3\n",
    "                      )\n",
    "                    ), \n",
    "                    NFD\n",
    "                  ), \n",
    "                  '\\pM', \n",
    "                  ''\n",
    "                ), \n",
    "                '[^\\w\\s]|\\d+| +', \n",
    "                ' '\n",
    "              ), \n",
    "              '(?:^|(?<= ))(AU|AUX|AVEC|CE|CES|DANS|DE|DES|DU|ELLE|EN|ET|EUX|IL|ILS|LA|LE|LES)(?:(?= )|$)', \n",
    "              ''\n",
    "            ), \n",
    "            '\\s\\s+', \n",
    "            ' '\n",
    "          ), \n",
    "          '^\\s+|\\s+$', \n",
    "          ''\n",
    "        ), \n",
    "        '\\s', \n",
    "        '|'\n",
    "      ), \n",
    "      -- milieu regex\n",
    "      ')(?:(?= )|$)' -- fin regex\n",
    "      ) AS adress_regex_inpi,\n",
    "      code_postal, \n",
    "    code_postal_matching, \n",
    "    ville, \n",
    "    REGEXP_REPLACE(\n",
    "      REGEXP_REPLACE(\n",
    "        REGEXP_REPLACE(\n",
    "          REGEXP_REPLACE(\n",
    "            REGEXP_REPLACE(\n",
    "              REGEXP_REPLACE(\n",
    "                REGEXP_REPLACE(\n",
    "                  REGEXP_REPLACE(\n",
    "                    REGEXP_REPLACE(\n",
    "                      NORMALIZE(\n",
    "                        UPPER(ville), \n",
    "                        NFD\n",
    "                      ), \n",
    "                      '\\pM', \n",
    "                      ''\n",
    "                    ), \n",
    "                    '^\\d+\\s|\\s\\d+\\s|\\s\\d+$', \n",
    "                    -- digit\n",
    "                    ''\n",
    "                  ), \n",
    "                  '^LA\\s+|^LES\\s+|^LE\\s+|\\\\(.*\\\\)|^L(ES|A|E) | L(ES|A|E) | L(ES|A|E)$|CEDEX | CEDEX | CEDEX|^E[R*] | E[R*] | E[R*]$', \n",
    "                  ''\n",
    "                ), \n",
    "                '^STE | STE | STE$|^STES | STES | STES', \n",
    "                'SAINTE'\n",
    "              ), \n",
    "              '^ST | ST | ST$', \n",
    "              'SAINT'\n",
    "            ), \n",
    "            'S/|^S | S | S$', \n",
    "            'SUR'\n",
    "          ), \n",
    "          '/S', \n",
    "          'SOUS'\n",
    "        ), \n",
    "        '[^\\w\\s]|\\([^()]*\\)|ER ARRONDISSEMENT|E ARRONDISSEMENT|\" \\\n",
    "\"|^SUR$|CEDEX|[0-9]+|\\s+', \n",
    "        ''\n",
    "      ), \n",
    "      'MARSEILLEE', \n",
    "      'MARSEILLE'\n",
    "    ) as ville_matching, \n",
    "    code_commune, \n",
    "    pays, \n",
    "    domiciliataire_nom, \n",
    "    domiciliataire_siren, \n",
    "    domiciliataire_greffe, \n",
    "    \"domiciliataire_complément\", \n",
    "    \"siege_domicile_représentant\", \n",
    "    nom_commercial, \n",
    "    UPPER(enseigne) as enseigne, \n",
    "    \"activité_ambulante\", \n",
    "    \"activité_saisonnière\", \n",
    "    \"activité_non_sédentaire\", \n",
    "    \"date_début_activité\", \n",
    "    \"activité\", \n",
    "    origine_fonds, \n",
    "    origine_fonds_info, \n",
    "    type_exploitation, \n",
    "    csv_source\n",
    "FROM ets_test_filtered_id_seq\n",
    ") \n",
    "SELECT \n",
    "  * \n",
    "FROM \n",
    "  (\n",
    "    WITH voie_type_voie AS (\n",
    "      SELECT \n",
    "      index_id,\n",
    "sequence_id,\n",
    "        siren, \n",
    "        code_greffe, \n",
    "        nom_greffe, \n",
    "        numero_gestion, \n",
    "        id_etablissement, \n",
    "        status, \n",
    "        origin, \n",
    "        date_greffe, \n",
    "        file_timestamp, \n",
    "        libelle_evt, \n",
    "        type, \n",
    "        \"siège_pm\", \n",
    "        rcs_registre, \n",
    "        adresse_ligne1, \n",
    "        adresse_ligne2, \n",
    "        adresse_ligne3, \n",
    "        adress_reconstituee_inpi,\n",
    "        -- adress_nettoyee, \n",
    "        -- adresse_inpi_reconstitue, \n",
    "        adress_regex_inpi,\n",
    "        adress_distance_inpi, \n",
    "        numero_voie_matching, \n",
    "        numero_voie_type_voie.voie_clean, \n",
    "        voie_matching, \n",
    "        code_postal, \n",
    "        code_postal_matching, \n",
    "        ville, \n",
    "        ville_matching, \n",
    "        code_commune, \n",
    "        pays, \n",
    "        domiciliataire_nom, \n",
    "        domiciliataire_siren, \n",
    "        domiciliataire_greffe, \n",
    "        \"domiciliataire_complément\", \n",
    "        \"siege_domicile_représentant\", \n",
    "        nom_commercial, \n",
    "        enseigne, \n",
    "        \"activité_ambulante\", \n",
    "        \"activité_saisonnière\", \n",
    "        \"activité_non_sédentaire\", \n",
    "        \"date_début_activité\", \n",
    "        \"activité\", \n",
    "        origine_fonds, \n",
    "        origine_fonds_info, \n",
    "        type_exploitation, \n",
    "        csv_source\n",
    "      FROM \n",
    "        type_voie \n",
    "        RIGHT JOIN (\n",
    "          SELECT \n",
    "          index_id,\n",
    "sequence_id,\n",
    "            siren, \n",
    "            code_greffe, \n",
    "            nom_greffe, \n",
    "            numero_gestion, \n",
    "            id_etablissement, \n",
    "            status, \n",
    "            origin, \n",
    "            date_greffe, \n",
    "            file_timestamp, \n",
    "            libelle_evt, \n",
    "            type, \n",
    "            \"siège_pm\", \n",
    "            rcs_registre, \n",
    "            adresse_ligne1, \n",
    "            adresse_ligne2, \n",
    "            adresse_ligne3,\n",
    "            adress_reconstituee_inpi,\n",
    "            adress_regex_inpi,\n",
    "            adress_distance_inpi,\n",
    "            -- adress_nettoyee,  \n",
    "            -- adress_regex, \n",
    "            regexp_extract(adress_reconstituee_inpi, '\\d+') as numero_voie_matching, \n",
    "            regexp_extract(\n",
    "              adress_reconstituee_inpi, '(?:^|(?<= ))(ALLEE|AVENUE|BOULEVARD|CARREFOUR|CHEMIN|CHAUSSEE|CITE|CORNICHE|COURS|DOMAINE|DESCENTE|ECART|ESPLANADE|FAUBOURG|GRANDE RUE|HAMEAU|HALLE|IMPASSE|LIEU DIT|LOTISSEMENT|MARCHE|MONTEE|PASSAGE|PLACE|PLAINE|PLATEAU|PROMENADE|PARVIS|QUARTIER|QUAI|RESIDENCE|RUELLE|ROCADE|ROND POINT|ROUTE|RUE|SENTE   SENTIER|SQUARE|TERRE PLEIN|TRAVERSE|VILLA|VILLAGE)(?:(?= )|$)'\n",
    "            ) as voie_clean, \n",
    "            code_postal, \n",
    "            code_postal_matching, \n",
    "            ville, \n",
    "            ville_matching, \n",
    "            code_commune, \n",
    "            pays, \n",
    "            domiciliataire_nom, \n",
    "            domiciliataire_siren, \n",
    "            domiciliataire_greffe, \n",
    "            \"domiciliataire_complément\", \n",
    "            \"siege_domicile_représentant\", \n",
    "            nom_commercial, \n",
    "            enseigne, \n",
    "            \"activité_ambulante\", \n",
    "            \"activité_saisonnière\", \n",
    "            \"activité_non_sédentaire\", \n",
    "            \"date_début_activité\", \n",
    "            \"activité\", \n",
    "            origine_fonds, \n",
    "            origine_fonds_info, \n",
    "            type_exploitation, \n",
    "            csv_source\n",
    "          FROM \n",
    "            create_regex\n",
    "        ) as numero_voie_type_voie ON numero_voie_type_voie.voie_clean = type_voie.voie_clean\n",
    "    ) \n",
    "    SELECT \n",
    "      * \n",
    "    FROM \n",
    "      (\n",
    "        WITH convert_date AS (\n",
    "          SELECT \n",
    "            siren, \n",
    "            code_greffe, \n",
    "            nom_greffe, \n",
    "            numero_gestion, \n",
    "            id_etablissement, \n",
    "            Coalesce(\n",
    "              try(\n",
    "                date_parse(date_greffe, '%Y-%m-%d')\n",
    "              ), \n",
    "              try(\n",
    "                date_parse(\n",
    "                  date_greffe, '%Y-%m-%d %hh:%mm:%ss.SSS'\n",
    "                )\n",
    "              ), \n",
    "              try(\n",
    "                date_parse(\n",
    "                  date_greffe, '%Y-%m-%d %hh:%mm:%ss'\n",
    "                )\n",
    "              ), \n",
    "              try(\n",
    "                cast(date_greffe as timestamp)\n",
    "              )\n",
    "            ) as date_greffe, \n",
    "            libelle_evt \n",
    "          FROM \n",
    "            voie_type_voie\n",
    "        ) \n",
    "        SELECT \n",
    "        index_id,\n",
    "        sequence_id,\n",
    "          voie_type_voie.siren, \n",
    "          voie_type_voie.code_greffe, \n",
    "          voie_type_voie.nom_greffe, \n",
    "          voie_type_voie.numero_gestion, \n",
    "          voie_type_voie.id_etablissement, \n",
    "          status, \n",
    "          origin, \n",
    "          date_greffe, \n",
    "          file_timestamp, \n",
    "          libelle_evt, \n",
    "          last_libele_evt, \n",
    "          CASE WHEN last_libele_evt = 'Etablissement supprimé' THEN 'F' ELSE 'A' END AS status_admin,\n",
    "          type, \n",
    "          CASE WHEN type = 'SIE' OR type = 'SEP' THEN 'true' ELSE 'false' END AS status_ets,\n",
    "          \"siège_pm\", \n",
    "          rcs_registre, \n",
    "          adresse_ligne1, \n",
    "          adresse_ligne2, \n",
    "          adresse_ligne3, \n",
    "          adress_reconstituee_inpi,\n",
    "        -- adress_nettoyee, \n",
    "        -- adresse_inpi_reconstitue, \n",
    "          adress_regex_inpi,\n",
    "          adress_distance_inpi,\n",
    "          numero_voie_matching, \n",
    "          voie_clean, \n",
    "          voie_matching,\n",
    "          code_postal, \n",
    "          code_postal_matching, \n",
    "          ville, \n",
    "          ville_matching, \n",
    "          code_commune, \n",
    "          pays, \n",
    "          domiciliataire_nom, \n",
    "          domiciliataire_siren, \n",
    "          domiciliataire_greffe, \n",
    "          \"domiciliataire_complément\", \n",
    "          \"siege_domicile_représentant\", \n",
    "          nom_commercial, \n",
    "          enseigne, \n",
    "          \"activité_ambulante\", \n",
    "          \"activité_saisonnière\", \n",
    "          \"activité_non_sédentaire\", \n",
    "          \"date_début_activité\", \n",
    "          \"activité\", \n",
    "          origine_fonds, \n",
    "          origine_fonds_info, \n",
    "          type_exploitation, \n",
    "          csv_source\n",
    "        FROM \n",
    "          voie_type_voie \n",
    "          INNER JOIN (\n",
    "            SELECT \n",
    "              convert_date.siren, \n",
    "              convert_date.code_greffe, \n",
    "              convert_date.nom_greffe, \n",
    "              convert_date.numero_gestion, \n",
    "              convert_date.id_etablissement, \n",
    "              convert_date.libelle_evt as last_libele_evt, \n",
    "              max_date_greffe \n",
    "            FROM \n",
    "              convert_date \n",
    "              INNER JOIN (\n",
    "                SELECT \n",
    "                  siren, \n",
    "                  code_greffe, \n",
    "                  nom_greffe, \n",
    "                  numero_gestion, \n",
    "                  id_etablissement, \n",
    "                  MAX(\n",
    "                    Coalesce(\n",
    "                      try(\n",
    "                        date_parse(date_greffe, '%Y-%m-%d')\n",
    "                      ), \n",
    "                      try(\n",
    "                        date_parse(\n",
    "                          date_greffe, '%Y-%m-%d %hh:%mm:%ss.SSS'\n",
    "                        )\n",
    "                      ), \n",
    "                      try(\n",
    "                        date_parse(\n",
    "                          date_greffe, '%Y-%m-%d %hh:%mm:%ss'\n",
    "                        )\n",
    "                      ), \n",
    "                      try(\n",
    "                        cast(date_greffe as timestamp)\n",
    "                      )\n",
    "                    )\n",
    "                  ) as max_date_greffe \n",
    "                FROM \n",
    "                  voie_type_voie \n",
    "                GROUP BY \n",
    "                  siren, \n",
    "                  code_greffe, \n",
    "                  nom_greffe, \n",
    "                  numero_gestion, \n",
    "                  id_etablissement\n",
    "              ) AS temp ON temp.siren = convert_date.siren \n",
    "              AND temp.code_greffe = convert_date.code_greffe \n",
    "              AND temp.nom_greffe = convert_date.nom_greffe \n",
    "              AND temp.numero_gestion = convert_date.numero_gestion \n",
    "              AND temp.id_etablissement = convert_date.id_etablissement \n",
    "              AND temp.max_date_greffe = convert_date.date_greffe\n",
    "          ) as latest_libele ON voie_type_voie.siren = latest_libele.siren \n",
    "          AND voie_type_voie.code_greffe = latest_libele.code_greffe \n",
    "          AND voie_type_voie.nom_greffe = latest_libele.nom_greffe \n",
    "          AND voie_type_voie.numero_gestion = latest_libele.numero_gestion \n",
    "          AND voie_type_voie.id_etablissement = latest_libele.id_etablissement\n",
    "      )\n",
    "    ORDER BY siren, code_greffe, nom_greffe, numero_gestion, id_etablissement, date_greffe\n",
    "  )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Details Etapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 1: Préparation `ville_matching`\n",
    "\n",
    "Cette étape fait référence à l'US [00_prep_ville_2613.md](https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/05_redaction_US/00_prep_ville_2613.md), et la conception du regex est la suivante:\n",
    "\n",
    "```\n",
    "Select\n",
    "    REGEXP_REPLACE(\n",
    "    REGEXP_REPLACE(\n",
    "    REGEXP_REPLACE(\n",
    "    REGEXP_REPLACE(\n",
    "    REGEXP_REPLACE(\n",
    "    REGEXP_REPLACE(\n",
    "    UPPER(TRANSLATE(\n",
    "    ville,'ÀÁÂÃÄÅàáâãäåÒÓÔÕÖØòóôõöøÈÉÊËèéêëÇçÌÍÎÏìíîïÙÚÛÜùúûüÿÑñ-\\'0123456789','aaaaaaaaaaaaooooooooooooeeeeeeeecciiiiiiiiuuuuuuuuynn  ')) --Remplacement accent + chiffres\n",
    "    ,'\\\\(.*\\\\)|^L(ES|A|E) | L(ES|A|E) | L(ES|A|E)$|CEDEX | CEDEX | CEDEX|^E[R*] | E[R*] | E[R*]$','') --Suppression de certains patterns\n",
    "    ,'^STE | STE | STE$|^STES | STES | STES$','SAINTE') -- Remplacement\n",
    "    ,'^ST | ST | ST$','SAINT') -- Remplacement\n",
    "    ,'S/|^S | S | S$','SUR') -- Remplacement\n",
    "    ,'/S','SOUS') -- Remplacement\n",
    "    ,' ','') ville_matching -- Suppression des espaces à la fin\n",
    "from ${BDD_REFERENTIEL}.inpi_etablissement_historique;\n",
    "\n",
    "```\n",
    "Dans notre notebook, on a changé la facon d'enlever les accents, et on a rajouté des règles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "REGEXP_REPLACE(\n",
    "  REGEXP_REPLACE(\n",
    "    REGEXP_REPLACE(\n",
    "      REGEXP_REPLACE(\n",
    "        REGEXP_REPLACE(\n",
    "          REGEXP_REPLACE(\n",
    "            REGEXP_REPLACE(\n",
    "              REGEXP_REPLACE(\n",
    "                REGEXP_REPLACE(NORMALIZE(UPPER(ville), NFD) , '\\pM', ''),\n",
    "          '^\\d+\\s|\\s\\d+\\s|\\s\\d+$', -- digit\n",
    "          ''\n",
    "        ),\n",
    "        '^LA\\s+|^LES\\s+|^LE\\s+|\\\\(.*\\\\)|^L(ES|A|E) | L(ES|A|E) | L(ES|A|E)$|CEDEX | CEDEX | CEDEX|^E[R*] | E[R*] | E[R*]$',\n",
    "      ''\n",
    "      ),\n",
    "      '^STE | STE | STE$|^STES | STES | STES',\n",
    "      'SAINTE'\n",
    "    ),\n",
    "    '^ST | ST | ST$',\n",
    "    'SAINT'\n",
    "  ),\n",
    "  'S/|^S | S | S$',\n",
    "  'SUR'\n",
    "  ),\n",
    "  '/S',\n",
    "  'SOUS'\n",
    "  ),\n",
    "  '[^\\w\\s]|\\([^()]*\\)|ER ARRONDISSEMENT|E ARRONDISSEMENT|\" \\\n",
    "\"|^SUR$|CEDEX|[0-9]+|\\s+',\n",
    "  ''\n",
    "),\n",
    "  'MARSEILLEE',\n",
    "  'MARSEILLE'\n",
    "  ) as ville_matching\n",
    "  \n",
    "FROM initial_partiel_evt_new_ets_status_final  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 2: Preparation `adress_reconsitituee_inpi` & `adresse_distance_inpi` & `adress_regex_inpi` \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `adress_reconsitituee_inpi`\n",
    "\n",
    "* Code pour construire adresse_inpi_reconstitue \n",
    "    - [Etape 1: Merge](https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/02_siretisation/05_siretisation_new_ets_v2.md#etape-1-merge-1)\n",
    "    \n",
    "``` \n",
    "adresse_inpi_reconstitue = lambda x: x['adress_new'].apply(\n",
    "        lambda x:' '.join([word for word in str(x).split() if word not in\n",
    "        (upper_word)]))\n",
    "``` \n",
    "\n",
    "Dans le code ci dessus, `adress_new` fait référence a la concatenation des champs de l'adresse et du cleaning regex. Dans notre cas, on n'effectue plus de nettoyage regex, mise a part les espaces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "REGEXP_REPLACE(\n",
    "            REGEXP_REPLACE(\n",
    "              REGEXP_REPLACE(\n",
    "                REGEXP_REPLACE(\n",
    "                  NORMALIZE(\n",
    "                    UPPER(\n",
    "                      CONCAT(\n",
    "                        adresse_ligne1, ' ', adresse_ligne2, \n",
    "                        ' ', adresse_ligne3\n",
    "                      )\n",
    "                    ), \n",
    "                    NFD\n",
    "                  ), \n",
    "                  '\\pM', \n",
    "                  ''\n",
    "                ), \n",
    "                '[^\\w\\s]| +', \n",
    "                ' '\n",
    "              ), \n",
    "            '\\s\\s+', \n",
    "            ' '\n",
    "          ), \n",
    "          '^\\s+|\\s+$', \n",
    "          ''\n",
    "      ) AS adress_reconstituee_inpi\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `adresse_distance_inpi`\n",
    "\n",
    "Cette étape fait référence à l'US [03_prep_adresse_2690.md](https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/05_redaction_US/03_prep_adresse_2690.md) \n",
    "\n",
    "- Input\n",
    "    - CSV: [upper_stop.csv](https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/data/input/Parameters/upper_stop.csv)\n",
    "        - CSV dans S3: [Parameters/upper_stop.csv](https://s3.console.aws.amazon.com/s3/object/calfdata/Parameters/STOP_WORD/upper_stop.csv?region=eu-west-3&tab=overview)\n",
    "        - A créer en table\n",
    "   - Athena: stop_word\n",
    "   \n",
    "Dans notre nouvelle version, on décide de tout garder car on va reconstituer l'adresse à l'INSEE. On supprime seulement  les articles   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.download_file(\n",
    "'Parameters/STOP_WORD/upper_stop.csv')\n",
    "\n",
    "#split = [i + \"$\" for i in pd.read_csv('upper_stop.csv', usecols = ['stop_word'])['stop_word'].to_list()]\n",
    "'|'.join(pd.read_csv('upper_stop.csv', usecols = ['stop_word'])['stop_word'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "REGEXP_REPLACE(\n",
    "          REGEXP_REPLACE(\n",
    "            REGEXP_REPLACE(\n",
    "              REGEXP_REPLACE(\n",
    "                REGEXP_REPLACE(\n",
    "                  NORMALIZE(\n",
    "                    UPPER(\n",
    "                      CONCAT(\n",
    "                        adresse_ligne1, ' ', adresse_ligne2, \n",
    "                        ' ', adresse_ligne3\n",
    "                      )\n",
    "                    ), \n",
    "                    NFD\n",
    "                  ), \n",
    "                  '\\pM', \n",
    "                  ''\n",
    "                ), \n",
    "                '[^\\w\\s]| +', \n",
    "                ' '\n",
    "              ), \n",
    "              '(?:^|(?<= ))(AU|AUX|AVEC|CE|CES|DANS|DE|DES|DU|ELLE|EN|ET|EUX|IL|ILS|LA|LE|LES(?:(?= )|$)', \n",
    "              ''\n",
    "            ), \n",
    "            '\\s\\s+', \n",
    "            ' '\n",
    "          ), \n",
    "          '^\\s+|\\s+$', \n",
    "          ''\n",
    "      ) AS adress_distance_inpi\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `adress_regex_inpi`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour créer le pattern regex, on utilise une liste de stop word disponible dans le Gitlab, que nous avons ensuite modifié manuellement. \n",
    "\n",
    "Le pattern regex devient le suivant. Par ailleurs, on utilise `(?:^|(?<= ))` et `(?:(?= )|$)` car cela semble mieux fonctionner. Cf. discussion [Stackedit](https://stackoverflow.com/questions/21448139/match-list-of-words-without-the-list-of-chars-around)\n",
    "\n",
    "Pattern regex:\n",
    "\n",
    "\n",
    "```\n",
    "(?:^|(?<= ))(AU|AUX|AVEC|CE|CES|DANS|DE|DES|DU|ELLE|EN|ET|EUX|IL|ILS|LA|LE|LES)(?:(?= )|$)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "CONCAT(\n",
    "      '(?:^|(?<= ))(', \n",
    "      -- debut regex\n",
    "      REGEXP_REPLACE(\n",
    "        REGEXP_REPLACE(\n",
    "          REGEXP_REPLACE(\n",
    "            REGEXP_REPLACE(\n",
    "              REGEXP_REPLACE(\n",
    "                REGEXP_REPLACE(\n",
    "                  NORMALIZE(\n",
    "                    UPPER(\n",
    "                      CONCAT(\n",
    "                        adresse_ligne1, ' ', adresse_ligne2, \n",
    "                        ' ', adresse_ligne3\n",
    "                      )\n",
    "                    ), \n",
    "                    NFD\n",
    "                  ), \n",
    "                  '\\pM', \n",
    "                  ''\n",
    "                ), \n",
    "                '[^\\w\\s]|\\d+| +', \n",
    "                ' '\n",
    "              ), \n",
    "              '(?:^|(?<= ))(AU|AUX|AVEC|CE|CES|DANS|DE|DES|DU|ELLE|EN|ET|EUX|IL|ILS|LA|LE|LES)(?:(?= )|$)', \n",
    "              ''\n",
    "            ), \n",
    "            '\\s\\s+', \n",
    "            ' '\n",
    "          ), \n",
    "          '^\\s+|\\s+$', \n",
    "          ''\n",
    "        ), \n",
    "        '\\s', \n",
    "        '|'\n",
    "      ), \n",
    "      -- milieu regex\n",
    "      ')(?:(?= )|$)' -- fin regex\n",
    "      ) AS adress_regex_inpi\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut tester si le regex marche en faisaint le test sur la variable `adress_nettoyee` et `adress_regex`. Avec la fonction `regexp_like`, on ne devrait retrouver que des `True`\n",
    "\n",
    "```\n",
    "WITH create_regex AS (\n",
    "SELECT \n",
    "siren, adresse_ligne1, adresse_ligne2, adresse_ligne3,\n",
    "REGEXP_REPLACE(\n",
    "  REGEXP_REPLACE(\n",
    "    REGEXP_REPLACE(\n",
    "      NORMALIZE(\n",
    "        UPPER(CONCAT(adresse_ligne1, ' ', adresse_ligne2, ' ', adresse_ligne3)),\n",
    "        NFD),\n",
    "      '\\pM', ''),\n",
    "    '[^\\w\\s]', ' '),\n",
    "    '\\s\\s+',\n",
    "    ' '\n",
    "  ) AS adress_nettoyee,\n",
    "CONCAT(\n",
    " '(?:^|(?<= ))(', -- debut regex\n",
    " REGEXP_REPLACE(\n",
    "  REGEXP_REPLACE(  \n",
    "   REGEXP_REPLACE(\n",
    "    REGEXP_REPLACE(\n",
    "     REGEXP_REPLACE(\n",
    "      REGEXP_REPLACE(\n",
    "        NORMALIZE(\n",
    "          UPPER(CONCAT(adresse_ligne1, ' ', adresse_ligne2, ' ', adresse_ligne3)),\n",
    "        NFD),\n",
    "      '\\pM', ''),\n",
    "  '[^\\w\\s]|\\d+| +', ' '\n",
    "  ), '(?:^|(?<= ))(AU|AUX|AVEC|CE|CES|DANS|DE|DES|DU|ELLE|EN|ET|EUX|IL|ILS|LA|LE|LES|AVENUE|BOULEVARD|CARREFOUR|CHEMIN|CITE|CORNICHE|COURS|DOMAINE|DESCENTE|ECART|ESPLANADE|FAUBOURG|GRANDE RUE|HAMEAU|HALLE|IMPASSE|LIEU DIT|LOTISSEMENT|MARCHE|MONTEE|PASSAGE|PLACE|PLAINE|PLATEAU|PROMENADE|PARVIS|QUARTIER|QUAI|RESIDENCE|RUELLE|ROCADE|ROND POINT|ROUTE|RUE|SENTIER|SQUARE|TERRE PLEIN|TRAVERSE|VILLA|VILLAGE|RN|BP|CEDEX|BIS)(?:(?= )|$)',\n",
    "  ''),\n",
    "    '\\s\\s+',\n",
    "    ' '),\n",
    "  '^\\s+|\\s+$',''),\n",
    "  '\\s', '|'), -- milieu regex\n",
    "  ')(?:(?= )|$)' -- fin regex\n",
    "  \n",
    "  ) AS adress_regex\n",
    "   \n",
    "  -- AS adress_nettoyee\n",
    "  \n",
    "FROM initial_partiel_evt_new_ets_status_final  \n",
    "--WHERE (adresse_ligne1 IS NOT NULL and adresse_ligne2 IS NOT NULL)\n",
    "--WHERE siren = '841344229'\n",
    "LIMIT 15\n",
    ")\n",
    "SELECT siren, adresse_ligne1, adresse_ligne2, adresse_ligne3, adress_nettoyee,adress_regex,\n",
    "regexp_like(adress_nettoyee,adress_regex)\n",
    "FROM create_regex   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 3: Préparation `numero_voie_matching` & `voie_matching`\n",
    "\n",
    "Cette étape fait référence à l'US [04_prep_voie_num_2697.md](https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/05_redaction_US/04_prep_voie_num_2697.md)\n",
    "\n",
    "### `numero_voie_matching`\n",
    "\n",
    "Le `numero_voie_matching` est l'extraction du numéro de voie dans la variable `adress_netoyee`.\n",
    "\n",
    "Exemple de code pour recupérer les digits dans un string avec SQL [US 2622](https://tree.taiga.io/project/olivierlubet-air/us/2622):\n",
    "\n",
    "```\n",
    "REGEXP_EXTRACT(ville, '\\d{5}')\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "regexp_extract(adress_nettoyee,'\\d+') as numero_voie_matching\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `voie_matching`\n",
    "\n",
    "Pour créer le pattern regex, on utilise une liste de type de voie disponible dans le Gitlab et à l'INSEE, que nous avons ensuite modifié manuellement. \n",
    "\n",
    "- Input\n",
    "    - CSV: [TypeVoie.csv](https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/data/input/Parameters/typeVoieEtablissement.csv)\n",
    "        - CSV dans S3: [Parameters/upper_stop.csv](https://s3.console.aws.amazon.com/s3/buckets/calfdata/Parameters/TYPE_VOIE/)\n",
    "        - A créer en table\n",
    "   - Athena: type_voie\n",
    "       - CSV dans S3: [Parameters/type_voie.csv](https://s3.console.aws.amazon.com/s3/buckets/calfdata/Parameters/TYPE_VOIE_SQL/)\n",
    "- Code Python: [Exemple Input 1](https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/05_redaction_US/04_prep_voie_num_2697.md#exemple-input-1)\n",
    "\n",
    "Pattern regex\n",
    "\n",
    "```\n",
    "(?:^|(?<= ))(ALLEE|AVENUE|BOULEVARD|CARREFOUR|CHEMIN|CHAUSSEE|CITE|CORNICHE|COURS|DOMAINE|DESCENTE|ECART|ESPLANADE|FAUBOURG|GRANDE RUE|HAMEAU|HALLE|IMPASSE|LIEU DIT|LOTISSEMENT|MARCHE|MONTEE|PASSAGE|PLACE|PLAINE|PLATEAU|PROMENADE|PARVIS|QUARTIER|QUAI|RESIDENCE|RUELLE|ROCADE|ROND POINT|ROUTE|RUE|SENTE   SENTIER|SQUARE|TERRE PLEIN|TRAVERSE|VILLA|VILLAGE)(?:(?= )|$)'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.download_file(\n",
    "'Parameters/TYPE_VOIE/typeVoieEtablissement.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'|'.join((pd.read_csv('typeVoieEtablissement.csv')\n",
    " .assign(voie_clean = lambda x: x['possibilite'].str.normalize(\n",
    "            'NFKD')\n",
    "        .str.encode('ascii', errors='ignore')\n",
    "        .str.decode('utf-8')\n",
    "        .str.replace('[^\\w\\s]', ' ')\n",
    "        .str.replace('^\\s+|\\s+$', '')\n",
    "        .str.upper()\n",
    "            )\n",
    "          )['voie_clean'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.read_csv('typeVoieEtablissement.csv')\n",
    " .assign(voie_clean = lambda x: x['possibilite'].str.normalize(\n",
    "            'NFKD')\n",
    "        .str.encode('ascii', errors='ignore')\n",
    "        .str.decode('utf-8')\n",
    "        .str.replace('[^\\w\\s]', ' ')\n",
    "        .str.replace('^\\s+|\\s+$', '')\n",
    "        .str.upper()\n",
    "            )\n",
    "          ).to_csv('type_voie.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.upload_file('type_voie.csv',\n",
    "               'Parameters/TYPE_VOIE_SQL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `type_voie` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.read_csv('typeVoieEtablissement.csv')\n",
    " .assign(voie_clean = lambda x: x['possibilite'].str.normalize(\n",
    "            'NFKD')\n",
    "        .str.encode('ascii', errors='ignore')\n",
    "        .str.decode('utf-8')\n",
    "        .str.replace('[^\\w\\s]', ' ')\n",
    "        .str.replace('^\\s+|\\s+$', '')\n",
    "        .str.upper()\n",
    "            )\n",
    "          ).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_['global']['Parameters']['type_voie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_create = \"\"\"\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS {0}.{1} (\n",
    "voie_matching string,\n",
    "possibilite string, \n",
    "voie_clean string\n",
    " )\n",
    "     ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'\n",
    "    WITH SERDEPROPERTIES (\n",
    "   'separatorChar' = ',',\n",
    "   'quoteChar' = '\"'\n",
    "   )\n",
    "     LOCATION '{2}'\n",
    "     TBLPROPERTIES ('has_encrypted_data'='false',\n",
    "              'skip.header.line.count'='1');\"\"\".format(\n",
    "    dic_['global']['database'],\n",
    "    'type_voie',\n",
    "    dic_['global']['Parameters']['type_voie'])\n",
    "\n",
    "output = athena.run_query(\n",
    "                            query=query_create,\n",
    "                            database=dic_['global']['database'],\n",
    "                            s3_output=dic_['global']['output']\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching entre la query de préparation des data et la table de la voie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT siren, adresse_ligne1, adresse_ligne2, adresse_ligne3, adress_nettoyee,adresse_inpi_reconstitue,adress_regex,\n",
    "numero_voie_matching, numero_voie_type_voie.voie_clean, voie_matching\n",
    "FROM type_voie   \n",
    "RIGHT JOIN (\n",
    "  SELECT siren, adresse_ligne1, adresse_ligne2, adresse_ligne3, adress_nettoyee,adresse_inpi_reconstitue,adress_regex,\n",
    "regexp_extract(adress_nettoyee,'\\d+') as numero_voie_matching,\n",
    "regexp_extract(adress_nettoyee, '(?:^|(?<= ))(ALLEE|AVENUE|BOULEVARD|CARREFOUR|CHEMIN|CHAUSSEE|CITE|CORNICHE|COURS|DOMAINE|DESCENTE|ECART|ESPLANADE|FAUBOURG|GRANDE RUE|HAMEAU|HALLE|IMPASSE|LIEU DIT|LOTISSEMENT|MARCHE|MONTEE|PASSAGE|PLACE|PLAINE|PLATEAU|PROMENADE|PARVIS|QUARTIER|QUAI|RESIDENCE|RUELLE|ROCADE|ROND POINT|ROUTE|RUE|SENTE   SENTIER|SQUARE|TERRE PLEIN|TRAVERSE|VILLA|VILLAGE)(?:(?= )|$)') as voie_clean \n",
    "  FROM create_regex\n",
    "  ) as numero_voie_type_voie\n",
    "ON numero_voie_type_voie.voie_clean = type_voie.voie_clean\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 4: Création `last_libele_evt` & `status_admin` & `status_ets`\n",
    "\n",
    "Le code SQL pour préparer ses deux variables:\n",
    "\n",
    "```\n",
    "### First \n",
    "/*add status etb*/\n",
    "CREATE TABLE inpi.ets_preparation_python_lib\n",
    "WITH (\n",
    "  format='PARQUET'\n",
    ") AS\n",
    "WITH convert_date AS (SELECT siren, code_greffe, nom_greffe, numero_gestion, id_etablissement,Coalesce(\n",
    "         try(date_parse(date_greffe, '%Y-%m-%d')),\n",
    "         try(date_parse(date_greffe, '%Y-%m-%d %hh:%mm:%ss.SSS')),\n",
    "         try(date_parse(date_greffe, '%Y-%m-%d %hh:%mm:%ss')),\n",
    "         try(cast(date_greffe as timestamp))\n",
    "  ) as date_greffe, libelle_evt\n",
    "FROM ets_preparation_python\n",
    ")\n",
    "\n",
    "SELECT ets_preparation_python.siren,ets_preparation_python.code_greffe, ets_preparation_python.nom_greffe, ets_preparation_python.numero_gestion, ets_preparation_python.id_etablissement, status, origin, file_timestamp, date_greffe, libelle_evt,last_libele_evt, type, adress_new, adresse_new_clean_reg, possibilite, insee as voie_matching, digit_inpi as numero_voie_matching, code_postal_matching, ncc, code_commune, enseigne, \"date_début_activité\", csv_source, index \n",
    "FROM ets_preparation_python \n",
    "\n",
    "INNER JOIN (SELECT\n",
    "convert_date.siren, convert_date.code_greffe, convert_date.nom_greffe, convert_date.numero_gestion, convert_date.id_etablissement, convert_date.libelle_evt as last_libele_evt, max_date_greffe\n",
    "FROM convert_date\n",
    "INNER JOIN  (SELECT siren, code_greffe, nom_greffe, numero_gestion, id_etablissement, MAX(Coalesce(\n",
    "         try(date_parse(date_greffe, '%Y-%m-%d')),\n",
    "         try(date_parse(date_greffe, '%Y-%m-%d %hh:%mm:%ss.SSS')),\n",
    "         try(date_parse(date_greffe, '%Y-%m-%d %hh:%mm:%ss')),\n",
    "         try(cast(date_greffe as timestamp))\n",
    "  )) as max_date_greffe\n",
    "FROM ets_preparation_python  \n",
    "GROUP BY siren, code_greffe, nom_greffe, numero_gestion, id_etablissement\n",
    "  ) AS temp\n",
    "ON temp.siren = convert_date.siren\n",
    "AND temp.code_greffe = convert_date.code_greffe\n",
    "AND temp.nom_greffe = convert_date.nom_greffe\n",
    "AND temp.numero_gestion = convert_date.numero_gestion\n",
    "AND temp.id_etablissement = convert_date.id_etablissement\n",
    "AND temp.max_date_greffe = convert_date.date_greffe) as latest_libele\n",
    "\n",
    "ON ets_preparation_python.siren = latest_libele.siren\n",
    "AND ets_preparation_python.code_greffe = latest_libele.code_greffe\n",
    "AND ets_preparation_python.nom_greffe = latest_libele.nom_greffe\n",
    "AND ets_preparation_python.numero_gestion = latest_libele.numero_gestion\n",
    "AND ets_preparation_python.id_etablissement = latest_libele.id_etablissement\n",
    "\n",
    "#### Seconds\n",
    "CREATE TABLE inpi.ets_preparation_python_lib1\n",
    "WITH (\n",
    "  format='PARQUET'\n",
    ") AS\n",
    "SELECT *,\n",
    "CASE WHEN last_libele_evt = 'Etablissement ouvert' THEN 'A' ELSE 'F' END AS status_admin,\n",
    "CASE WHEN type = 'SIE' OR type = 'SEP' THEN 'true' ELSE 'false' END AS status_ets\n",
    "FROM ets_preparation_python_lib\n",
    "ORDER BY siren, code_greffe, nom_greffe, numero_gestion, id_etablissement, date_greffe\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "      * \n",
    "    FROM \n",
    "      (\n",
    "        WITH convert_date AS (\n",
    "          SELECT \n",
    "            siren, \n",
    "            code_greffe, \n",
    "            nom_greffe, \n",
    "            numero_gestion, \n",
    "            id_etablissement, \n",
    "            Coalesce(\n",
    "              try(\n",
    "                date_parse(date_greffe, '%Y-%m-%d')\n",
    "              ), \n",
    "              try(\n",
    "                date_parse(\n",
    "                  date_greffe, '%Y-%m-%d %hh:%mm:%ss.SSS'\n",
    "                )\n",
    "              ), \n",
    "              try(\n",
    "                date_parse(\n",
    "                  date_greffe, '%Y-%m-%d %hh:%mm:%ss'\n",
    "                )\n",
    "              ), \n",
    "              try(\n",
    "                cast(date_greffe as timestamp)\n",
    "              )\n",
    "            ) as date_greffe, \n",
    "            libelle_evt \n",
    "          FROM \n",
    "            voie_type_voie\n",
    "        ) \n",
    "        SELECT \n",
    "          voie_type_voie.siren, \n",
    "          voie_type_voie.code_greffe, \n",
    "          voie_type_voie.nom_greffe, \n",
    "          voie_type_voie.numero_gestion, \n",
    "          voie_type_voie.id_etablissement, \n",
    "          status, \n",
    "          origin, \n",
    "          date_greffe, \n",
    "          file_timestamp, \n",
    "          libelle_evt, \n",
    "          last_libele_evt, \n",
    "          CASE WHEN last_libele_evt = 'Etablissement ouvert' THEN 'A' ELSE 'F' END AS status_admin,\n",
    "          type, \n",
    "          CASE WHEN type = 'SIE' OR type = 'SEP' THEN 'true' ELSE 'false' END AS status_ets,\n",
    "          \"siège_pm\", \n",
    "          rcs_registre, \n",
    "          adresse_ligne1, \n",
    "          adresse_ligne2, \n",
    "          adresse_ligne3, \n",
    "          adress_nettoyee, \n",
    "          adresse_inpi_reconstitue, \n",
    "          adress_regex, \n",
    "          numero_voie_matching, \n",
    "          voie_clean, \n",
    "          code_postal, \n",
    "          code_postal_matching, \n",
    "          ville, \n",
    "          ville_matching, \n",
    "          code_commune, \n",
    "          pays, \n",
    "          domiciliataire_nom, \n",
    "          domiciliataire_siren, \n",
    "          domiciliataire_greffe, \n",
    "          \"domiciliataire_complément\", \n",
    "          \"siege_domicile_représentant\", \n",
    "          nom_commercial, \n",
    "          enseigne, \n",
    "          \"activité_ambulante\", \n",
    "          \"activité_saisonnière\", \n",
    "          \"activité_non_sédentaire\", \n",
    "          \"date_début_activité\", \n",
    "          \"activité\", \n",
    "          origine_fonds, \n",
    "          origine_fonds_info, \n",
    "          type_exploitation, \n",
    "          csv_source, \n",
    "          rn \n",
    "        FROM \n",
    "          voie_type_voie \n",
    "          INNER JOIN (\n",
    "            SELECT \n",
    "              convert_date.siren, \n",
    "              convert_date.code_greffe, \n",
    "              convert_date.nom_greffe, \n",
    "              convert_date.numero_gestion, \n",
    "              convert_date.id_etablissement, \n",
    "              convert_date.libelle_evt as last_libele_evt, \n",
    "              max_date_greffe \n",
    "            FROM \n",
    "              convert_date \n",
    "              INNER JOIN (\n",
    "                SELECT \n",
    "                  siren, \n",
    "                  code_greffe, \n",
    "                  nom_greffe, \n",
    "                  numero_gestion, \n",
    "                  id_etablissement, \n",
    "                  MAX(\n",
    "                    Coalesce(\n",
    "                      try(\n",
    "                        date_parse(date_greffe, '%Y-%m-%d')\n",
    "                      ), \n",
    "                      try(\n",
    "                        date_parse(\n",
    "                          date_greffe, '%Y-%m-%d %hh:%mm:%ss.SSS'\n",
    "                        )\n",
    "                      ), \n",
    "                      try(\n",
    "                        date_parse(\n",
    "                          date_greffe, '%Y-%m-%d %hh:%mm:%ss'\n",
    "                        )\n",
    "                      ), \n",
    "                      try(\n",
    "                        cast(date_greffe as timestamp)\n",
    "                      )\n",
    "                    )\n",
    "                  ) as max_date_greffe \n",
    "                FROM \n",
    "                  voie_type_voie \n",
    "                GROUP BY \n",
    "                  siren, \n",
    "                  code_greffe, \n",
    "                  nom_greffe, \n",
    "                  numero_gestion, \n",
    "                  id_etablissement\n",
    "              ) AS temp ON temp.siren = convert_date.siren \n",
    "              AND temp.code_greffe = convert_date.code_greffe \n",
    "              AND temp.nom_greffe = convert_date.nom_greffe \n",
    "              AND temp.numero_gestion = convert_date.numero_gestion \n",
    "              AND temp.id_etablissement = convert_date.id_etablissement \n",
    "              AND temp.max_date_greffe = convert_date.date_greffe\n",
    "          ) as latest_libele ON voie_type_voie.siren = latest_libele.siren \n",
    "          AND voie_type_voie.code_greffe = latest_libele.code_greffe \n",
    "          AND voie_type_voie.nom_greffe = latest_libele.nom_greffe \n",
    "          AND voie_type_voie.numero_gestion = latest_libele.numero_gestion \n",
    "          AND voie_type_voie.id_etablissement = latest_libele.id_etablissement\n",
    "      )\n",
    "    ORDER BY siren, code_greffe, nom_greffe, numero_gestion, id_etablissement, date_greffe\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
