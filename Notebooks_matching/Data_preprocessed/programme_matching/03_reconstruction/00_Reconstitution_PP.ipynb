{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstitution INPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recreation du fichier INPI \n",
    "\n",
    "Le notebook comporte 4 parties:\n",
    "\n",
    "- Description champs [INPI ETS](https://github.com/thomaspernet/InseeInpi_matching/tree/master/Documentation/IMR#etablissements)\n",
    "\n",
    "1. Reconsitution Data\n",
    "    - Matched:\n",
    "        - Input:\n",
    "        - output: \n",
    "            - CSV: [03_siretisation/match/PP](https://s3.console.aws.amazon.com/s3/buckets/calfdata/INPI/TC_1/03_siretisation/match/PP/)\n",
    "            - Table: `inpi_siret_initial_partiel_ets_matched` \n",
    "    - Unmatched\n",
    "        - Input:\n",
    "        - output:\n",
    "            - CSV: [03_siretisation/Non_match/PP](https://s3.console.aws.amazon.com/s3/buckets/calfdata/INPI/TC_1/03_siretisation/Non_match/PP/)\n",
    "            - Table: `inpi_siret_initial_partiel_ets_unmatched`\n",
    "    - Treatement speciaux\n",
    "        - Input:\n",
    "        - output:\n",
    "            - CSV: [03_siretisation/special_treatment/ETS](https://s3.console.aws.amazon.com/s3/buckets/calfdata/INPI/TC_1/03_siretisation/special_treatment/PP/)\n",
    "            - Table: `inpi_siret_initial_partiel_ets_ts`\n",
    "2. Details sequence\n",
    "3. Rapport logs\n",
    "\n",
    "Comme la taille de la donnée est trop élevée, il faut prendre un sous échantillon pour faire la siretisation. Le sous échantillonage se fait avec l'origine. \n",
    "\n",
    "To Do: Ajouter la description des champs ajoutées\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "current_dir = os.getcwd()\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from inpi_insee import preparation_data\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awsPy.aws_authorization import aws_connector\n",
    "from awsPy.aws_s3 import service_s3\n",
    "from awsPy.aws_athena import service_athena\n",
    "bucket = 'calfdata'\n",
    "path_cred = \"{}/programme_matching/credential_AWS.json\".format(parent_path)\n",
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                        region = 'eu-west-3')\n",
    "client= con.client_boto()\n",
    "s3 = service_s3.connect_S3(client = client,\n",
    "                      bucket = 'calfdata') \n",
    "athena = service_athena.connect_athena(client = client,\n",
    "                      bucket = 'calfdata') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = \"InitialPartielEVTNEW\"\n",
    "filename = \"inpi_initial_partiel_evt_new_pp_status_final_InitialPartielEVTNEW_0.csv\"\n",
    "#origin = \"NEW\"\n",
    "#filename = \"inpi_initial_partiel_evt_new_ets_status_final_NEW_0.csv\"\n",
    "path_data_merge = \"programme_matching/data/output\"\n",
    "path_data_siren_inpi = \"programme_matching/data/input/SIREN_INPI\"\n",
    "path_data_initial = \"programme_matching/data/input/INPI\"\n",
    "path_data_st = \"programme_matching/data/input/INPI/special_treatment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes_or = {\n",
    "'siren': 'string',\n",
    " 'siret':'string',\n",
    " 'code_greffe': 'string',\n",
    " 'nom_greffe': 'string',\n",
    " 'numero_gestion': 'string'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconsitution Data\n",
    "\n",
    "Pour chaque categorie (Matched, Umatched, TS), 3 steps sont réalisées:\n",
    "\n",
    "- Append des csv/gz\n",
    "- Sauvegarde csv local\n",
    "- Upload dans le S3\n",
    "- Creation table Athena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matched\n",
    "\n",
    "- Input:\n",
    "    - CSV: \n",
    "        - `data/input/INPI` + `ORIGIN` + [`FILENAME` + `ORIGIN` +  `_O.csv`]\n",
    "            - ex: `data/input/INPI/NEW/inpi_initial_partiel_evt_new_ets_status_final_NEW_0.csv`\n",
    "        - `data/output/` + `ORIGIN` + [`i_FILENAME` + `ORIGIN` +  `_+[not_duplicate/pure_match].csv`]\n",
    "            - `data/output/NEW/0_inpi_initial_partiel_evt_new_ets_status_final_InitialPartielEVT_not_duplicate.gz`\n",
    "- output: \n",
    "    - CSV: [03_siretisation/match/ETS/](https://s3.console.aws.amazon.com/s3/buckets/calfdata/INPI/TC_1/03_siretisation/match/ETS/)\n",
    "    - Table: `inpi_siret_initial_partiel_ets_matched`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append des csv/gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_issue = []\n",
    "df_matched = pd.DataFrame()\n",
    "for root, dirs, files in os.walk(os.path.join(parent_path,path_data_merge,origin)):\n",
    "    for name in tqdm(files):\n",
    "        if name.endswith((\".gz\")):\n",
    "            path_gz = '{}/{}'.format(root, name)\n",
    "            df_ = pd.read_csv(path_gz, compression = 'gzip',low_memory = False, dtype= dtypes_or)\n",
    "            df_matched = df_matched.append(\n",
    "            df_\n",
    "            )\n",
    "df_inpi = pd.read_csv(\n",
    "    os.path.join(parent_path,path_data_initial,origin, filename),\n",
    "    dtype = {\n",
    "        'siren': 'string',\n",
    " 'code_greffe': 'string'\n",
    "        \n",
    "    },\n",
    "                      low_memory = False)\n",
    "df_inpi.shape[0] - df_matched.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df_inpi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inpi.loc[lambda x:\n",
    "            x['siren'].isin(['849981527'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inpi.merge(df_matched[\n",
    "    ['index','siret','origin_test','count_initial_insee', 'count_siren_siret',\n",
    "     'test_address_libelle','test_address_complement','test_join_address',\n",
    "     'test_date','test_1','test_siege','test_voie','test_numero',\n",
    "     'count_duplicates_final','count_duplicates_','test'\n",
    "     ]\n",
    "], on='index', how='inner').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegarde csv local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reindex = ['siren', 'siret','csv_source','code_greffe', 'nom_greffe',\n",
    "           'numero_gestion', 'origin',\n",
    "       'file_timestamp', 'date_greffe', 'libelle_evt', 'type',\n",
    "       'type_inscription', 'date_immatriculation', 'date_1re_immatriculation',\n",
    "       'date_radiation', 'date_transfert', 'sans_activite',\n",
    "       'date_debut_activite', 'date_debut_1re_activite',\n",
    "       'date_cessation_activite', 'nom_patronymique', 'nom_usage',\n",
    "       'pseudonyme', 'prenoms', 'date_naissance', 'ville_naissance',\n",
    "       'pays_naissance', 'nationalité', 'adresse_ligne1', 'adresse_ligne2',\n",
    "       'adresse_ligne3', 'adress_new', 'adresse_new_clean_reg', 'possibilite',\n",
    "       'INSEE', 'digit_inpi', 'list_digit_inpi', 'len_digit_address_inpi',\n",
    "       'code_postal_matching', 'ville', 'ncc', 'code_commune',\n",
    "       'count_initial_inpi', 'pays', 'activite_forain', 'eirl',\n",
    "       'auto_entrepreneur', 'dap', 'dap_denomination', 'dap_objet',\n",
    "       'dap_date_cloture', 'dap_adresse_ligne1', 'dap_adresse_ligne2',\n",
    "       'dap_adresse_ligne3', 'dap_code_postal', 'dap_ville',\n",
    "       'dap_code_commune', 'dap_pays', 'conjoint_collab_nom_patronym',\n",
    "       'conjoint_collab_nom_usage', 'conjoint_collab_pseudo',\n",
    "       'conjoint_collab_prenoms', 'conjoint_collab_date_fin', 'max_partiel'\n",
    "        , 'origin_test', 'count_initial_insee',\n",
    "       'count_siren_siret', 'test_address_libelle', 'test_address_complement',\n",
    "       'test_join_address', 'test_date', 'test_1', 'test_siege', 'test_voie',\n",
    "       'test_numero', 'count_duplicates_final', 'count_duplicates_', 'test', 'index']\n",
    "\n",
    "\n",
    "df_matched_full = df_inpi.merge(df_matched[\n",
    "    ['index','siret','origin_test','count_initial_insee', 'count_siren_siret',\n",
    "     'test_address_libelle','test_address_complement','test_join_address',\n",
    "     'test_date','test_1','test_siege','test_voie','test_numero',\n",
    "     'count_duplicates_final','count_duplicates_','test'\n",
    "     ]\n",
    "], on='index', how='inner').reindex(columns = reindex)\n",
    "\n",
    "path_save = '{}/programme_matching/data/' \\\n",
    "'inpi_initial_partiel_evt_pp_status_final_{}.csv'.format(parent_path,\n",
    "                                                        df_matched_full.shape[0]\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matched_full.to_csv(\n",
    "    path_save\n",
    "    .format(\n",
    "    df_matched_full.shape[0]),\n",
    "    index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matched_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload data dans le S3: [03_siretisation/match/PP/](https://s3.console.aws.amazon.com/s3/buckets/calfdata/INPI/TC_1/03_siretisation/match/PP/) et creation table dans Athena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'INPI/TC_1/03_siretisation/match/PP'\n",
    "s3.upload_file(\n",
    "    file_to_upload = path_save,\n",
    "    destination_in_s3 = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(path_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = \"inpi\"\n",
    "table_name = \"inpi_siret_initial_partiel_pp_matched\"\n",
    "key_input = \"s3://calfdata/INPI/TC_1/03_siretisation/match/PP\"\n",
    "\n",
    "query = \"\"\"\n",
    "DROP TABLE `{}`;\n",
    "\"\"\".format(table_name)\n",
    "athena.run_query(\n",
    "    query=query,\n",
    "    database='inpi',\n",
    "    s3_output='INPI/sql_output'\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = \"inpi\"\n",
    "table_name = \"inpi_siret_initial_partiel_pp_matched\"\n",
    "key_input = \"s3://calfdata/INPI/TC_1/03_siretisation/match/PP\"\n",
    "\n",
    "s3_ouput = 'INPI/sql_output'\n",
    "col_type = \"\"\"CREATE EXTERNAL TABLE IF NOT EXISTS {}.{}(\\n\"\"\".format(db,\n",
    "                                                                     table_name)\n",
    "for v, name in enumerate(reindex):\n",
    "    type_ = 'string'\n",
    "    if v != len(reindex) -1:\n",
    "        text = \"`{}` {},\\n\".format(name, type_)\n",
    "    else:\n",
    "        text = \"`{}` {}\\n)\".format(name, type_)\n",
    "    col_type += text\n",
    "bottom = \"\"\"\\n\n",
    "     ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'\n",
    "    WITH SERDEPROPERTIES (\n",
    "    'serialization.null.format'='',\n",
    "   'separatorChar' = ',',\n",
    "   'quoteChar' = '\"',\n",
    "   'escapeChar' = '\\\\\\\\'\n",
    "   )\n",
    "     LOCATION '{}'\n",
    "     TBLPROPERTIES ('has_encrypted_data'='false',\n",
    "              'skip.header.line.count'='1');\n",
    "\"\"\"\n",
    "create_table = col_type +  bottom.format(key_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Athena database and table definition\n",
    "\n",
    "output= athena.run_query(\n",
    "    query = create_table,\n",
    "    database = db,\n",
    "    s3_output = s3_ouput\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### non matched Treatment speciaux\n",
    "\n",
    "- Input:\n",
    "    - CSV: \n",
    "        - `data/INPI/special_treatment` + `ORIGIN` + [`i_ FILENAME` + `ORIGIN` +`.gz`]\n",
    "            - `data/INPI/special_treatment/`\n",
    "            - `0_inpi_initial_partiel_evt_new_ets_status_final_InitialPartielEVT_special_treatment.gz`\n",
    "- output: \n",
    "    - CSV: [03_siretisation/special_treatment/ETS/](https://s3.console.aws.amazon.com/s3/buckets/calfdata/INPI/TC_1/03_siretisation/special_treatment/ETS/)\n",
    "    - Table: `inpi_siret_initial_partiel_ets_TS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts = pd.DataFrame()\n",
    "for root, dirs, files in os.walk(os.path.join(parent_path,path_data_st,origin)):\n",
    "    for name in tqdm(files):\n",
    "        if name.endswith((\".gz\")):\n",
    "            path_gz = '{}/{}'.format(root, name)\n",
    "            df_ = pd.read_csv(path_gz, compression = 'gzip',low_memory = False)\n",
    "            df_ts = df_ts.append(\n",
    "            df_\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegarde csv local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_save = '{}/programme_matching/data/' \\\n",
    "'inpi_initial_partiel_evt_pp_status_final_TS_{}.csv'.format(parent_path,\n",
    "                                                        df_ts.shape[0]\n",
    "                                                        )\n",
    "df_ts.to_csv(\n",
    "    path_save\n",
    "    .format(\n",
    "    df_ts.shape[0]),\n",
    "    index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload data dans le S3: [03_siretisation/special_treatment/PP/](https://s3.console.aws.amazon.com/s3/buckets/calfdata/INPI/TC_1/03_siretisation/special_treatment/PP/) et creation table dans Athena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'INPI/TC_1/03_siretisation/special_treatment/PP'\n",
    "s3.upload_file(\n",
    "    file_to_upload = path_save,\n",
    "    destination_in_s3 = key)\n",
    "os.remove(path_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = \"inpi\"\n",
    "table_name = \"inpi_siret_initial_partiel_pp_TS\"\n",
    "key_input = \"s3://calfdata/INPI/TC_1/03_siretisation/special_treatment/PP\"\n",
    "\n",
    "query = \"\"\"\n",
    "DROP TABLE `{}`;\n",
    "\"\"\".format(table_name)\n",
    "athena.run_query(\n",
    "    query=query,\n",
    "    database='inpi',\n",
    "    s3_output='INPI/sql_output'\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tb = \\\n",
    "    \"\"\"CREATE EXTERNAL TABLE IF NOT EXISTS {0}.{1} (\n",
    "`siren` string, \n",
    " `type` string, \n",
    " `date_debut_activite` string, \n",
    " `adress_new` string, \n",
    " `adresse_new_clean_reg` string, \n",
    " `INSEE` string, \n",
    " `digit_inpi` string, \n",
    " `list_digit_inpi` string, \n",
    " `len_digit_address_inpi` string, \n",
    " `code_postal` string, \n",
    " `ville` string, \n",
    " `ncc` string, \n",
    " `code_commune` string, \n",
    " `count_initial_inpi` string, \n",
    " `pays` string, \n",
    " `index` string, \n",
    " `siret` string, \n",
    " `dateCreationEtablissement` string, \n",
    " `count_initial_insee` string, \n",
    " `etablissementSiege` string, \n",
    " `complementAdresseEtablissement` string, \n",
    " `numeroVoieEtablissement` string, \n",
    " `indiceRepetitionEtablissement` string, \n",
    " `typeVoieEtablissement` string, \n",
    " `libelleVoieEtablissement` string, \n",
    " `len_digit_address_insee` string, \n",
    " `list_digit_insee` string, \n",
    " `codePostalEtablissement` string, \n",
    " `libelleCommuneEtablissement` string, \n",
    " `libelleCommuneEtrangerEtablissement` string, \n",
    " `distributionSpecialeEtablissement` string, \n",
    " `codeCommuneEtablissement` string, \n",
    " `codeCedexEtablissement` string, \n",
    " `libelleCedexEtablissement` string, \n",
    " `codePaysEtrangerEtablissement` string, \n",
    " `libellePaysEtrangerEtablissement` string, \n",
    " `etatAdministratifEtablissement` string, \n",
    " `count_duplicates_` string, \n",
    " `origin_test` string, \n",
    " `count_siren_siret` string, \n",
    " `test_address_libelle` string, \n",
    " `test_address_complement` string, \n",
    " `test_join_address` string, \n",
    " `test_date` string, \n",
    " `test_1` string, \n",
    " `test_siege` string, \n",
    " `test_voie` string, \n",
    " `test_numero` string, \n",
    " `count_duplicates_final` string)\n",
    "    ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' \n",
    "    WITH SERDEPROPERTIES ( 'separatorChar' = ',', 'quoteChar' = '\"' ) \n",
    "    LOCATION '{2}' \n",
    "    TBLPROPERTIES ('has_encrypted_data'='false', 'skip.header.line.count'='1');\n",
    "\"\"\".format(db,table_name,key_input)\n",
    "athena.run_query(\n",
    "    query=query_tb,\n",
    "    database='inpi',\n",
    "    s3_output='INPI/sql_output'\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unmatched\n",
    "\n",
    "- Input:\n",
    "    - Pandas DataFrame:\n",
    "        - `df_inpi`: Créer en step 1\n",
    "    - List `index` des matches: via DataFrame step 1\n",
    "        - `df_matched_full['index']`\n",
    "- output: \n",
    "    - CSV: [03_siretisation/Non_match/ETS/](https://s3.console.aws.amazon.com/s3/buckets/calfdata/INPI/TC_1/03_siretisation/Non_match/ETS/)\n",
    "    - Table: `inpi_siret_initial_partiel_ets_Unmatched`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegarde csv local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_save = '{}/programme_matching/data/' \\\n",
    "'inpi_initial_partiel_evt_pp_status_final_unmatched_{}.csv'.format(parent_path,\n",
    "                                                        df_inpi.shape[0] - df_matched.shape[0]\n",
    "                                                        )\n",
    "df_inpi.loc[lambda x: \n",
    "            ~x['index'].isin(df_matched_full['index'].to_list())\n",
    "           ].to_csv(\n",
    "    path_save\n",
    "    .format(\n",
    "    df_ts.shape[0]),\n",
    "    index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_col_unmatched = df_inpi.loc[lambda x: \n",
    "            ~x['index'].isin(df_matched_full['index'].to_list())\n",
    "           ].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload data dans le S3: [03_siretisation/Non_match/PP/](https://s3.console.aws.amazon.com/s3/buckets/calfdata/INPI/TC_1/03_siretisation/Non_match/PP/) et creation table dans Athena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'INPI/TC_1/03_siretisation/Non_match/PP'\n",
    "s3.upload_file(\n",
    "    file_to_upload = path_save,\n",
    "    destination_in_s3 = key)\n",
    "os.remove(path_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = \"inpi\"\n",
    "table_name = \"inpi_siret_initial_partiel_pp_Unmatched\"\n",
    "key_input = \"s3://calfdata/INPI/TC_1/03_siretisation/Non_match/PP\"\n",
    "\n",
    "query = \"\"\"\n",
    "DROP TABLE `{}`;\n",
    "\"\"\".format(table_name)\n",
    "athena.run_query(\n",
    "    query=query,\n",
    "    database='inpi',\n",
    "    s3_output='INPI/sql_output'\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_ouput = 'INPI/sql_output'\n",
    "col_type = \"\"\"CREATE EXTERNAL TABLE IF NOT EXISTS {}.{}(\\n\"\"\".format(db,\n",
    "                                                                     table_name)\n",
    "for v, name in enumerate(list_col_unmatched):\n",
    "    type_ = 'string'\n",
    "    if v != len(list_col_unmatched) -1:\n",
    "        text = \"`{}` {},\\n\".format(name, type_)\n",
    "    else:\n",
    "        text = \"`{}` {}\\n)\".format(name, type_)\n",
    "    col_type += text\n",
    "bottom = \"\"\"\\n\n",
    "     ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'\n",
    "    WITH SERDEPROPERTIES (\n",
    "    'serialization.null.format'='',\n",
    "   'separatorChar' = ',',\n",
    "   'quoteChar' = '\"',\n",
    "   'escapeChar' = '\\\\\\\\'\n",
    "   )\n",
    "     LOCATION '{}'\n",
    "     TBLPROPERTIES ('has_encrypted_data'='false',\n",
    "              'skip.header.line.count'='1');\n",
    "\"\"\"\n",
    "create_table = col_type +  bottom.format(key_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Athena database and table definition\n",
    "\n",
    "output= athena.run_query(\n",
    "    query = create_table,\n",
    "    database = db,\n",
    "    s3_output = s3_ouput\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(parent_path,path_data_initial,origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(os.path.join(parent_path,path_data_merge,origin)):\n",
    "    for name in tqdm(files):\n",
    "        if name.endswith((\".gz\")):\n",
    "            path_gz = '{}/{}'.format(root, name)\n",
    "            os.remove(path_gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(os.path.join(parent_path,path_data_st,origin)):\n",
    "    for name in tqdm(files):\n",
    "        if name.endswith((\".gz\")):\n",
    "            path_gz = '{}/{}'.format(root, name)\n",
    "            os.remove(path_gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(os.path.join(parent_path,path_data_initial,origin)):\n",
    "    for name in tqdm(files):\n",
    "        if name.endswith((\".csv\")):\n",
    "            path_gz = '{}/{}'.format(root, name)\n",
    "            os.remove(path_gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(os.path.join(parent_path,path_data_siren_inpi,origin)):\n",
    "    for name in tqdm(files):\n",
    "        if name.endswith((\".csv\")):\n",
    "            path_gz = '{}/{}'.format(root, name)\n",
    "            os.remove(path_gz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(os.path.join(parent_path,path_data_initial,origin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(os.path.join(parent_path,path_data_st,origin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(os.path.join(parent_path,path_data_merge,origin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(os.path.join(parent_path,path_data_siren_inpi,origin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Data\n",
    "\n",
    "- Input: Déjà dans le S3\n",
    "    - CSV: \n",
    "        - `INSEE/00_rawData/StockEtablissement_utf8.csv`\n",
    "- output: \n",
    "    - CSV: [01_preparation/ETS/](https://s3.console.aws.amazon.com/s3/buckets/calfdata/INSEE/00_rawData/)\n",
    "    - Table: `insee_rawdata`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = \"inpi\"\n",
    "table_name = \"insee_rawdata\"\n",
    "key_input = \"s3://calfdata/INSEE/00_rawData\"\n",
    "\n",
    "query_tb = \\\n",
    "    \"\"\"CREATE EXTERNAL TABLE IF NOT EXISTS {0}.{1} (\n",
    "`siren`   string, \n",
    " `nic`   string, \n",
    " `siret`   string, \n",
    " `statutDiffusionEtablissement`   string, \n",
    " `dateCreationEtablissement`   string, \n",
    " `trancheEffectifsEtablissement`   string, \n",
    " `anneeEffectifsEtablissement`   string, \n",
    " `activitePrincipaleRegistreMetiersEtablissement`   string, \n",
    " `dateDernierTraitementEtablissement`   string, \n",
    " `etablissementSiege`   string, \n",
    " `nombrePeriodesEtablissement`   string, \n",
    " `complementAdresseEtablissement`   string, \n",
    " `numeroVoieEtablissement`   string, \n",
    " `indiceRepetitionEtablissement`   string, \n",
    " `typeVoieEtablissement`   string, \n",
    " `libelleVoieEtablissement`   string, \n",
    " `codePostalEtablissement`   string, \n",
    " `libelleCommuneEtablissement`   string, \n",
    " `libelleCommuneEtrangerEtablissement`   string, \n",
    " `distributionSpecialeEtablissement`   string, \n",
    " `codeCommuneEtablissement`   string, \n",
    " `codeCedexEtablissement`   string, \n",
    " `libelleCedexEtablissement`   string, \n",
    " `codePaysEtrangerEtablissement`   string, \n",
    " `libellePaysEtrangerEtablissement`   string, \n",
    " `complementAdresse2Etablissement`   string, \n",
    " `numeroVoie2Etablissement`   string, \n",
    " `indiceRepetition2Etablissement`   string, \n",
    " `typeVoie2Etablissement`   string, \n",
    " `libelleVoie2Etablissement`   string, \n",
    " `codePostal2Etablissement`   string, \n",
    " `libelleCommune2Etablissement`   string, \n",
    " `libelleCommuneEtranger2Etablissement`   string, \n",
    " `distributionSpeciale2Etablissement`   string, \n",
    " `codeCommune2Etablissement`   string, \n",
    " `codeCedex2Etablissement`   string, \n",
    " `libelleCedex2Etablissement`   string, \n",
    " `codePaysEtranger2Etablissement`   string, \n",
    " `libellePaysEtranger2Etablissement`   string, \n",
    " `dateDebut`   string, \n",
    " `etatAdministratifEtablissement`   string, \n",
    " `enseigne1Etablissement`   string, \n",
    " `enseigne2Etablissement`   string, \n",
    " `enseigne3Etablissement`   string, \n",
    " `denominationUsuelleEtablissement`   string, \n",
    " `activitePrincipaleEtablissement`   string, \n",
    " `nomenclatureActivitePrincipaleEtablissement`   string, \n",
    " `caractereEmployeurEtablissement` string\n",
    "\n",
    "    )\n",
    "     ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'\n",
    "    WITH SERDEPROPERTIES (\n",
    "   'separatorChar' = ',',\n",
    "   'quoteChar' = '\"'\n",
    "   )\n",
    "     LOCATION '{2}'\n",
    "     TBLPROPERTIES ('has_encrypted_data'='false',\n",
    "              'skip.header.line.count'='1');\"\"\".format(db,table_name,key_input)\n",
    "athena.run_query(\n",
    "    query=query_tb,\n",
    "    database='inpi',\n",
    "    s3_output='INPI/sql_output'\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data préparée\n",
    "\n",
    "- Input:\n",
    "    - CSV: \n",
    "        - `data/input/INSEE/` + `ORIGIN` + [`insee` + `size`+`ORIGIN` +`.csv`]\n",
    "            - `data/input/INSEE/InitialPartielEVT/insee_8272605_InitialPartielEVT.csv`\n",
    "- output: \n",
    "    - CSV: [01_preparation/PP/](https://s3.console.aws.amazon.com/s3/buckets/calfdata/INSEE/01_preparation/PP/)\n",
    "    - Table: `insee_siret_initial_partiel_ets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ = {\n",
    "    'InitialPartielEVTNEW':\"insee_1557220_InitialPartielEVTNEW\",\n",
    "    #'NEW':\"insee_1745311_NEW\",\n",
    "}\n",
    "key_s3 = \"INSEE/01_preparation/PP\"\n",
    "\n",
    "for key, value in dic_.items():\n",
    "    path_insee = 'programme_matching/' \\\n",
    "'data/input/INSEE/{0}/{1}.csv'.format(key, value)\n",
    "    s3.upload_file(\n",
    "    file_to_upload = os.path.join(parent_path, path_insee),\n",
    "    destination_in_s3 = key_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(os.path.join(parent_path, path_insee))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(parent_path, \"data/input/INSEE\", origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = \"inpi\"\n",
    "table_name = \"insee_siret_initial_partiel_pp\"\n",
    "key_input = \"s3://calfdata/INSEE/01_preparation/PP\"\n",
    "\n",
    "query = \"\"\"\n",
    "DROP TABLE `{}`;\n",
    "\"\"\".format(table_name)\n",
    "athena.run_query(\n",
    "    query=query,\n",
    "    database='inpi',\n",
    "    s3_output='INPI/sql_output'\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tb = \\\n",
    "    \"\"\"CREATE EXTERNAL TABLE IF NOT EXISTS {0}.{1} (\n",
    "`siren`   string, \n",
    " `siret`   string, \n",
    " `dateCreationEtablissement`   string, \n",
    " `count_initial_insee`   string, \n",
    " `etablissementSiege`   string, \n",
    " `complementAdresseEtablissement`   string, \n",
    " `numeroVoieEtablissement`   string, \n",
    " `indiceRepetitionEtablissement`   string, \n",
    " `typeVoieEtablissement`   string, \n",
    " `libelleVoieEtablissement`   string, \n",
    " `len_digit_address_insee`   string, \n",
    " `list_digit_insee`   string, \n",
    " `codePostalEtablissement`   string, \n",
    " `libelleCommuneEtablissement`   string, \n",
    " `libelleCommuneEtrangerEtablissement`   string, \n",
    " `distributionSpecialeEtablissement`   string, \n",
    " `codeCommuneEtablissement`   string, \n",
    " `codeCedexEtablissement`   string, \n",
    " `libelleCedexEtablissement`   string, \n",
    " `codePaysEtrangerEtablissement`   string, \n",
    " `libellePaysEtrangerEtablissement`   string, \n",
    " `etatAdministratifEtablissement`   string, \n",
    " `index` string\n",
    "\n",
    "    )\n",
    "     ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'\n",
    "    WITH SERDEPROPERTIES (\n",
    "   'separatorChar' = ',',\n",
    "   'quoteChar' = '\"'\n",
    "   )\n",
    "     LOCATION '{2}'\n",
    "     TBLPROPERTIES ('has_encrypted_data'='false',\n",
    "              'skip.header.line.count'='1');\"\"\".format(db,table_name,key_input)\n",
    "\n",
    "athena.run_query(\n",
    "    query=query_tb,\n",
    "    database='inpi',\n",
    "    s3_output='INPI/sql_output'\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération Detail sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inpi_insee import siretisation\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siretisation.crate_graph_report_test(df_matched_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siretisation.create_graph_report(df_matched_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rapport sur les logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, json\n",
    "import pandas as pd\n",
    "data = []\n",
    "#os.chdir(r\"data\\logs\\\")\n",
    "for file in glob.glob(\"{}/programme_matching/data/logs/{}/*.json\".format(parent_path,\n",
    "                                                                         origin)):\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = pd.json_normalize(data)\n",
    "logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre de lignes sirétisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs[['total_match_rows_current']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pourcentage de lignes sirétisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs[['perc_total_match_rows_initial']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre de lignes ayant été trouvé à l'INSEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs[['perc_total_match_siren_initial']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphique sur la séquence ayant aidée à la sirétisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs[['perc_total_match_rows_initial',\n",
    "      'perc_total_match_siren_initial']].plot.bar(stacked=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphique sur la séquence avec le nombre de lignes sirétisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs[['total_match_rows_current']].plot.bar(stacked=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre de SIREN et index non sirétisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs[[\"df_duplication.df_sp_index.nb_index\",\n",
    "      'df_duplication.df_sp_index.unique_siren']].plot.bar(stacked=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test generation SIREN aléatoire\n",
    "\n",
    "Utile pour faire des vérifications dans l'App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "df_matched_full.loc[np.random.randint(low= 1, high= 7000000, size=1)[0]].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matched_full.loc[lambda x: x['siren'].isin(['448416636'])].reset_index()#.T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
