{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Test nombre lignes siretise\n",
        "\n",
        "Copy paste from Coda to fill the information\n",
        "\n",
        "## Objective(s)\n",
        "\n",
        "\n",
        "\n",
        "## Metadata \n",
        "\n",
        "* Metadata parameters are available here: \n",
        "* Task type:\n",
        "  * \n",
        "* Users: :\n",
        "  * \n",
        "* Watchers:\n",
        "  * \n",
        "* Estimated Log points:\n",
        "  * One being a simple task, 15 a very difficult one\n",
        "  *  \n",
        "* Task tag\n",
        "  *  \n",
        "* Toggl Tag\n",
        "  * \n",
        "* Instance [AWS/GCP]\n",
        "  *   \n",
        "  \n",
        "## Input Cloud Storage [AWS/GCP]\n",
        "\n",
        "If link from the internet, save it to the cloud first\n",
        "\n",
        "### Tables [AWS/BigQuery]\n",
        "\n",
        "1. Batch 1:\n",
        "  * Select Provider: \n",
        "  * Select table(s): \n",
        "    * Select only tables created from the same notebook, else copy/paste selection to add new input tables\n",
        "    * If table(s) does not exist, add them: Add New Table\n",
        "    * Information:\n",
        "      * Region: \n",
        "        * Name: \n",
        "        * Code: \n",
        "      * Database: \n",
        "      * Notebook construction file: \n",
        "    \n",
        "## Destination Output/Delivery\n",
        "\n",
        "* AWS\n",
        "  1. Athena: \n",
        "      * Region: \n",
        "      * Database: \n",
        "      * Tables (Add name new table): \n",
        "\n",
        "## Things to know (Steps, Attention points or new flow of information)\n",
        "\n",
        "### Sources of information  (meeting notes, Documentation, Query, URL)\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connexion serveur"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from awsPy.aws_authorization import aws_connector\n",
        "from awsPy.aws_athena import service_athena\n",
        "from awsPy.aws_s3 import service_s3\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, shutil\n",
        "bucket = 'calfdata'\n",
        "path = os.getcwd()\n",
        "parent_path = str(Path(path).parent)\n",
        "path_cred = r\"{}/credential_AWS.json\".format(parent_path)\n",
        "\n",
        "region = ''\n",
        "bucket = ''"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "con = aws_connector.aws_instantiate(credential = path_cred,\n",
        "                                       region = region)\n",
        "client= con.client_boto()\n",
        "s3 = service_s3.connect_S3(client = client,\n",
        "                      bucket = bucket, verbose = False) \n",
        "#athena = service_athena.connect_athena(client = client,\n",
        "#                      bucket = bucket) \n",
        "region = 'XX'\n",
        "bucket = 'XX'\n",
        "s3_output = 'XX'"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "cm = sns.light_palette(\"green\", as_cmap=True)\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creation tables\n",
        "\n",
        "## Steps"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "output = s3.run_query(\n",
        "            query=query,\n",
        "            database='',\n",
        "            s3_output='',\n",
        "  filename = None, ## Add filename to print dataframe\n",
        "  destination_key = None ### Add destination key if need to copy output\n",
        "        )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generation report"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, shutil, urllib, ipykernel, json\n",
        "from pathlib import Path\n",
        "from notebook import notebookapp"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def create_report(extension = \"html\"):\n",
        "    \"\"\"\n",
        "    Create a report from the current notebook and save it in the \n",
        "    Report folder (Parent-> child directory)\n",
        "    \n",
        "    1. Exctract the current notbook name\n",
        "    2. Convert the Notebook \n",
        "    3. Move the newly created report\n",
        "    \n",
        "    Args:\n",
        "    extension: string. Can be \"html\", \"pdf\", \"md\"\n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    ### Get notebook name\n",
        "    connection_file = os.path.basename(ipykernel.get_connection_file())\n",
        "    kernel_id = connection_file.split('-', 1)[0].split('.')[0]\n",
        "\n",
        "    for srv in notebookapp.list_running_servers():\n",
        "        try:\n",
        "            if srv['token']=='' and not srv['password']:  \n",
        "                req = urllib.request.urlopen(srv['url']+'api/sessions')\n",
        "            else:\n",
        "                req = urllib.request.urlopen(srv['url']+ \\\n",
        "                                             'api/sessions?token=' + \\\n",
        "                                             srv['token'])\n",
        "            sessions = json.load(req)\n",
        "            notebookname = sessions[0]['name']\n",
        "        except:\n",
        "            pass  \n",
        "    \n",
        "    sep = '.'\n",
        "    path = os.getcwd()\n",
        "    #parent_path = str(Path(path).parent)\n",
        "    \n",
        "    ### Path report\n",
        "    #path_report = \"{}/Reports\".format(parent_path)\n",
        "    #path_report = \"{}/Reports\".format(path)\n",
        "    \n",
        "    ### Path destination\n",
        "    name_no_extension = notebookname.split(sep, 1)[0]\n",
        "    source_to_move = name_no_extension +'.{}'.format(extension)\n",
        "    dest = os.path.join(path,'Reports', source_to_move)\n",
        "    \n",
        "    ### Generate notebook\n",
        "    os.system('jupyter nbconvert --no-input --to {} {}'.format(\n",
        "    extension,notebookname))\n",
        "    \n",
        "    ### Move notebook to report folder\n",
        "    #time.sleep(5)\n",
        "    shutil.move(source_to_move, dest)\n",
        "    print(\"Report Available at this adress:\\n {}\".format(dest))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "create_report(extension = \"html\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "jupytext": {
      "formats": "ipynb,md"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "nteract": {
      "version": "0.24.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}