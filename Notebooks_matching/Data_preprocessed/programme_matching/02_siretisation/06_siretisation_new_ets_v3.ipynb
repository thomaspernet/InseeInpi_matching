{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siretisation Version 3: SQL\n",
    "\n",
    "## Etape \n",
    "\n",
    "Décrire les étapes de siretisation en SQL \n",
    "\n",
    "US potentielles\n",
    "Creation table rapprochement INSEE/INPI\n",
    "1. US 1 match sur siren + ville + code postal\n",
    "  1. US: US 01 rapprochement INSEE INPI\n",
    "  2. US taiga:\n",
    "Création règles de gestion\n",
    "1. US 2 Création Levenshtein \n",
    "  1. US US 02 Variables regles de gestion\n",
    "  2. US taiga:\n",
    "2. US 3 Création Jaccard\n",
    "  1. US US 02 Variables regles de gestion\n",
    "  2. US taiga:\n",
    "3. US 4 Creation Regex\n",
    "  1.  US US 02 Variables regles de gestion\n",
    "  2. US taiga:\n",
    "4. US 5 Récupération minimum Levenshtein + Jaccard\n",
    "  1. US XX\n",
    "  2. US taiga:\n",
    "5. US 6 Tests de logique\n",
    "  1. US XX\n",
    "  2. US taiga:\n",
    "Dedoublonnage\n",
    "1. US 6 Filtre selon règles de séparation\n",
    "  1. US XX\n",
    "  2.  US taiga:\n",
    "2. US 7 Création indicateur de doublons\n",
    "  1. Meme séquence, plusieurs siret → adresse différente au cours d’une séquence (ici, l’index est différent)\n",
    "  2. Meme index, plusieurs siret → adresse très similaire entre deux siret (ici, l’index est identique)\n",
    "  3. US XX\n",
    "  4.  US taiga:\n",
    "3. US 8 Récupération index unique et siret unique\n",
    "  1. US XX\n",
    "  2.  US taiga:\n",
    "Deduction siret sur séquence\n",
    "1. US 9 Attribution du siret sur une séquence\n",
    "  1. US XX\n",
    "  2. US taiga:\n",
    "  \n",
    "## Input\n",
    "\n",
    "* Athena \n",
    "    * region: eu-west-3 \n",
    "    * Database: inpi \n",
    "    *  Table: ets_final_sql \n",
    "      * Notebook construction file (data lineage) \n",
    "        * md : [03_ETS_add_variables.md](https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/01_preparation/03_ETS_add_variables.md)\n",
    "    *  Table: insee_final_sql \n",
    "      * Notebook construction file (data lineage) \n",
    "        * md : [04_ETS_add_variables_insee.md](https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/01_preparation/04_ETS_add_variables_insee.md)\n",
    "\n",
    "## Ouput\n",
    "\n",
    "* Athena: \n",
    "    * region: eu-west-3 \n",
    "    * Database: inpi \n",
    "    *  Table: ets_insee_inpi "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connexion serveru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awsPy.aws_authorization import aws_connector\n",
    "from awsPy.aws_athena import service_athena\n",
    "from awsPy.aws_s3 import service_s3\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os, shutil\n",
    "bucket = 'calfdata'\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent)\n",
    "path_cred = r\"{}/credential_AWS.json\".format(parent_path)\n",
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = 'eu-west-3')\n",
    "client= con.client_boto()\n",
    "s3 = service_s3.connect_S3(client = client,\n",
    "                      bucket = 'calfdata') \n",
    "athena = service_athena.connect_athena(client = client,\n",
    "                      bucket = 'calfdata') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametres et fonctions\n",
    "\n",
    "- `split_duplication`: Split un dataframe si l'index (la variable, pas l'index) contient des doublons\n",
    "- `find_regex`: Performe une recherche regex entre deux colonnes\n",
    "- `jackard_distance`: Calcul l'indice de dissimilarité entre deux colonnes\n",
    "- `edit_distance`: Calcul le nombre de modification a faire pour obtenir la même séquence\n",
    "- `import_dask`: Charge csv en Dask DataFrame pour clusteriser les calculs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 1: rapprochement INSEE-INPI\n",
    "\n",
    "*  Rapprocher la table de l’INSEE avec celle de l’INPI avec les variables de matching suivantes:\n",
    "   * siren\n",
    "   * ville_matching  → ville_matching\n",
    "   * code_postal_matching  → codepostaletablissement \n",
    "* La première query consiste à rapprocher les deux tables INPI & INSEE [NEW]\n",
    "   \n",
    "### test Acceptance \n",
    "\n",
    "1. Compter nombre de lignes après match\n",
    "  1. 11957437"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "/*matching ets inpi insee*/\n",
    "CREATE TABLE inpi.ets_insee_inpi\n",
    "WITH (\n",
    "  format='PARQUET'\n",
    ") AS\n",
    "  SELECT \n",
    "  index_id, \n",
    "  sequence_id, \n",
    "  count_initial_insee,\n",
    "  ets_final_sql.siren, \n",
    "  code_greffe, \n",
    "  nom_greffe, \n",
    "  numero_gestion, \n",
    "  id_etablissement, \n",
    "  status, \n",
    "  origin,\n",
    "  date_greffe, \n",
    "  file_timestamp,\n",
    "  datecreationetablissement,\n",
    "  \"date_début_activité\",\n",
    "  libelle_evt, \n",
    "  last_libele_evt,\n",
    "  etatadministratifetablissement, \n",
    "  status_admin, \n",
    "  type, \n",
    "  etablissementsiege,\n",
    "  status_ets, \n",
    "  adress_reconstituee_inpi,\n",
    "  adress_regex_inpi,\n",
    "  adress_distance_inpi, \n",
    "  adress_reconstituee_insee, \n",
    "  numerovoieetablissement, \n",
    "  numero_voie_matching,\n",
    "  typevoieetablissement,\n",
    "  voie_clean, \n",
    "  voie_matching type_voie_matching, \n",
    "  ets_final_sql.code_postal_matching, \n",
    "  ets_final_sql.ville_matching, \n",
    "  codecommuneetablissement,\n",
    "  code_commune, \n",
    "  enseigne, \n",
    "  enseigne1etablissement, \n",
    "  enseigne2etablissement, \n",
    "  enseigne3etablissement\n",
    "FROM \n",
    "  ets_final_sql \n",
    "INNER JOIN (\n",
    "  SELECT \n",
    "  count_initial_insee, \n",
    "  siren, \n",
    "  siret, \n",
    "  datecreationetablissement, \n",
    "  etablissementsiege, \n",
    "  etatadministratifetablissement, \n",
    "  codepostaletablissement, \n",
    "  codecommuneetablissement, \n",
    "  -- libellecommuneetablissement, \n",
    "  ville_matching, \n",
    "  -- libellevoieetablissement, \n",
    "  -- complementadresseetablissement, \n",
    "  numerovoieetablissement, \n",
    "  -- indicerepetitionetablissement, \n",
    "  typevoieetablissement, \n",
    "  adress_reconstituee_insee, \n",
    "  enseigne1etablissement, \n",
    "  enseigne2etablissement, \n",
    "  enseigne3etablissement\n",
    "FROM \n",
    "  insee_final_sql \n",
    "  ) as insee\n",
    "ON ets_final_sql.siren = insee.siren\n",
    "AND ets_final_sql.ville_matching = insee.ville_matching\n",
    "AND ets_final_sql.code_postal_matching = insee.codepostaletablissement\n",
    "WHERE \n",
    "  status != 'IGNORE'\n",
    "-- LIMIT 10\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
