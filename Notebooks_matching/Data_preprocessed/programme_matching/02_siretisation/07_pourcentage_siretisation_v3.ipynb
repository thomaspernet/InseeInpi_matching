{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test nombre lignes siretise\n",
    "\n",
    "Objective(s)\n",
    "\n",
    "*   Lors de l’US 6 Union et intersection, nous avons compté séparément le nombre de lignes siretisés avec les tests unitaires, indépendamment des autres tests. Le niveau de matching avec les tests unitaires va de 39% a 70%. Dans cette US, nous allons faire le test avec une prise en compte de l’ensemble des tests, autrement dit, compter le nombre de lignes sirétisé lorsque les tests sont co-dépendant.\n",
    "  * L’objectif principal étant de fournir un pourcentage avec le nombre de lignes siretisé.\n",
    "  * Les tests vont suivre l’arborescence suivante:\n",
    "    * Calcul des cas 1 à 7\n",
    "      * Calcul des tests \n",
    "      * Calcul des duplicates sur index & séquence\n",
    "        * Filtrer les lignes sans duplicate et tests (a definir les règles sur les tests)\n",
    "\n",
    "## Metadata\n",
    "\n",
    "* Metadata parameters are available here: Ressources_suDYJ#_luZqd\n",
    "* Task type:\n",
    "  * Jupyter Notebook\n",
    "* Users: :\n",
    "  * Thomas Pernet\n",
    "* Watchers:\n",
    "  * Thomas Pernet\n",
    "* Estimated Log points:\n",
    "  * One being a simple task, 15 a very difficult one\n",
    "  *  9\n",
    "* Task tag\n",
    "  *  #sql-query,#matching,#test-codependance,#siretisation\n",
    "* Toggl Tag\n",
    "  * #data-analysis\n",
    "* Instance [AWS/GCP]\n",
    "  *   \n",
    "  \n",
    "## Input Cloud Storage [AWS/GCP]\n",
    "\n",
    "If link from the internet, save it to the cloud first\n",
    "\n",
    "### Tables [AWS/BigQuery]\n",
    "\n",
    "1. Batch 1:\n",
    "  * Select Provider: Athena\n",
    "  * Select table(s): ets_insee_inpi\n",
    "    * Select only tables created from the same notebook, else copy/paste selection to add new input tables\n",
    "    * If table(s) does not exist, add them: Add New Table\n",
    "    * Information:\n",
    "      * Region: \n",
    "        * Name: Europe (Paris)\n",
    "        * Code: eu-west-3\n",
    "      * Database: inpi\n",
    "      * Notebook construction file: https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/01_preparation/03_ETS_add_variables.md\n",
    "    \n",
    "## Destination Output/Delivery\n",
    "\n",
    "* AWS\n",
    "  1. Athena: \n",
    "      * Region: Europe (Paris)\n",
    "      * Database: inpi\n",
    "      * Tables (Add name new table): ets_inpi_insee_cases\n",
    "      * List new tables\n",
    "      * ets_inpi_insee_cases\n",
    "  \n",
    "## Things to know (Steps, Attention points or new flow of information)\n",
    "\n",
    "## Similarité entre deux adresses\n",
    "\n",
    "Le rapprochement entre les deux tables, à savoir l’INSEE et l’INPI, va amener à la création de deux vecteurs d’adresse. Un vecteur avec des mots contenus spécifiquement à l’INSEE, et un second vecteur avec les mots de l’adresse de l’INPI. Notre objectif est de comparé ses deux vecteurs pour définir si ils sont identiques ou non. Nous avons distingué 7 cas de figures possibles entre les deux vecteurs (figure 1).\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1Qj_HooHrhFYSuTsoqFbl4Vxy9tN3V5Bu)\n",
    "\n",
    "\n",
    "### Sources of information  (meeting notes, Documentation, Query, URL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connexion serveur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awsPy.aws_authorization import aws_connector\n",
    "from awsPy.aws_athena import service_athena\n",
    "from awsPy.aws_s3 import service_s3\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, shutil\n",
    "bucket = 'calfdata'\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent)\n",
    "path_cred = r\"{}/credential_AWS.json\".format(parent_path)\n",
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = 'eu-west-3')\n",
    "client= con.client_boto()\n",
    "s3 = service_s3.connect_S3(client = client,\n",
    "                      bucket = 'calfdata', verbose = False) \n",
    "athena = service_athena.connect_athena(client = client,\n",
    "                      bucket = 'calfdata') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation table analyse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_table = False\n",
    "if drop_table:\n",
    "    output = athena.run_query(\n",
    "        query=\"DROP TABLE `ets_inpi_insee_cases`;\",\n",
    "        database='inpi',\n",
    "        s3_output='INPI/sql_output'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table = \"\"\"\n",
    "/*match insee inpi 7 cas de figs*/\n",
    "CREATE TABLE inpi.ets_inpi_insee_cases\n",
    "WITH (\n",
    "  format='PARQUET'\n",
    ") AS\n",
    "WITH test_proba AS (\n",
    "  SELECT \n",
    "  count_initial_insee, \n",
    "    index_id, \n",
    "    sequence_id, \n",
    "    siren, \n",
    "    siret, \n",
    "    Coalesce(\n",
    "      try(\n",
    "        date_parse(\n",
    "          datecreationetablissement, '%Y-%m-%d'\n",
    "        )\n",
    "      ), \n",
    "      try(\n",
    "        date_parse(\n",
    "          datecreationetablissement, '%Y-%m-%d %hh:%mm:%ss.SSS'\n",
    "        )\n",
    "      ), \n",
    "      try(\n",
    "        date_parse(\n",
    "          datecreationetablissement, '%Y-%m-%d %hh:%mm:%ss'\n",
    "        )\n",
    "      ), \n",
    "      try(\n",
    "        cast(\n",
    "          datecreationetablissement as timestamp\n",
    "        )\n",
    "      )\n",
    "    ) as datecreationetablissement, \n",
    "    Coalesce(\n",
    "      try(\n",
    "        date_parse(\n",
    "          \"date_début_activité\", '%Y-%m-%d'\n",
    "        )\n",
    "      ), \n",
    "      try(\n",
    "        date_parse(\n",
    "          \"date_début_activité\", '%Y-%m-%d %hh:%mm:%ss.SSS'\n",
    "        )\n",
    "      ), \n",
    "      try(\n",
    "        date_parse(\n",
    "          \"date_début_activité\", '%Y-%m-%d %hh:%mm:%ss'\n",
    "        )\n",
    "      ), \n",
    "      try(\n",
    "        cast(\n",
    "          \"date_début_activité\" as timestamp\n",
    "        )\n",
    "      )\n",
    "    ) as date_debut_activite, \n",
    "    etatadministratifetablissement, \n",
    "    status_admin, \n",
    "    etablissementsiege, \n",
    "    status_ets, \n",
    "    codecommuneetablissement, \n",
    "    code_commune, \n",
    "    codepostaletablissement, \n",
    "    code_postal_matching, \n",
    "    numerovoieetablissement, \n",
    "    numero_voie_matching, \n",
    "    typevoieetablissement, \n",
    "    type_voie_matching, \n",
    "    adresse_distance_inpi, \n",
    "    adresse_distance_insee, \n",
    "    list_numero_voie_matching_inpi, \n",
    "    list_numero_voie_matching_insee, \n",
    "    array_distinct(\n",
    "      split(adresse_distance_inpi, ' ')\n",
    "    ) as list_inpi, \n",
    "    cardinality(\n",
    "      array_distinct(\n",
    "        split(adresse_distance_inpi, ' ')\n",
    "      )\n",
    "    ) as lenght_list_inpi, \n",
    "    array_distinct(\n",
    "      split(adresse_distance_insee, ' ')\n",
    "    ) as list_insee, \n",
    "    cardinality(\n",
    "      array_distinct(\n",
    "        split(adresse_distance_insee, ' ')\n",
    "      )\n",
    "    ) as lenght_list_insee, \n",
    "    array_distinct(\n",
    "      array_except(\n",
    "        split(adresse_distance_insee, ' '), \n",
    "        split(adresse_distance_inpi, ' ')\n",
    "      )\n",
    "    ) as insee_except, \n",
    "    array_distinct(\n",
    "      array_except(\n",
    "        split(adresse_distance_inpi, ' '), \n",
    "        split(adresse_distance_insee, ' ')\n",
    "      )\n",
    "    ) as inpi_except, \n",
    "    CAST(\n",
    "      cardinality(\n",
    "        array_distinct(\n",
    "          array_intersect(\n",
    "            split(adresse_distance_inpi, ' '), \n",
    "            split(adresse_distance_insee, ' ')\n",
    "          )\n",
    "        )\n",
    "      ) AS DECIMAL(10, 2)\n",
    "    ) as intersection, \n",
    "    CAST(\n",
    "      cardinality(\n",
    "        array_distinct(\n",
    "          array_union(\n",
    "            split(adresse_distance_inpi, ' '), \n",
    "            split(adresse_distance_insee, ' ')\n",
    "          )\n",
    "        )\n",
    "      ) AS DECIMAL(10, 2)\n",
    "    ) as union_,\n",
    "  CAST(\n",
    "      cardinality(\n",
    "        array_distinct(\n",
    "          array_intersect(\n",
    "            list_numero_voie_matching_inpi,\n",
    "            list_numero_voie_matching_insee\n",
    "          )\n",
    "        )\n",
    "      ) AS DECIMAL(10, 2)\n",
    "    ) as intersection_numero_voie,\n",
    "  CAST(\n",
    "      cardinality(\n",
    "        array_distinct(\n",
    "          array_union(\n",
    "            list_numero_voie_matching_inpi, \n",
    "            list_numero_voie_matching_insee\n",
    "          )\n",
    "        )\n",
    "      ) AS DECIMAL(10, 2)\n",
    "    ) as union_numero_voie,\n",
    "     REGEXP_REPLACE(\n",
    "  NORMALIZE(\n",
    "  enseigne, \n",
    "            NFD\n",
    "          ), \n",
    "          '\\pM', \n",
    "          ''\n",
    "        ) AS enseigne,\n",
    "  enseigne1etablissement, enseigne2etablissement, enseigne3etablissement, \n",
    "  array_remove(\n",
    "array_distinct(\n",
    "SPLIT(\n",
    "  concat(\n",
    "  enseigne1etablissement,',', enseigne2etablissement,',', enseigne3etablissement),\n",
    "  ',')\n",
    "  ), ''\n",
    "  ) as test, \n",
    "  \n",
    "contains( \n",
    "         array_remove(\n",
    "array_distinct(\n",
    "SPLIT(\n",
    "  concat(\n",
    "  enseigne1etablissement,',', enseigne2etablissement,',', enseigne3etablissement),\n",
    "  ',')\n",
    "  ), ''\n",
    "  ),REGEXP_REPLACE(\n",
    "  NORMALIZE(\n",
    "  enseigne, \n",
    "            NFD\n",
    "          ), \n",
    "          '\\pM', \n",
    "          ''\n",
    "        )\n",
    "         ) AS temp_test_enseigne\n",
    "  FROM \n",
    "    \"inpi\".\"ets_insee_inpi\" -- limit 10\n",
    "    ) \n",
    "SELECT \n",
    "count_initial_insee,\n",
    "  index_id, \n",
    "  sequence_id, \n",
    "  siren, \n",
    "  siret, \n",
    "  CASE WHEN cardinality(list_numero_voie_matching_inpi) = 0 THEN NULL ELSE list_numero_voie_matching_inpi END as list_numero_voie_matching_inpi, \n",
    "  CASE WHEN cardinality(list_numero_voie_matching_insee) = 0 THEN NULL ELSE list_numero_voie_matching_insee END as list_numero_voie_matching_insee,\n",
    "  intersection_numero_voie,\n",
    "  union_numero_voie,\n",
    "  \n",
    "  CASE WHEN intersection_numero_voie = union_numero_voie AND (intersection_numero_voie IS NOT NULL OR union_numero_voie IS NOT NULL) THEN 'True' \n",
    "  WHEN (intersection_numero_voie IS NULL OR union_numero_voie IS NULL) THEN 'NULL'\n",
    "  ELSE 'False' END AS test_list_num_voie,\n",
    "  \n",
    "  datecreationetablissement, \n",
    "  date_debut_activite, \n",
    "  \n",
    "  CASE WHEN datecreationetablissement = date_debut_activite THEN 'True' \n",
    "  WHEN datecreationetablissement IS NULL \n",
    "  OR date_debut_activite IS NULL  THEN 'NULL'\n",
    "  --WHEN datecreationetablissement = '' \n",
    "  --OR date_debut_activite = ''   THEN 'NULL'\n",
    "  ELSE 'False' \n",
    "  END AS test_date, \n",
    "  \n",
    "  etatadministratifetablissement, \n",
    "  status_admin, \n",
    "  \n",
    "  CASE WHEN etatadministratifetablissement = status_admin THEN 'True' \n",
    "  WHEN etatadministratifetablissement IS NULL \n",
    "  OR status_admin IS NULL  THEN 'NULL'\n",
    "  WHEN etatadministratifetablissement = '' \n",
    "  OR status_admin = '' THEN 'NULL'\n",
    "  ELSE 'False'  \n",
    "  END AS test_status_admin, \n",
    "  \n",
    "  etablissementsiege, \n",
    "  status_ets, \n",
    "  \n",
    "  CASE WHEN etablissementsiege = status_ets THEN 'True' \n",
    "  WHEN etablissementsiege IS NULL \n",
    "  OR status_ets IS NULL  THEN 'NULL'\n",
    "  WHEN etablissementsiege = '' \n",
    "  OR status_ets = ''   THEN 'NULL'\n",
    "  ELSE 'False'  \n",
    "  END AS test_siege, \n",
    "  \n",
    "  codecommuneetablissement, \n",
    "  code_commune, \n",
    "  \n",
    "  CASE WHEN codecommuneetablissement = code_commune THEN 'True' \n",
    "  WHEN codecommuneetablissement IS NULL \n",
    "  OR code_commune IS NULL  THEN 'NULL'\n",
    "  WHEN codecommuneetablissement = '' \n",
    "  OR code_commune = ''   THEN 'NULL'\n",
    "  ELSE 'False'  \n",
    "  END AS test_code_commune, \n",
    "  \n",
    "  codepostaletablissement, \n",
    "  code_postal_matching, \n",
    "  numerovoieetablissement, \n",
    "  numero_voie_matching, \n",
    "  \n",
    "  CASE WHEN numerovoieetablissement = numero_voie_matching THEN 'True' \n",
    "  WHEN numerovoieetablissement IS NULL \n",
    "  OR numero_voie_matching IS NULL  THEN 'NULL'\n",
    "  WHEN numerovoieetablissement = '' \n",
    "  OR numero_voie_matching = ''   THEN 'NULL'\n",
    "  ELSE 'False'  \n",
    "  END AS test_numero_voie, \n",
    "  \n",
    "  typevoieetablissement, \n",
    "  type_voie_matching, \n",
    "  \n",
    "  CASE WHEN typevoieetablissement = type_voie_matching THEN 'True' \n",
    "  WHEN typevoieetablissement IS NULL \n",
    "  OR type_voie_matching IS NULL  THEN 'NULL'\n",
    "  WHEN typevoieetablissement = '' \n",
    "  OR type_voie_matching = ''   THEN 'NULL'\n",
    "  ELSE 'False'  \n",
    "  END AS test_type_voie, \n",
    "  \n",
    "  CASE WHEN cardinality(list_inpi) = 0 THEN NULL ELSE list_inpi END as list_inpi,\n",
    "  \n",
    "  lenght_list_inpi, \n",
    "  \n",
    "  CASE WHEN cardinality(list_insee) = 0 THEN NULL ELSE list_insee END as list_insee,\n",
    "  lenght_list_insee, \n",
    "  \n",
    "  CASE WHEN cardinality(inpi_except) = 0 THEN NULL ELSE inpi_except END as inpi_except,\n",
    "  CASE WHEN cardinality(insee_except) = 0 THEN NULL ELSE insee_except END as insee_except,\n",
    "   \n",
    "  intersection, \n",
    "  union_, \n",
    "  CASE WHEN intersection = union_  THEN 'CAS_1' WHEN intersection = 0 THEN 'CAS_2' WHEN lenght_list_inpi = intersection \n",
    "  AND intersection != union_ THEN 'CAS_3' WHEN lenght_list_insee = intersection \n",
    "  AND intersection != union_ THEN 'CAS_4' WHEN cardinality(insee_except) = cardinality(inpi_except) \n",
    "  AND intersection != 0 \n",
    "  AND cardinality(insee_except) > 0 THEN 'CAS_5' WHEN cardinality(insee_except) > cardinality(inpi_except) \n",
    "  AND intersection != 0 \n",
    "  AND cardinality(insee_except) > 0 \n",
    "  AND cardinality(inpi_except) > 0 THEN 'CAS_6' WHEN cardinality(insee_except) < cardinality(inpi_except) \n",
    "  AND intersection != 0 \n",
    "  AND cardinality(insee_except) > 0 \n",
    "  AND cardinality(inpi_except) > 0 THEN 'CAS_7' ELSE 'CAS_NO_ADRESSE' END AS status_cas,\n",
    "  enseigne, enseigne1etablissement, enseigne2etablissement, enseigne3etablissement, \n",
    "  CASE WHEN cardinality(test) = 0 THEN 'NULL'\n",
    "WHEN enseigne = '' THEN 'NULL'\n",
    "WHEN temp_test_enseigne = TRUE THEN 'True'\n",
    "ELSE 'False' END AS test_enseigne \n",
    "  \n",
    "FROM \n",
    "  test_proba\n",
    "\"\"\"\n",
    "output = athena.run_query(\n",
    "        query=create_table,\n",
    "        database='inpi',\n",
    "        s3_output='INPI/sql_output'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create table par cas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation functions\n",
    "\n",
    "La fonction ci dessous va générer le tableau d'analayse via une query, et retourne un dataframe Pandas, tout en stockant le resultat dans le dossier suivant:\n",
    "\n",
    "- [calfdata/TEMP_ANALYSE_SIRETISATION/INDEX_20](https://s3.console.aws.amazon.com/s3/buckets/calfdata/TEMP_ANALYSE_SIRETISATION/INDEX_20/?region=eu-west-3&tab=overview)\n",
    "- [calfdata/TEMP_ANALYSE_SIRETISATION/INDEX_20_TRUE](https://s3.console.aws.amazon.com/s3/buckets/calfdata/TEMP_ANALYSE_SIRETISATION/INDEX_20_TRUE/?region=eu-west-3&tab=overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = (pd.DataFrame(data = {'index_unique': range(1,21)})\n",
    "       .to_csv('index_20.csv', index = False)\n",
    "      )\n",
    "\n",
    "s3.upload_file(file_to_upload = 'index_20.csv',\n",
    "            destination_in_s3 = 'TEMP_ANALYSE_SIRETISATION/INDEX_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table = \"\"\"\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS inpi.index_20 (\n",
    "`index_unique`                     integer\n",
    "    )\n",
    "     ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'\n",
    "    WITH SERDEPROPERTIES (\n",
    "   'separatorChar' = ',',\n",
    "   'quoteChar' = '\"'\n",
    "   )\n",
    "     LOCATION 's3://calfdata/TEMP_ANALYSE_SIRETISATION/INDEX_20'\n",
    "     TBLPROPERTIES ('has_encrypted_data'='false',\n",
    "              'skip.header.line.count'='1');\"\"\"\n",
    "output = athena.run_query(\n",
    "        query=create_table,\n",
    "        database='inpi',\n",
    "        s3_output='INPI/sql_output'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = range(1,10)\n",
    "b = [\"True\", \"False\", \"NULL\"]\n",
    "\n",
    "\n",
    "\n",
    "index = pd.MultiIndex.from_product([a, b], names = [\"index_unique\", \"groups\"])\n",
    "\n",
    "df_ = (pd.DataFrame(index = index)\n",
    "       .reset_index()\n",
    "       .sort_values(by = [\"index_unique\", \"groups\"])\n",
    "       .to_csv('index_20_true.csv', index = False)\n",
    "      )\n",
    "\n",
    "s3.upload_file(file_to_upload = 'index_20_true.csv',\n",
    "            destination_in_s3 = 'TEMP_ANALYSE_SIRETISATION/INDEX_20_TRUE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table = \"\"\"\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS inpi.index_20_true (\n",
    "`index_unique`                     integer,\n",
    "`groups`                     string\n",
    "\n",
    "    )\n",
    "     ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'\n",
    "    WITH SERDEPROPERTIES (\n",
    "   'separatorChar' = ',',\n",
    "   'quoteChar' = '\"'\n",
    "   )\n",
    "     LOCATION 's3://calfdata/TEMP_ANALYSE_SIRETISATION/INDEX_20_TRUE'\n",
    "     TBLPROPERTIES ('has_encrypted_data'='false',\n",
    "              'skip.header.line.count'='1');\"\"\"\n",
    "output = athena.run_query(\n",
    "        query=create_table,\n",
    "        database='inpi',\n",
    "        s3_output='INPI/sql_output'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_test_not_false(cas = \"CAS_1\"):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    top = \"\"\"\n",
    "    SELECT count_test_list_num_voie.status_cas,\n",
    "    nb_unique_index, \n",
    "    index_unique,\n",
    "    count_cas,\n",
    "    test_list_num_voie,\n",
    "    test_siege,\n",
    "    test_enseigne,\n",
    "    test_date, \n",
    "    test_status_admin,\n",
    "    test_code_commune,\n",
    "    test_type_voie\n",
    "    FROM index_20 \n",
    "    \n",
    "    LEFT JOIN (\n",
    "    SELECT count_, COUNT(count_) as count_cas\n",
    "    FROM (\n",
    "    SELECT COUNT(index_id) as count_\n",
    "    FROM ets_inpi_insee_cases \n",
    "    WHERE status_cas = '{0}'\n",
    "    GROUP BY index_id\n",
    "    ORDER BY count_ DESC\n",
    "  )\n",
    "  GROUP BY count_\n",
    "  ORDER BY count_\n",
    "  ) AS count_unique\n",
    "  ON index_20.index_unique = count_unique.count_ \n",
    "    \"\"\".format(cas)\n",
    "    query = \"\"\"\n",
    "    LEFT JOIN (\n",
    "    SELECT status_cas,count_index,  count(count_index) AS {1}\n",
    "    FROM (\n",
    "    SELECT status_cas, index_id, COUNT(test_enseigne) as count_index\n",
    "    FROM ets_inpi_insee_cases \n",
    "    WHERE status_cas = '{0}' AND  {1} != 'False'\n",
    "    GROUP BY status_cas, index_id\n",
    "      ) as c\n",
    "      GROUP BY status_cas, count_index\n",
    "      ORDER BY count_index\n",
    "      ) AS count_{1}\n",
    "      ON index_20.index_unique = count_{1}.count_index \n",
    "    \"\"\"\n",
    "    \n",
    "    bottom = \"\"\"\n",
    "    LEFT JOIN (\n",
    "    SELECT  DISTINCT(status_cas), COUNT(DISTINCT(index_id)) as nb_unique_index\n",
    "    FROM ets_inpi_insee_cases \n",
    "    WHERE status_cas = '{0}' \n",
    "    GROUP BY status_cas\n",
    "    ) as index_unique\n",
    "    ON index_unique.status_cas = count_test_list_num_voie.status_cas\n",
    "    ORDER BY index_unique\n",
    "    \"\"\".format(cas)\n",
    "\n",
    "    for i, table in enumerate([\"test_list_num_voie\",\n",
    "              \"test_siege\",\n",
    "              \"test_enseigne\",\n",
    "              \"test_date\", \"test_status_admin\", \"test_code_commune\", \"test_type_voie\"]):\n",
    "\n",
    "        top += query.format(cas, table)\n",
    "    top += bottom\n",
    "    \n",
    "    ### run query\n",
    "    output = athena.run_query(\n",
    "        query=top,\n",
    "        database='inpi',\n",
    "        s3_output='INPI/sql_output'\n",
    "    )\n",
    "\n",
    "    results = False\n",
    "    filename = 'table_{}_test_not_false.csv'.format(cas)\n",
    "    \n",
    "    while results != True:\n",
    "        source_key = \"{}/{}.csv\".format(\n",
    "                            'INPI/sql_output',\n",
    "                            output['QueryExecutionId']\n",
    "                                   )\n",
    "        destination_key = \"{}/{}\".format(\n",
    "                                'ANALYSE_PRE_SIRETISATION',\n",
    "                                filename\n",
    "                            )\n",
    "        \n",
    "        results = s3.copy_object_s3(\n",
    "                                source_key = source_key,\n",
    "                                destination_key = destination_key,\n",
    "                                remove = True\n",
    "                            )\n",
    "        \n",
    "    #filename = 'table_{}_test_not_false.csv'.format('CAS_1')\n",
    "    index_unique_inpi = 10981811\n",
    "    reindex= ['status_cas','nb_unique_index', 'index_unique','count_cas',\n",
    "              'test_list_num_voie',\n",
    "              'count_num_voie',\n",
    "              'test_siege',\n",
    "              'count_siege',\n",
    "           'test_enseigne',\n",
    "               'count_enseigne',\n",
    "              'test_date',\n",
    "               'count_date',\n",
    "              'test_status_admin',\n",
    "              'count_admin',\n",
    "              'test_code_commune',\n",
    "              'count_code_commune',\n",
    "           'test_type_voie',\n",
    "              'count_type_voie']\n",
    "    test_1 = (s3.read_df_from_s3(\n",
    "            key = 'ANALYSE_PRE_SIRETISATION/{}'.format(filename), sep = ',')\n",
    "             )\n",
    "    \n",
    "    df_ = (\n",
    "        test_1\n",
    "     .assign(\n",
    "\n",
    "         count_num_voie = lambda x: x['test_list_num_voie'] /  index_unique_inpi,\n",
    "         count_siege = lambda x: x['test_siege'] /  index_unique_inpi,\n",
    "         count_enseigne\t = lambda x: x['test_enseigne'] /  index_unique_inpi,\n",
    "         count_date = lambda x: x['test_date'] /  index_unique_inpi,\n",
    "         count_admin = lambda x: x['test_status_admin'] /  index_unique_inpi,\n",
    "         count_code_commune = lambda x: x['test_code_commune'] /  index_unique_inpi,\n",
    "         count_type_voie = lambda x: x['test_type_voie'] /  index_unique_inpi,\n",
    "         status_cas = lambda x: x['status_cas'].fillna(method='ffill'),\n",
    "         nb_unique_index = lambda x: x['nb_unique_index'].fillna(method='ffill')\n",
    "     )\n",
    "     .reindex(columns = reindex)\n",
    "     .fillna(0)\n",
    "                  .style\n",
    "                  .format(\"{:,.0f}\", subset =  [\n",
    "                      \"nb_unique_index\",\n",
    "                      \"count_cas\",\n",
    "                      'test_list_num_voie',\n",
    "                                                'test_siege',\n",
    "                                                'test_enseigne',\n",
    "                                                'test_date',\n",
    "                                                'test_status_admin',\n",
    "                                                'test_code_commune',\n",
    "                                                'test_type_voie'])\n",
    "                  .format(\"{:.2%}\", subset =  ['count_num_voie',\n",
    "                                               'count_siege',\n",
    "                                               'count_enseigne',\n",
    "                                               'count_date',\n",
    "                                               'count_admin',\n",
    "                                               'count_code_commune',\n",
    "                                               'count_type_voie'])\n",
    "                  .bar(subset= ['count_num_voie',\n",
    "                                               'count_siege',\n",
    "                                               'count_enseigne',\n",
    "                                               'count_date',\n",
    "                                               'count_admin',\n",
    "                                               'count_code_commune',\n",
    "                                               'count_type_voie'],\n",
    "                       color='#d65f5f')\n",
    "     )\n",
    "    \n",
    "    unique_1 = test_1.loc[lambda x: x['index_unique'].isin([1])]\n",
    "    dic_ = {\n",
    "    \n",
    "    'nb_index_unique_{}'.format(cas): int(unique_1['nb_unique_index'].values[0]),\n",
    "     'index_unique_inpi':index_unique_inpi,   \n",
    "    'lignes_matches': {   \n",
    "        'lignes_matche_list_num': int(unique_1['test_list_num_voie'].values[0]),\n",
    "    'lignes_matche_list_num_pct': unique_1['test_list_num_voie'].values[0] / index_unique_inpi\n",
    "    },    \n",
    "    'lignes_a_trouver': {\n",
    "        'test_list_num_voie':[\n",
    "            int((unique_1['nb_unique_index'].values - unique_1['test_list_num_voie'].values)[0]),\n",
    "            (unique_1['test_list_num_voie'].values / unique_1['nb_unique_index'].values)[0]\n",
    "        ],\n",
    "        'test_siege':[\n",
    "            int((unique_1['nb_unique_index'].values - unique_1['test_siege'].values)[0]),\n",
    "            (unique_1['test_siege'].values / unique_1['nb_unique_index'].values)[0]\n",
    "        ],\n",
    "        'test_enseigne':[\n",
    "            int((unique_1['nb_unique_index'].values - unique_1['test_enseigne'].values)[0]),\n",
    "            (unique_1['test_enseigne'].values / unique_1['nb_unique_index'].values)[0]\n",
    "        ],\n",
    "        'test_date':[\n",
    "            int((unique_1['nb_unique_index'].values - unique_1['test_date'].values)[0]),\n",
    "            (unique_1['test_date'].values / unique_1['nb_unique_index'].values)[0]\n",
    "        ],\n",
    "        'status_admin':[\n",
    "            int((unique_1['nb_unique_index'].values - unique_1['test_status_admin'].values)[0]),\n",
    "            (unique_1['test_status_admin'].values / unique_1['nb_unique_index'].values)[0]\n",
    "        ],\n",
    "        'test_code_commune':[\n",
    "            int((unique_1['nb_unique_index'].values - unique_1['test_code_commune'].values)[0]),\n",
    "            (unique_1['test_code_commune'].values / unique_1['nb_unique_index'].values)[0]\n",
    "        ],\n",
    "        'test_type_voie':[\n",
    "            int((unique_1['nb_unique_index'].values - unique_1['test_type_voie'].values)[0]),\n",
    "            (unique_1['test_type_voie'].values / unique_1['nb_unique_index'].values)[0]\n",
    "        ],\n",
    "    }\n",
    "}\n",
    "    \n",
    "    return test_1, dic_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_list_num_other_tests(cas = 'CAS_1'):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    top = \"\"\"\n",
    "    SELECT \n",
    "    count_test_siege.status_cas,\n",
    "    index_unique, \n",
    "    groups, \n",
    "    cnt_test_list_num_voie,\n",
    "    cnt_test_siege,\n",
    "    cnt_test_enseigne,\n",
    "    cnt_test_date, \n",
    "    cnt_test_status_admin,\n",
    "    cnt_test_code_commune,\n",
    "    cnt_test_type_voie\n",
    "    FROM index_20_true \n",
    "    \"\"\"\n",
    "    \n",
    "    query = \"\"\"\n",
    "    -- {0}\n",
    "    LEFT JOIN (\n",
    "    SELECT status_cas, count_index,{0}, COUNT(index_id) as cnt_{0}\n",
    "    FROM (\n",
    "    SELECT ets_inpi_insee_cases.status_cas, count_index, ets_inpi_insee_cases.index_id, {0}\n",
    "    FROM ets_inpi_insee_cases\n",
    "    RIGHT JOIN (\n",
    "    SELECT *\n",
    "    FROM(\n",
    "    SELECT status_cas, index_id, COUNT(index_id) as count_index\n",
    "    FROM ets_inpi_insee_cases \n",
    "    WHERE status_cas = '{1}' AND  test_list_num_voie != 'False'\n",
    "    GROUP BY status_cas, index_id\n",
    "  )\n",
    "  ) as index_\n",
    "  ON ets_inpi_insee_cases.status_cas = index_.status_cas AND\n",
    "  ets_inpi_insee_cases.index_id = index_.index_id\n",
    "  WHERE ets_inpi_insee_cases.status_cas = '{1}' AND  test_list_num_voie != 'False'\n",
    "  ) \n",
    "  GROUP BY status_cas, count_index, {0}\n",
    "  ) as count_{0}\n",
    "  ON index_20_true.index_unique = count_{0}.count_index AND\n",
    "  index_20_true.groups = count_{0}.{0}\n",
    " \n",
    "    \"\"\"\n",
    "    \n",
    "    bottom =   \"\"\"ORDER BY index_unique, groups\"\"\"\n",
    "    for i, table in enumerate([\"test_list_num_voie\",\n",
    "              \"test_siege\",\n",
    "              \"test_enseigne\",\n",
    "              \"test_date\", \"test_status_admin\", \"test_code_commune\", \"test_type_voie\"]):\n",
    "\n",
    "        top += query.format(table, cas)\n",
    "    top += bottom\n",
    "    ### run query\n",
    "    output = athena.run_query(\n",
    "        query=top,\n",
    "        database='inpi',\n",
    "        s3_output='INPI/sql_output'\n",
    "    )\n",
    "\n",
    "    results = False\n",
    "    filename = 'table_{}_num_voie_test_not_false.csv'.format(cas)\n",
    "    \n",
    "    while results != True:\n",
    "        source_key = \"{}/{}.csv\".format(\n",
    "                            'INPI/sql_output',\n",
    "                            output['QueryExecutionId']\n",
    "                                   )\n",
    "        destination_key = \"{}/{}\".format(\n",
    "                                'ANALYSE_PRE_SIRETISATION',\n",
    "                                filename\n",
    "                            )\n",
    "        \n",
    "        results = s3.copy_object_s3(\n",
    "                                source_key = source_key,\n",
    "                                destination_key = destination_key,\n",
    "                                remove = True\n",
    "                            )\n",
    "    reindex= ['status_cas',\n",
    "          'index_unique',\n",
    "          'groups',\n",
    "              \"total_rows\",\n",
    "              'cnt_test_list_num_voie',\n",
    "              'count_list_num_voie',\n",
    "              'cnt_test_siege',\n",
    "              'count_siege',\n",
    "           'cnt_test_enseigne',\n",
    "               'count_enseigne',\n",
    "              'cnt_test_date',\n",
    "               'count_date',\n",
    "              'cnt_test_status_admin',\n",
    "              'count_admin',\n",
    "              'cnt_test_code_commune',\n",
    "              'count_code_commune',\n",
    "           'cnt_test_type_voie',\n",
    "              'count_type_voie']\n",
    "\n",
    "    test_1 = (s3.read_df_from_s3(\n",
    "            key = 'ANALYSE_PRE_SIRETISATION/{}'.format(filename), sep = ',')\n",
    "          .assign(\n",
    "         total_rows = lambda x: x['cnt_test_siege'].groupby(x['index_unique']).transform('sum'),\n",
    "         count_list_num_voie = lambda x: x['cnt_test_list_num_voie'] /  x['total_rows'],\n",
    "         count_siege = lambda x: x['cnt_test_siege'] /  x['total_rows'],\n",
    "         count_enseigne\t = lambda x: x['cnt_test_enseigne'] /  x['total_rows'],\n",
    "         count_date = lambda x: x['cnt_test_date'] /  x['total_rows'],\n",
    "         count_admin = lambda x: x['cnt_test_status_admin'] /  x['total_rows'],\n",
    "         count_code_commune = lambda x: x['cnt_test_code_commune'] /  x['total_rows'],\n",
    "         count_type_voie = lambda x: x['cnt_test_type_voie'] /  x['total_rows'],\n",
    "         status_cas = lambda x: x['status_cas'].fillna(method='ffill'),\n",
    "         groups = lambda x: x['groups'].fillna('Null')\n",
    "          )\n",
    "          .reindex(columns = reindex)\n",
    "          .fillna(0)\n",
    "          .style\n",
    "                  .format(\"{:,.0f}\", subset =  ['total_rows',\n",
    "                                                'cnt_test_list_num_voie',\n",
    "                                                'cnt_test_siege',\n",
    "                                                'cnt_test_enseigne',\n",
    "                                                'cnt_test_date',\n",
    "                                                'cnt_test_status_admin',\n",
    "                                                'cnt_test_code_commune',\n",
    "                                                'cnt_test_type_voie'])\n",
    "                  .format(\"{:.2%}\", subset =  ['count_list_num_voie',\n",
    "                                               'count_siege',\n",
    "                                               'count_enseigne',\n",
    "                                               'count_date',\n",
    "                                               'count_admin',\n",
    "                                               'count_code_commune',\n",
    "                                               'count_type_voie'])\n",
    "                  .bar(subset= ['count_list_num_voie',\n",
    "                                               'count_siege',\n",
    "                                               'count_enseigne',\n",
    "                                               'count_date',\n",
    "                                               'count_admin',\n",
    "                                               'count_code_commune',\n",
    "                                               'count_type_voie'],\n",
    "                       color='#d65f5f')\n",
    "             )\n",
    "    \n",
    "    return test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_list_num_test_false(cas = 'CAS_1',test = 'test_type_voie'):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    to_append = \"\"\"count_initial_insee, index_id, sequence_id, siren, siret,\n",
    "             list_inpi, list_insee,etablissementsiege, status_ets,\n",
    "             enseigne, enseigne1etablissement, enseigne2etablissement,\n",
    "             enseigne3etablissement, datecreationetablissement,\n",
    "             date_debut_activite, etatadministratifetablissement, status_admin,\n",
    "             typevoieetablissement, type_voie_matching\"\"\"\n",
    "\n",
    "    for i, value in enumerate([\"test_siege\", \"test_enseigne\", \"test_date\", \"test_status_admin\", \"test_type_voie\"]):\n",
    "        if value not in [test]:\n",
    "            to_append += \",{}\".format(value) \n",
    "    \n",
    "    query = \"\"\"\n",
    "    SELECT  \n",
    "\n",
    "count_initial_insee,filter_a.index_id, sequence_id, siren, siret,list_inpi, list_insee,\n",
    "etablissementsiege, status_ets, test_siege, \n",
    "enseigne, enseigne1etablissement, enseigne2etablissement, enseigne3etablissement, test_enseigne, \n",
    "datecreationetablissement, date_debut_activite, test_date, \n",
    "etatadministratifetablissement, status_admin, test_status_admin, \n",
    "test_type_voie, typevoieetablissement, type_voie_matching \n",
    "\n",
    "    FROM (\n",
    "    SELECT ets_inpi_insee_cases.status_cas, count_index, ets_inpi_insee_cases.index_id, {1}\n",
    "    FROM ets_inpi_insee_cases\n",
    "    RIGHT JOIN (\n",
    "    SELECT *\n",
    "    FROM(\n",
    "    SELECT status_cas, index_id, COUNT(index_id) as count_index\n",
    "    FROM ets_inpi_insee_cases \n",
    "    WHERE status_cas = '{0}' AND  test_list_num_voie != 'False'\n",
    "    GROUP BY status_cas, index_id\n",
    "  )\n",
    "      WHERE count_index = 1\n",
    "  ) as index_\n",
    "  ON ets_inpi_insee_cases.status_cas = index_.status_cas AND\n",
    "  ets_inpi_insee_cases.index_id = index_.index_id\n",
    "  WHERE ets_inpi_insee_cases.status_cas = '{0}' AND  test_list_num_voie != 'False'\n",
    "  ) as filter_a\n",
    "  \n",
    "  LEFT JOIN (\n",
    "    \n",
    "    SELECT {2}\n",
    "    \n",
    "    FROM ets_inpi_insee_cases\n",
    "    WHERE ets_inpi_insee_cases.status_cas = '{0}' AND  test_list_num_voie != 'False'\n",
    "    ) as filter_b\n",
    "    ON filter_a.index_id = filter_b.index_id\n",
    "    WHERE {1} = 'False'\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "    #print(query.format(cas, test,to_append))\n",
    "    output = athena.run_query(\n",
    "        query=query.format(cas, test,to_append),\n",
    "        database='inpi',\n",
    "        s3_output='INPI/sql_output'\n",
    "    )\n",
    "\n",
    "    results = False\n",
    "    filename = 'table_{0}_{1}_example_filter.csv'.format(cas, test)\n",
    "    \n",
    "    while results != True:\n",
    "        source_key = \"{}/{}.csv\".format(\n",
    "                            'INPI/sql_output',\n",
    "                            output['QueryExecutionId']\n",
    "                                   )\n",
    "        destination_key = \"{}/{}\".format(\n",
    "                                'ANALYSE_PRE_SIRETISATION',\n",
    "                                filename\n",
    "                            )\n",
    "        \n",
    "        results = s3.copy_object_s3(\n",
    "                                source_key = source_key,\n",
    "                                destination_key = destination_key,\n",
    "                                remove = True\n",
    "                            )\n",
    "    \n",
    "    test_1 = (s3.read_df_from_s3(\n",
    "            key = 'ANALYSE_PRE_SIRETISATION/{}'.format(filename), sep = ',')\n",
    "             )\n",
    "    \n",
    "    return test_1\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nombre observations par cas\n",
    "\n",
    "Le nombre d'observations doit correspondre au suivant:\n",
    "\n",
    "|   Cas de figure | Titre                   |   Total |   Total cumulé |   pourcentage |   Pourcentage cumulé | Comment                 |\n",
    "|----------------:|:------------------------|--------:|---------------:|--------------:|---------------------:|:------------------------|\n",
    "|               1 | similarité parfaite     | 7775392 |        7775392 |     0.670261  |             0.670261 | Match parfait           |\n",
    "|               2 | Exclusion parfaite      |  974444 |        8749836 |     0.0839998 |             0.75426  | Exclusion parfaite      |\n",
    "|               3 | Match partiel parfait   |  407404 |        9157240 |     0.0351194 |             0.78938  | Match partiel parfait   |\n",
    "|               4 | Match partiel parfait   |  558992 |        9716232 |     0.0481867 |             0.837566 | Match partiel parfait   |\n",
    "|               5 | Match partiel compliqué | 1056406 |       10772638 |     0.0910652 |             0.928632 | Match partiel compliqué |\n",
    "|               6 | Match partiel compliqué |  361242 |       11133880 |     0.0311401 |             0.959772 | Match partiel compliqué |\n",
    "|               7 | Match partiel compliqué |  466671 |       11600551 |     0.0402283 |             1        | Match partiel compliqué |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nombre ets par cas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT status_cas, COUNT(*) as count\n",
    "FROM ets_inpi_insee_cases \n",
    "GROUP BY status_cas\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nombre etb unique INSEE par cas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT status_cas, COUNT(DISTINCT(index_id)) as distinct_ets\n",
    "FROM ets_inpi_insee_cases \n",
    "GROUP BY status_cas\n",
    "ORDER BY status_cas\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT * \n",
    "FROM (\n",
    "SELECT status_cas, count_initial_insee, COUNT(*) as count\n",
    "FROM ets_inpi_insee_cases \n",
    "GROUP BY status_cas, count_initial_insee\n",
    "  )\n",
    "  WHERE count_initial_insee = 1\n",
    "ORDER BY status_cas, count_initial_insee\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution somme enseigne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "  approx_percentile(sum_enseigne, ARRAY[0.25,0.50,0.75,.80,.85,.86,.87, .88, .89,.90,0.95, 0.99]) as sum_enseigne\n",
    "FROM \n",
    "  ets_inpi_insee_cases \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anayse cas\n",
    "\n",
    "Explication:\n",
    "\n",
    "- Dictionnaire:\n",
    "    - \n",
    "\n",
    "- Table 1:\n",
    "    - nb_unique_index: Nombre d'index unique pour un cas donnée. Ex. Il y a 7,584,503 index unique pour la cas 1\n",
    "    - index_unique: . Possibilité de duplicate allant 1 (aucun duplicate) a 20. Si supérieur à 1, cela indique le nombre de lignes ayant 2,3,4 etc doublons\n",
    "    - count_cas: Compte le nombre de duplicate par cas et index_unique. Par exemple, le cas 1 possède 128,821 lignes avec deux doublons pour un index donnée\n",
    "    - `test_*`: Nombre de lignes ayant un result de test différent de false, pour chaqun des duplicates. par exemple, il y a 7,471,838 lignes ayant passées le test test_list_num_voie et n'ayant aucun duplicate.\n",
    "    - `count_*`: test_* / nb_unique_index. Informe du pourcentage de lignes ayant un test concluant sur le nombre d'index unique. Se référé à la ligne 0.\n",
    "- Table 2:\n",
    "    - index_unique: Idem que index_unique\n",
    "    - groups: Possibilité des résultats des tests -> True, False, NULL. NULL si aucune info dans les variables pour faire le test\n",
    "    - total_rows: Nombre de lignes ayant réussi le test test_list_num_voie. Le chiffre doit correspondre à test_list_num_voie, ligne 0\n",
    "    - `cnt_test_*`: Nombre de lignes ayant résussi le test test_list_num_voie, puis décomposé par résultat pour chaque test. Par exemple, il y a 3,037,959 lignes parmi les 7,471,838 lignes n'ayant pas de duplicates qui ont un test_siege egal à True.\n",
    "    - `count_*`: cnt_test_* / total_rows. Pourcentage de lignes par décomposition des tests sur le nombre de lignes ayant réussi le test test_list_num_voie, décomposé par duplicate.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cas 01: similarité parfaite\n",
    "\n",
    "* Definition: Les mots dans l’adresse de l’INPI sont égales aux mots dans l’adresse de l’INSEE\n",
    "- Math definition: $\\frac{|INSEE \\cap INPI|}{|INSEE|+|INPI|-|INSEE \\cap INPI|} =1$\n",
    "- Règle: $ \\text{intersection} = \\text{union} \\rightarrow \\text{cas 1}$\n",
    "* Query [case 1](https://eu-west-3.console.aws.amazon.com/athena/home?region=eu-west-3#query/history/24e58c22-4a67-4a9e-b98d-4eb9d65e7f27)\n",
    "\n",
    "| list_inpi              | list_insee             | insee_except | intersection | union_ |\n",
    "|------------------------|------------------------|--------------|--------------|--------|\n",
    "| [BOULEVARD, HAUSSMANN] | [BOULEVARD, HAUSSMANN] | []           | 2            | 2      |\n",
    "| [QUAI, GABUT]          | [QUAI, GABUT]          | []           | 2            | 2      |\n",
    "| [BOULEVARD, VOLTAIRE]  | [BOULEVARD, VOLTAIRE]  | []           | 2            | 2      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb1, dic_tb1 = create_table_test_not_false(cas = \"CAS_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_tb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_list_num_other_tests(cas = 'CAS_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_list_num_test_false(cas = 'CAS_1',test = 'test_enseigne')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAS 03: Intersection parfaite INPI\n",
    "\n",
    "* Definition:  Tous les mots dans l’adresse de l’INPI  sont contenus dans l’adresse de l’INSEE\n",
    "* Math définition: $\\frac{|INPI|}{|INSEE \\cap INPI|}  \\text{  = 1 and }|INSEE \\cap INPI| <> |INSEE \\cup INPI|$\n",
    "* Query [case 3](https://eu-west-3.console.aws.amazon.com/athena/home?region=eu-west-3#query/history/7fb420a1-5f50-4256-a2ba-b8c7c2b63c9b)\n",
    "* Règle: $|\\text{list_inpi}|= \\text{intersection}  \\text{  = 1 and }\\text{intersection} \\neq  \\text{union} \\rightarrow \\text{cas 3}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb3, dic_tb3 = create_table_test_not_false(cas = \"CAS_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_tb3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_list_num_other_tests(cas = 'CAS_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_list_num_test_false(cas = 'CAS_3',test = 'test_type_voie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAS 04: Intersection parfaite INSEE\n",
    "\n",
    "* Definition:  Tous les mots dans l’adresse de l’INSEE  sont contenus dans l’adresse de l’INPI\n",
    "* Math definition: $\\frac{|INSEE|}{|INSEE \\cap INPI|}  \\text{  = 1 and }|INSEE \\cap INPI| <> |INSEE \\cup INPI|$\n",
    "* Query [case 4](https://eu-west-3.console.aws.amazon.com/athena/home?region=eu-west-3#query/history/65344bf4-8999-4ddb-a65e-11bb825f5f40)\n",
    "* Règle: $|\\text{list_insee}|= \\text{intersection}  \\text{  = 1 and }\\text{intersection} \\neq  \\text{union} \\rightarrow \\text{cas 4}$\n",
    "\n",
    "| list_inpi                                                 | list_insee                                      | insee_except | intersection | union_ |\n",
    "|-----------------------------------------------------------|-------------------------------------------------|--------------|--------------|--------|\n",
    "| [ROUTE, D, ENGHIEN]                                       | [ROUTE, ENGHIEN]                                | []           | 2            | 3      |\n",
    "| [ZAC, PARC, D, ACTIVITE, PARIS, EST, ALLEE, LECH, WALESA] | [ALLEE, LECH, WALESA, ZAC, PARC, ACTIVITE, EST] | []           | 7            | 9      |\n",
    "| [LIEU, DIT, PADER, QUARTIER, RIBERE]                      | [LIEU, DIT, RIBERE]                             | []           | 3            | 5      |\n",
    "| [A, BOULEVARD, CONSTANTIN, DESCAT]                        | [BOULEVARD, CONSTANTIN, DESCAT]                 | []           | 3            | 4      |\n",
    "| [RUE, MENILMONTANT, BP]                                   | [RUE, MENILMONTANT]                             | []           | 2            | 3      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb4, dic_tb4 = create_table_test_not_false(cas = \"CAS_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_tb4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_list_num_other_tests(cas = 'CAS_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_list_num_test_false(cas = 'CAS_4',test = 'test_type_voie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAS 05: Cardinality exception parfaite INSEE INPI, intersection positive\n",
    "\n",
    "* Definition:  L’adresse de l’INPI contient des mots de l’adresse de l’INSEE et la cardinality des mots non présents dans les deux adresses est équivalente\n",
    "* Math definition: $|INPI|-|INPI \\cap INSEE| = |INSEE|-|INPI \\cap INSEE|$\n",
    "* Query [case 5](https://eu-west-3.console.aws.amazon.com/athena/home?region=eu-west-3#query/history/fec67222-3a7b-4bfb-af20-dd70d82932e3)\n",
    "* Règle: $|\\text{insee_except}| = |\\text{inpi_except}| \\text{ and } \\text{intersection} > 0 \\rightarrow \\text{cas 5}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb5, dic_tb5 = create_table_test_not_false(cas = \"CAS_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_tb5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_list_num_other_tests(cas = 'CAS_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_list_num_test_false(cas = 'CAS_5',test = 'test_type_voie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAS 06: Cardinality exception INSEE supérieure INPI, intersection positive \n",
    "\n",
    "* Definition:  L’adresse de l’INPI contient des mots de l’adresse de l’INSEE et la cardinality des mots non présents dans l’adresse de l’INSEE est supérieure à la cardinality de l’adresse de l’INPI\n",
    "* Math definition: $|INPI|-|INPI \\cap INSEE| < |INSEE|-|INPI \\cap INSEE|$\n",
    "* Query [case 6](https://eu-west-3.console.aws.amazon.com/athena/home?region=eu-west-3#query/history/9bdce567-5871-4a5a-add4-d5cca6a83528)\n",
    "* Règle: $|\\text{insee_except}| > |\\text{inpi_except}| \\text{ and } \\text{intersection} > 0 \\rightarrow \\text{cas 6}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb6, dic_tb6 = create_table_test_not_false(cas = \"CAS_6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_tb6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_list_num_other_tests(cas = 'CAS_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_list_num_test_false(cas = 'CAS_6',test = 'test_type_voie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAS 07: Cardinality exception INPI supérieure INSEE, intersection positive \n",
    "\n",
    "* Definition:  L’adresse de l’INSEE contient des mots de l’adresse de l’INPI et la cardinality des mots non présents dans l’adresse de l’INPI est supérieure à la cardinality de l’adresse de l’INSEE\n",
    "* Math definition: $|INPI|-|INPI \\cap INSEE| > |INSEE|-|INPI \\cap INSEE|$\n",
    "* Règle: $|\\text{insee_except}| < |\\text{inpi_except}| \\text{ and } \\text{intersection} > 0 \\rightarrow \\text{cas 7}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb7, dic_tb7 = create_table_test_not_false(cas = \"CAS_7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_tb7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_list_num_other_tests(cas = 'CAS_7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_list_num_test_false(cas = 'CAS_7',test = 'test_type_voie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume tests\n",
    "\n",
    "La différence du nombre d'observation vient du cas numéro 2, ou les siren ont été matché mais aucune des deux adresses ne correspond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_to_find = {\n",
    "    'cas':[],\n",
    "    'lignes_matche_list_num':[],\n",
    "    'to_find':[],\n",
    "    'lignes_matche_list_num_pct': [],\n",
    "    \n",
    "}\n",
    "\n",
    "for d, value in enumerate([dic_tb1,dic_tb3,dic_tb4,dic_tb5,dic_tb6,dic_tb7]):\n",
    "    cas = d + 1\n",
    "    if d >= 1:\n",
    "        cas = d + 2\n",
    "    nb_to_find['cas'].append(cas)\n",
    "    nb_to_find['to_find'].append(value['lignes_a_trouver']['test_list_num_voie'][0]),\n",
    "    nb_to_find['lignes_matche_list_num'].append(value['lignes_matches']['lignes_matche_list_num']),\n",
    "    nb_to_find['lignes_matche_list_num_pct'].append(value['lignes_matches']['lignes_matche_list_num_pct'])\n",
    "    \n",
    "reindex = [\"cas\",\n",
    "           \"lignes_matche_list_num\", \"lignes_matche_list_num_pct\", \"cum_sum_matche\",\"cum_sum_matche_pct\",\n",
    "           \"to_find\",\"to_find_pct\", \"cum_sum_to_find\", \"cum_sum_to_find_pct\"\n",
    "          ]\n",
    "    \n",
    "(pd.DataFrame(nb_to_find).assign(\n",
    "    cum_sum_to_find = lambda x: x['to_find'].cumsum(),\n",
    "    cum_sum_matche = lambda x: x['lignes_matche_list_num'].cumsum(),\n",
    "    cum_sum_matche_pct = lambda x: x['lignes_matche_list_num_pct'].cumsum(),\n",
    "    to_find_pct = lambda x:  x['to_find']/x['to_find'].sum(),\n",
    "    cum_sum_to_find_pct = lambda x: x['cum_sum_to_find']/x['to_find'].sum(),\n",
    "    #cum_sum_to_find_pct = lambda x: x['pct_total'].cumsum(),\n",
    "    #cum_sum_pct_inverse = lambda x: 1-x['pct_total'].cumsum(),\n",
    "    #cum_pct_match = lambda x: x['pct_match'].cumsum(),\n",
    "    \n",
    ")\n",
    " .reindex(columns  = reindex)\n",
    " .style\n",
    " .format(\"{:.2%}\", subset =  ['lignes_matche_list_num_pct', 'cum_sum_matche_pct', 'to_find_pct',\n",
    "                              'cum_sum_to_find_pct'])\n",
    " .format(\"{:,.0f}\", subset =  ['lignes_matche_list_num','cum_sum_matche', 'to_find', 'cum_sum_to_find'])\n",
    " .bar(subset= ['lignes_matche_list_num_pct','to_find_pct'], color='#d65f5f')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, shutil, urllib, ipykernel, json\n",
    "from pathlib import Path\n",
    "from notebook import notebookapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_report(extension = \"html\"):\n",
    "    \"\"\"\n",
    "    Create a report from the current notebook and save it in the \n",
    "    Report folder (Parent-> child directory)\n",
    "    \n",
    "    1. Exctract the current notbook name\n",
    "    2. Convert the Notebook \n",
    "    3. Move the newly created report\n",
    "    \n",
    "    Args:\n",
    "    extension: string. Can be \"html\", \"pdf\", \"md\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ### Get notebook name\n",
    "    connection_file = os.path.basename(ipykernel.get_connection_file())\n",
    "    kernel_id = connection_file.split('-', 1)[0].split('.')[0]\n",
    "\n",
    "    for srv in notebookapp.list_running_servers():\n",
    "        try:\n",
    "            if srv['token']=='' and not srv['password']:  \n",
    "                req = urllib.request.urlopen(srv['url']+'api/sessions')\n",
    "            else:\n",
    "                req = urllib.request.urlopen(srv['url']+ \\\n",
    "                                             'api/sessions?token=' + \\\n",
    "                                             srv['token'])\n",
    "            sessions = json.load(req)\n",
    "            notebookname = sessions[0]['name']\n",
    "        except:\n",
    "            pass  \n",
    "    \n",
    "    sep = '.'\n",
    "    path = os.getcwd()\n",
    "    #parent_path = str(Path(path).parent)\n",
    "    \n",
    "    ### Path report\n",
    "    #path_report = \"{}/Reports\".format(parent_path)\n",
    "    #path_report = \"{}/Reports\".format(path)\n",
    "    \n",
    "    ### Path destination\n",
    "    name_no_extension = notebookname.split(sep, 1)[0]\n",
    "    source_to_move = name_no_extension +'.{}'.format(extension)\n",
    "    dest = os.path.join(path,'Reports', source_to_move)\n",
    "    \n",
    "    ### Generate notebook\n",
    "    os.system('jupyter nbconvert --no-input --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    \n",
    "    ### Move notebook to report folder\n",
    "    #time.sleep(5)\n",
    "    shutil.move(source_to_move, dest)\n",
    "    print(\"Report Available at this adress:\\n {}\".format(dest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_report(extension = \"html\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
