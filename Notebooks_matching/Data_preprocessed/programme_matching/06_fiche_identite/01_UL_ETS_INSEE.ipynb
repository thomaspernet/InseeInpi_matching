{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rapprochement INSEE UL ETS\n",
    "\n",
    "```\n",
    "Entant que {X} je souhaite {normaliser la variable pays} afin de {pouvoir la faire correspondre à l'INSEE}\n",
    "```\n",
    "\n",
    "**Metadatab**\n",
    "\n",
    "- Taiga:\n",
    "    - Numero US: []()\n",
    "- Gitlab\n",
    "    - Notebook: []()\n",
    "    - Markdown: []()\n",
    "    - Data:\n",
    "        - []()\n",
    "        - \n",
    "\n",
    "# Contexte\n",
    "\n",
    "\n",
    "# US / ISSUES liées\n",
    "\n",
    "[PO & DEV : s'il existe des références, les inscrire]\n",
    "\n",
    "# Besoin\n",
    "\n",
    "Dans cette US, le besoin est le suivant:\n",
    "\n",
    "- créer une table contenant les informations sur les PP/PM et établissements a l'INPI et les informations sur les UL et etablissments à l'INSEE\n",
    "\n",
    "![](https://app.lucidchart.com/publicSegments/view/2a1a8c67-097c-4022-931e-6ee13d24371b/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spécifications\n",
    "\n",
    "### Origine information (si applicable) \n",
    "\n",
    "- Metadata:\n",
    "    - Type\n",
    "    - Source\n",
    "    - Summary\n",
    "    \n",
    "## Input\n",
    "\n",
    "[PO : dans le cas de transformation de données, préciser ,les sources :\n",
    "\n",
    "*   Applications\n",
    "*   Schémas\n",
    "*   Tables: `inpi_etablissement_historique`\n",
    "*   CSV: \n",
    "*   Champs: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple Input 1\n",
    "\n",
    "XXX\n",
    "\n",
    "**Snippet**\n",
    "\n",
    "- [Snippet 1]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from awsPy.aws_authorization import aws_connector\n",
    "from awsPy.aws_s3 import service_s3\n",
    "from awsPy.aws_athena import service_athena\n",
    "import os, time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'calfdata'\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent)\n",
    "path_cred = \"{}/credential_AWS.json\".format(parent_path)\n",
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                        region = 'eu-west-3')\n",
    "client= con.client_boto()\n",
    "s3 = service_s3.connect_S3(client = client,\n",
    "                      bucket = 'calfdata') \n",
    "athena = service_athena.connect_athena(client = client,\n",
    "                      bucket = 'calfdata') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple Input 2\n",
    "\n",
    "XXX\n",
    "\n",
    "**Snippet**\n",
    "\n",
    "- [Snippet 2]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "\n",
    "[PO : dans le cas de transformation de données, préciser les sorties :\n",
    "\n",
    "*   BDD cibles\n",
    "*   Tables: `inpi_etablissement_historique`\n",
    "*   Champs: \n",
    "\n",
    "]\n",
    "\n",
    "XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Règles de gestion applicables\n",
    "\n",
    "[PO : Formules applicables]\n",
    "\n",
    "Si nouvelle règle, ajouter ici.\n",
    "\n",
    "# Charges de l'équipe\n",
    "\n",
    "[\n",
    "\n",
    "PO : Si des étapes particulières / des points d'attention sont attendus, être aussi explicite que possible\n",
    "\n",
    "Spécifiquement pour l'intégration de nouvelles données dans DATUM :\n",
    "\n",
    "*   Nombre de lignes chargées pour chaque nouvelle table\n",
    "*   Poids de chaque nouvelle table\n",
    "*   Durée du traitement ajouté (+ durée avant et après)\n",
    "\n",
    "]\n",
    "\n",
    "# Tests d'acceptance\n",
    "\n",
    "[PO : comment contrôler que la réalisation est conforme]\n",
    "\n",
    "**Code reproduction**\n",
    "\n",
    "```\n",
    "```\n",
    "\n",
    "\n",
    "# CONCEPTION\n",
    "\n",
    "Conception réalisée par ............. et ..................\n",
    "\n",
    "[DEV :\n",
    "\n",
    "Important :\n",
    "\n",
    "*   Ce chapitre doit impérativement être complété **avant de basculer l'US à 'développement en cours'**\n",
    "*   La conception doit systématiquement être **faite à deux**\n",
    "*   Il ne doit **pas y avoir de code dans ce chapitre**\n",
    "*   Tout au long du développement, ce chapitre doit être enrichi\n",
    "*   Le nom du binôme ayant participé à la conception doit être précisé dans l'US\n",
    "\n",
    "Contenu :\n",
    "\n",
    "*   Décrire les traitements nouveaux / modifiés : emplacement des fichiers (liens vers GIT), mise en avant des évolutions fortes, impacts dans la chaîne d'exploitation\n",
    "*   Points d'attention spécifiques : notamment sur les règles de gestion et leur mise en oeuvre technique\n",
    "\n",
    "]\n",
    "\n",
    "# Evolution de la documentation\n",
    "\n",
    "[DEV :\n",
    "\n",
    "*   Identifier les champs enrichis dans le dictionnaire de données\n",
    "*   Identifier les impacts dans les documents pérennes DTA, DEXP, Consignes de supervision\n",
    "*   Identifier les impacts dans les documents de MEP (FI)\n",
    "\n",
    "]\n",
    "\n",
    "# Tests réalisés\n",
    "\n",
    "[DEV : préciser les tests réalisés pour contrôler le bon fonctionnement, et les résultats obtenus]\n",
    "\n",
    "# Tests automatiques mis en oeuvre\n",
    "\n",
    "[DEV : préciser les TA et expliciter leur fonctionnement]\n",
    "\n",
    "# Démonstration\n",
    "\n",
    "[DEV : suivant le cas, publier sur le sharepoint et mettre un lien ici soit :\n",
    "\n",
    "*   Capture d'écran\n",
    "*   Vidéo publiée\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, shutil, urllib, ipykernel, json\n",
    "from pathlib import Path\n",
    "from notebook import notebookapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_report(extension = \"html\"):\n",
    "    \"\"\"\n",
    "    Create a report from the current notebook and save it in the \n",
    "    Report folder (Parent-> child directory)\n",
    "    \n",
    "    1. Exctract the current notbook name\n",
    "    2. Convert the Notebook \n",
    "    3. Move the newly created report\n",
    "    \n",
    "    Args:\n",
    "    extension: string. Can be \"html\", \"pdf\", \"markdown\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ### Get notebook name\n",
    "    connection_file = os.path.basename(ipykernel.get_connection_file())\n",
    "    kernel_id = connection_file.split('-', 1)[1].split('.')[0]\n",
    "\n",
    "    for srv in notebookapp.list_running_servers():\n",
    "        try:\n",
    "            if srv['token']=='' and not srv['password']:  \n",
    "                req = urllib.request.urlopen(srv['url']+'api/sessions')\n",
    "            else:\n",
    "                req = urllib.request.urlopen(srv['url']+ \\\n",
    "                                             'api/sessions?token=' + \\\n",
    "                                             srv['token'])\n",
    "            sessions = json.load(req)\n",
    "            notebookname = sessions[0]['name']\n",
    "        except:\n",
    "            pass  \n",
    "    \n",
    "    sep = '.'\n",
    "    path = os.getcwd()\n",
    "    parent_path = str(Path(path).parent)\n",
    "    \n",
    "    ### Path report\n",
    "    #path_report = \"{}/Reports\".format(parent_path)\n",
    "    #path_report = \"{}/Reports\".format(path)\n",
    "    \n",
    "    ### Path destination\n",
    "    name_no_extension = notebookname.split(sep, 1)[0]\n",
    "    if extension == 'markdown':\n",
    "        #extension = 'md'\n",
    "        os.remove(name_no_extension +'.{}'.format('md'))\n",
    "        source_to_move = name_no_extension +'.{}'.format('md')\n",
    "    else:\n",
    "        source_to_move = name_no_extension +'.{}'.format(extension)\n",
    "    dest = os.path.join(path,'US_md', source_to_move)\n",
    "    \n",
    "    print('jupyter nbconvert --no-input --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    \n",
    "    ### Generate notebook\n",
    "    os.system('jupyter nbconvert --no-input --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    \n",
    "    ### Move notebook to report folder\n",
    "    #time.sleep(5)\n",
    "    shutil.move(source_to_move, dest)\n",
    "    print(\"Report Available at this adress:\\n {}\".format(dest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_report(extension = \"markdown\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
