{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation table merge INSEE INPI filtree \n",
    "\n",
    "Copy paste from Coda to fill the information\n",
    "\n",
    "# Objective(s)\n",
    "\n",
    "*  Création d’une table contenant la jointure des tables de l’INSEE et de l’INPI transformées. \n",
    "* Dans cette jointure, il n’est pas nécessaire de récupérer toutes les variables. Seules les variables énumérées ci-dessous seront utilisées:\n",
    "  * `row_id`\n",
    "  * `index_id` \n",
    "  * `sequence_id`  \n",
    "  * `count_initial_insee`  \n",
    "  * `ets_inpi_sql.siren` \n",
    "  * `siret` \n",
    "  * `datecreationetablissement` \n",
    "  * `date_debut_activite` \n",
    "  * `etatadministratifetablissement` \n",
    "  * `status_admin` \n",
    "  * `etablissementsiege` \n",
    "  * `status_ets` \n",
    "  * `adresse_distance_inpi` \n",
    "  * `adresse_distance_insee` \n",
    "  * `list_numero_voie_matching_inpi` \n",
    "  * `list_numero_voie_matching_insee` \n",
    "  * `ets_inpi_sql.code_postal_matching` \n",
    "  * `ets_inpi_sql.ville_matching` \n",
    "  * `codecommuneetablissement` \n",
    "  * `code_commune` \n",
    "  * `enseigne` \n",
    "  * `list_enseigne` \n",
    "\n",
    "# Metadata\n",
    "\n",
    "* Epic: Epic 6\n",
    "* US: US 4\n",
    "* Date Begin: 9/28/2020\n",
    "* Duration Task: 0\n",
    "* Description: Merger les tables insee et inpi afin d’avoir une table prête pour la réalisation des tests pour la siretisation\n",
    "* Step type: Transform table\n",
    "* Status: Active\n",
    "  * Change Status task: Active\n",
    "  * Update table: Modify rows\n",
    "* Source URL: US 04 Merge table INSEE INPI\n",
    "* Task type: Jupyter Notebook\n",
    "* Users: Thomas Pernet\n",
    "* Watchers: Thomas Pernet\n",
    "* User Account: https://937882855452.signin.aws.amazon.com/console\n",
    "* Estimated Log points: 10\n",
    "* Task tag: #athena,#sql,#data-preparation,#inpi,#insee\n",
    "* Toggl Tag: #documentation\n",
    "\n",
    "# Input Cloud Storage [AWS/GCP]\n",
    "\n",
    "## Table/file\n",
    "\n",
    "* Origin: \n",
    "* Athena\n",
    "* Name: \n",
    "* ets_inpi_transformed\n",
    "* ets_insee_transformed\n",
    "* Github: \n",
    "  * https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/10_sumup_preparation/02_creation_variables_siretisation_inpi.md\n",
    "  * https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/10_sumup_preparation/03_creation_variables_siretisation_insee.md\n",
    "\n",
    "# Destination Output/Delivery\n",
    "\n",
    "## Table/file\n",
    "* Origin: \n",
    "* Athena\n",
    "* Name:\n",
    "* ets_insee_inpi\n",
    "* GitHub:\n",
    "* https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/11_sumup_siretisation/00_merge_ets_insee_inpi.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connexion serveur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awsPy.aws_authorization import aws_connector\n",
    "from awsPy.aws_athena import service_athena\n",
    "from awsPy.aws_s3 import service_s3\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os, shutil\n",
    "\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent)\n",
    "path_cred = r\"{}/credential_AWS.json\".format(parent_path)\n",
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = 'eu-west-3')\n",
    "\n",
    "region = 'eu-west-3'\n",
    "bucket = 'calfdata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = region)\n",
    "client= con.client_boto()\n",
    "s3 = service_s3.connect_S3(client = client,\n",
    "                      bucket = bucket, verbose = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_setting = True\n",
    "if pandas_setting:\n",
    "    cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation tables\n",
    "\n",
    "## Steps\n",
    "\n",
    "- Merger la table `` avec `` \n",
    "    - utiliser `inner join`\n",
    "- Filtrer lorsque statut est différent de 'IGNORE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output = 'inpi/sql_output'\n",
    "database = 'inpi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "DROP TABLE `siretisation.ets_insee_inpi`;\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "  filename = None, ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "CREATE TABLE siretisation.ets_insee_inpi \n",
    "WITH (\n",
    "  format='PARQUET'\n",
    ") AS\n",
    " SELECT \n",
    "    ROW_NUMBER() OVER () AS row_id, \n",
    "    index_id, \n",
    "    sequence_id, \n",
    "    count_initial_insee, \n",
    "    ets_inpi_sql.siren, \n",
    "    siret, \n",
    "    datecreationetablissement, \n",
    "    \"date_début_activité\", \n",
    "    etatadministratifetablissement, \n",
    "    status_admin, \n",
    "    etablissementsiege, \n",
    "    status_ets, \n",
    "    adresse_distance_inpi, \n",
    "    adresse_distance_insee, \n",
    "    list_numero_voie_matching_inpi, \n",
    "    list_numero_voie_matching_insee, \n",
    "    typevoieetablissement, \n",
    "    type_voie_matching, \n",
    "    ets_inpi_sql.code_postal_matching, \n",
    "    ets_inpi_sql.ville_matching, \n",
    "    codecommuneetablissement, \n",
    "    code_commune, \n",
    "    enseigne, \n",
    "    list_enseigne,\n",
    "    enseigne1etablissement, \n",
    "    enseigne2etablissement, \n",
    "    enseigne3etablissement \n",
    "  FROM \n",
    "    siretisation.ets_inpi_sql \n",
    "    INNER JOIN (\n",
    "      SELECT \n",
    "        count_initial_insee, \n",
    "        siren, \n",
    "        siret, \n",
    "        datecreationetablissement, \n",
    "        etablissementsiege, \n",
    "        etatadministratifetablissement, \n",
    "        codepostaletablissement, \n",
    "        codecommuneetablissement, \n",
    "        ville_matching, \n",
    "        list_numero_voie_matching_insee, \n",
    "        numerovoieetablissement, \n",
    "        typevoieetablissement, \n",
    "        adresse_reconstituee_insee, \n",
    "        adresse_distance_insee, \n",
    "        list_enseigne,\n",
    "        enseigne1etablissement, \n",
    "        enseigne2etablissement,\n",
    "        enseigne3etablissement \n",
    "      FROM \n",
    "        siretisation.ets_insee_sql\n",
    "    ) as insee ON ets_inpi_sql.siren = insee.siren \n",
    "    AND ets_inpi_sql.ville_matching = insee.ville_matching \n",
    "    AND ets_inpi_sql.code_postal_matching = insee.codepostaletablissement \n",
    "  WHERE \n",
    "    status != 'IGNORE'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "s3.run_query(\n",
    "    query=query,\n",
    "    database=database,\n",
    "    s3_output=s3_output,\n",
    "    filename = None, ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation\n",
    "\n",
    "1. Imprimer 10 lignes aléatoirement\n",
    "2. Compter le nombre d'observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM siretisation.ets_insee_inpi\n",
    "limit 10\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database='siretisation',\n",
    "            s3_output=s3_output,\n",
    "  filename = 'exemple_siretisation', ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT COUNT(*)\n",
    "FROM siretisation.ets_insee_inpi\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database='siretisation',\n",
    "            s3_output=s3_output,\n",
    "  filename = 'count_siretisation', ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, shutil, urllib, ipykernel, json\n",
    "from pathlib import Path\n",
    "from notebook import notebookapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_report(extension = \"html\", keep_code = False):\n",
    "    \"\"\"\n",
    "    Create a report from the current notebook and save it in the \n",
    "    Report folder (Parent-> child directory)\n",
    "    \n",
    "    1. Exctract the current notbook name\n",
    "    2. Convert the Notebook \n",
    "    3. Move the newly created report\n",
    "    \n",
    "    Args:\n",
    "    extension: string. Can be \"html\", \"pdf\", \"md\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ### Get notebook name\n",
    "    connection_file = os.path.basename(ipykernel.get_connection_file())\n",
    "    kernel_id = connection_file.split('-', 1)[0].split('.')[0]\n",
    "\n",
    "    for srv in notebookapp.list_running_servers():\n",
    "        try:\n",
    "            if srv['token']=='' and not srv['password']:  \n",
    "                req = urllib.request.urlopen(srv['url']+'api/sessions')\n",
    "            else:\n",
    "                req = urllib.request.urlopen(srv['url']+ \\\n",
    "                                             'api/sessions?token=' + \\\n",
    "                                             srv['token'])\n",
    "            sessions = json.load(req)\n",
    "            notebookname = sessions[0]['name']\n",
    "        except:\n",
    "            pass  \n",
    "    \n",
    "    sep = '.'\n",
    "    path = os.getcwd()\n",
    "    #parent_path = str(Path(path).parent)\n",
    "    \n",
    "    ### Path report\n",
    "    #path_report = \"{}/Reports\".format(parent_path)\n",
    "    #path_report = \"{}/Reports\".format(path)\n",
    "    \n",
    "    ### Path destination\n",
    "    name_no_extension = notebookname.split(sep, 1)[0]\n",
    "    source_to_move = name_no_extension +'.{}'.format(extension)\n",
    "    dest = os.path.join(path,'Reports', source_to_move)\n",
    "    \n",
    "    ### Generate notebook\n",
    "    if keep_code:\n",
    "        os.system('jupyter nbconvert --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    else:\n",
    "        os.system('jupyter nbconvert --no-input --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    \n",
    "    ### Move notebook to report folder\n",
    "    #time.sleep(5)\n",
    "    shutil.move(source_to_move, dest)\n",
    "    print(\"Report Available at this adress:\\n {}\".format(dest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_report(extension = \"html\", keep_code = True)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.24.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
