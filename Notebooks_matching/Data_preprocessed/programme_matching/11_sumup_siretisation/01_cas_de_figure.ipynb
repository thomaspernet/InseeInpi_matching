{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation de la table contenant les statut entre les adresses INSEE et INPI\n",
    "\n",
    "# Objective(s)\n",
    "\n",
    "*  Creation des cas de figures possible entre la comparaison de l’adresse INSEE et l’adresse de l’INPI\n",
    "* Please, update the Source URL by clicking on the button after the information have been pasted\n",
    "  * US 05 Creation variables de siretisation Modify rows\n",
    "  * Delete tables and Github related to the US: Delete rows\n",
    "\n",
    "# Metadata\n",
    "\n",
    "* Epic: Epic 6\n",
    "* US: US 5\n",
    "* Date Begin: 9/29/2020\n",
    "* Duration Task: 0\n",
    "* Description: Creation de la documentation avec les types de statut et creation de la table statut\n",
    "* Step type: Transform table\n",
    "* Status: Active\n",
    "  * Change Status task: Active\n",
    "  * Update table: Modify rows\n",
    "* Source URL: US 05 Creation variables de siretisation\n",
    "* Task type: Jupyter Notebook\n",
    "* Users: Thomas Pernet\n",
    "* Watchers: Thomas Pernet\n",
    "* User Account: https://937882855452.signin.aws.amazon.com/console\n",
    "* Estimated Log points: 5\n",
    "* Task tag: #athena,#sql,#data-preparation,#inpi,#insee\n",
    "* Toggl Tag: #documentation\n",
    "\n",
    "# Input Cloud Storage [AWS/GCP]\n",
    "\n",
    "\n",
    "## Table/file\n",
    "\n",
    "* Origin: \n",
    "* Athena\n",
    "* Name: \n",
    "* ets_insee_inpi\n",
    "* Github: \n",
    "  * https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/11_sumup_siretisation/00_merge_ets_insee_inpi.md\n",
    "\n",
    "# Destination Output/Delivery\n",
    "\n",
    "## Table/file\n",
    "\n",
    "* Origin: \n",
    "* Athena\n",
    "* Name:\n",
    "* ets_insee_inpi_statut_cas\n",
    "* GitHub:\n",
    "* https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/11_sumup_siretisation/01_cas_de_figure.md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "  *   La version 2 de la siretisation ne se résume plus a une prise en compte de quelques règles écrits pour dédoubler les lignes. Dans cette version, les tests représentent un ensemble cohérent et ordonné de règles gestion. \n",
    "  * Avant tout chose, nous devons lister puis créer ses tests à partir de la table ets_insee_inpi créer lors de l’US, [Creation table merge INSEE INPI filtree](https://coda.io/d/CreditAgricole_dCtnoqIftTn/US-07-Preparation-tables-et-variables-tests_suFb9). \n",
    "  *  La variable `status_cas`  indique le cas de figure détecté entre l'adresse de l'INSEE et l'INPI. Il y a 5 possibilités au total:\n",
    "    *   CAS_1: Les mots dans l’adresse de l’INPI sont égales aux mots dans l’adresse de l’INSEE\n",
    "    *   CAS_2: Aucun des mots de l’adresse de l’INPI sont égales aux mots dans l’adresse de l’INSEE\n",
    "    *   CAS_3: Cardinalite exception parfaite mots INPI ou INSEE\n",
    "    *   CAS_4: Cardinalite Exception mots INPI diffférente Cardinalite Exception mots INSEE\n",
    "    *   CAS_5: Cadrinalite exception insee est égal de 0 ou cardinalite exception inpi est égal de 0\n",
    "    *   CAS_6: CAS_NO_ADRESSE\n",
    "  * Creation variables supplémentaires\n",
    "      * `insee_except`: Liste de mots provenant de l'INSEE non contenue dans l'INPI\n",
    "      * `inpi_except`: Liste de mots provenant de l'INPI non contenue dans l'INSEE\n",
    "      * `intersection`: Nombre de mots en commun\n",
    "      * `union_`: Nombre de mots total entre les deux adresses\n",
    "      * `pct_intersection`: `intersection` / `union_`\n",
    " * Il faut penser a garder la variable `row_id` \n",
    " \n",
    " Le tableau ci dessous indique l'ensemble des tests a réaliser ainsi que leur dépendence.\n",
    " \n",
    " | Rang | Nom_variable                              | Dependence                                    | Notebook                           | Difficulte | Table_input                                                                                                                                                            | Variables_crees_US                                                                 | Possibilites                  |\n",
    "|------|-------------------------------------------|-----------------------------------------------|------------------------------------|------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------|-------------------------------|\n",
    "| 1    | status_cas                                |                                               | 02_cas_de_figure                   | Moyen      | ets_insee_inpi_status_cas                                                                                                                                              | status_cas,intersection,pct_intersection,union_,inpi_except,insee_except           | CAS_1,CAS_2,CAS_3,CAS_4,CAS_5 |\n",
    "| 2    | test_list_num_voie                        | intersection_numero_voie,union_numero_voie    | 03_test_list_num_voie              | Moyen      | ets_insee_inpi_list_num_voie                                                                                                                                           | intersection_numero_voie,union_numero_voie                                         | FALSE,NULL,TRUE,PARTIAL       |\n",
    "| 3    | test_enseigne                             | list_enseigne,enseigne                        | 04_test_enseigne                   | Moyen      | ets_insee_inpi_list_enseigne                                                                                                                                           | list_enseigne_contain                                                              | FALSE,NULL,TRUE               |\n",
    "| 4    | test_pct_intersection                     | pct_intersection,index_id_max_intersection    | 06_creation_nb_siret_siren_max_pct | Facile     | ets_insee_inpi_var_group_max                                                                                                                                           | count_inpi_index_id_siret,count_inpi_siren_siret,index_id_max_intersection         | FALSE,TRUE                    |\n",
    "| 4    | test_index_id_duplicate                   | count_inpi_index_id_siret                     | 06_creation_nb_siret_siren_max_pct | Facile     | ets_insee_inpi_var_group_max                                                                                                                                           | count_inpi_index_id_siret,count_inpi_siren_siret,index_id_max_intersection         | FALSE,TRUE                    |\n",
    "| 4    | test_siren_insee_siren_inpi               | count_initial_insee,count_inpi_siren_siret    | 06_creation_nb_siret_siren_max_pct | Facile     | ets_insee_inpi_var_group_max                                                                                                                                           | count_inpi_index_id_siret,count_inpi_siren_siret,index_id_max_intersection         | FALSE,TRUE                    |\n",
    "| 5    | test_similarite_exception_words           | max_cosine_distance                           | 08_calcul_cosine_levhenstein       | Difficile  | ets_insee_inpi_similarite_max_word2vec                                                                                                                                 | unzip_inpi,unzip_insee,max_cosine_distance,levenshtein_distance,key_except_to_test | FALSE,NULL,TRUE               |\n",
    "| 5    | test_distance_levhenstein_exception_words | levenshtein_distance                          | 08_calcul_cosine_levhenstein       | Difficile  | ets_insee_inpi_similarite_max_word2vec                                                                                                                                 | unzip_inpi,unzip_insee,max_cosine_distance,levenshtein_distance,key_except_to_test | FALSE,NULL,TRUE               |\n",
    "| 6    | test_date                                 | datecreationetablissement,date_debut_activite | 10_match_et_creation_regles.md     | Facile     | ets_insee_inpi_list_num_voie,ets_insee_inpi_list_enseigne,ets_insee_inpi_similarite_max_word2vec,ets_insee_inpi_status_cas,ets_insee_inpi_var_group_max,ets_insee_inpi |                                                                                    | FALSE,TRUE                    |\n",
    "| 6    | test_siege                                | status_ets,etablissementsiege                 | 10_match_et_creation_regles.md     | Facile     | ets_insee_inpi_list_num_voie,ets_insee_inpi_list_enseigne,ets_insee_inpi_similarite_max_word2vec,ets_insee_inpi_status_cas,ets_insee_inpi_var_group_max,ets_insee_inpi |                                                                                    | FALSE,TRUE,NULL               |\n",
    "| 6    | test_status_admin                         | etatadministratifetablissement,status_admin   | 10_match_et_creation_regles.md     | Facile     | ets_insee_inpi_list_num_voie,ets_insee_inpi_list_enseigne,ets_insee_inpi_similarite_max_word2vec,ets_insee_inpi_status_cas,ets_insee_inpi_var_group_max,ets_insee_inpi |                                                                                    | FALSE,NULL,TRUE               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connexion serveur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awsPy.aws_authorization import aws_connector\n",
    "from awsPy.aws_athena import service_athena\n",
    "from awsPy.aws_s3 import service_s3\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os, shutil\n",
    "\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent)\n",
    "path_cred = r\"{}/credential_AWS.json\".format(parent_path)\n",
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = 'eu-west-3')\n",
    "\n",
    "region = 'eu-west-3'\n",
    "bucket = 'calfdata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = region)\n",
    "client= con.client_boto()\n",
    "s3 = service_s3.connect_S3(client = client,\n",
    "                      bucket = bucket, verbose = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_setting = True\n",
    "if pandas_setting:\n",
    "    cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output = 'inpi/sql_output'\n",
    "database = 'inpi'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "DROP TABLE siretisation.ets_insee_inpi_status_cas;\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "  filename = None, ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table = \"\"\"\n",
    "CREATE TABLE siretisation.ets_insee_inpi_status_cas\n",
    "WITH (\n",
    "  format='PARQUET'\n",
    ") AS\n",
    "WITH create_var AS (\n",
    "  SELECT \n",
    "    row_id,\n",
    "    siret, \n",
    "    adresse_distance_insee, \n",
    "    adresse_distance_inpi, \n",
    "    array_distinct(\n",
    "      array_except(\n",
    "        split(adresse_distance_insee, ' '), \n",
    "        split(adresse_distance_inpi, ' ')\n",
    "      )\n",
    "    ) as insee_except, \n",
    "    array_distinct(\n",
    "      array_except(\n",
    "        split(adresse_distance_inpi, ' '), \n",
    "        split(adresse_distance_insee, ' ')\n",
    "      )\n",
    "    ) as inpi_except, \n",
    "    CAST(\n",
    "      cardinality(\n",
    "        array_distinct(\n",
    "          array_intersect(\n",
    "            split(adresse_distance_inpi, ' '), \n",
    "            split(adresse_distance_insee, ' ')\n",
    "          )\n",
    "        )\n",
    "      ) AS DECIMAL(10, 2)\n",
    "    ) as intersection, \n",
    "    CAST(\n",
    "      cardinality(\n",
    "        array_distinct(\n",
    "          array_union(\n",
    "            split(adresse_distance_inpi, ' '), \n",
    "            split(adresse_distance_insee, ' ')\n",
    "          )\n",
    "        )\n",
    "      ) AS DECIMAL(10, 2)\n",
    "    ) as union_, \n",
    "    CAST(\n",
    "      cardinality(\n",
    "        array_distinct(\n",
    "          array_intersect(\n",
    "            split(adresse_distance_inpi, ' '), \n",
    "            split(adresse_distance_insee, ' ')\n",
    "          )\n",
    "        )\n",
    "      ) AS DECIMAL(10, 2)\n",
    "    )/ CAST(\n",
    "      cardinality(\n",
    "        array_distinct(\n",
    "          array_union(\n",
    "            split(adresse_distance_inpi, ' '), \n",
    "            split(adresse_distance_insee, ' ')\n",
    "          )\n",
    "        )\n",
    "      ) AS DECIMAL(10, 2)\n",
    "    ) as pct_intersection \n",
    "  FROM \n",
    "    siretisation.ets_insee_inpi\n",
    ") \n",
    "\n",
    "SELECT \n",
    "  * \n",
    "FROM \n",
    "  (\n",
    "    WITH test AS (\n",
    "      SELECT \n",
    "      row_id,\n",
    "        siret, \n",
    "        adresse_distance_insee, \n",
    "        adresse_distance_inpi, \n",
    "        CASE WHEN cardinality(insee_except) = 0 THEN NULL ELSE insee_except END as insee_except,\n",
    "        CASE WHEN cardinality(inpi_except) = 0 THEN NULL ELSE inpi_except END as inpi_except,\n",
    "        intersection, \n",
    "        union_, \n",
    "        intersection / union_ as pct_intersection, \n",
    "        CASE WHEN intersection = union_ THEN 'CAS_1' WHEN intersection = 0 THEN 'CAS_2' WHEN CARDINALITY(insee_except) = CARDINALITY(inpi_except) \n",
    "        AND intersection != union_ \n",
    "        AND intersection != union_ \n",
    "        AND intersection != 0 THEN 'CAS_3' WHEN (\n",
    "          CARDINALITY(insee_except) = 0 \n",
    "          OR CARDINALITY(inpi_except) = 0\n",
    "        ) \n",
    "        AND intersection != union_ \n",
    "        AND intersection != 0 THEN 'CAS_5' WHEN CARDINALITY(insee_except) != CARDINALITY(inpi_except) \n",
    "        AND intersection != union_ \n",
    "        AND intersection != union_ \n",
    "        AND intersection != 0 THEN 'CAS_4' ELSE 'CAS_NO_ADRESSE' END AS status_cas \n",
    "      FROM \n",
    "        create_var \n",
    "    )\n",
    "    SELECT *\n",
    "    FROM test\n",
    "    )\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=create_table,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "  filename = None, ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "       FROM (SELECT * \n",
    "             FROm siretisation.ets_insee_inpi_status_cas\n",
    "       WHERE status_cas = 'CAS_1'\n",
    "       LIMIT 1\n",
    "             )\n",
    "       UNION (SELECT *\n",
    "       FROM siretisation.ets_insee_inpi_status_cas\n",
    "       WHERE status_cas = 'CAS_2'\n",
    "              LIMIT 1\n",
    "              )\n",
    "       UNION (SELECT *\n",
    "       FROM siretisation.ets_insee_inpi_status_cas\n",
    "       WHERE status_cas = 'CAS_3'\n",
    "              LIMIT 1\n",
    "              )\n",
    "       UNION (SELECT *\n",
    "       FROM siretisation.ets_insee_inpi_status_cas\n",
    "       WHERE status_cas = 'CAS_4'\n",
    "              LIMIT 1\n",
    "              )\n",
    "       UNION (SELECT *\n",
    "       FROM siretisation.ets_insee_inpi_status_cas\n",
    "       WHERE status_cas = 'CAS_5'\n",
    "              LIMIT 1\n",
    "              )\n",
    "       ORDER BY status_cas\n",
    "       \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "tb = s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "  filename = 'tb_exemple', ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )\n",
    "\n",
    "tb = pd.concat([\n",
    "\n",
    "pd.concat([\n",
    "tb[['siret', 'adresse_distance_insee', 'adresse_distance_inpi']]\n",
    "],keys=[\"Input\"], axis = 1),\n",
    "pd.concat([\n",
    "tb[['insee_except', 'inpi_except', 'intersection', 'union_', 'pct_intersection','status_cas']]\n",
    "],keys=[\"Output\"], axis = 1)\n",
    "], axis = 1\n",
    ")\n",
    "\n",
    "tb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test acceptance\n",
    "\n",
    "1. Vérifier que le nombre de lignes est indentique avant et après la création des variables\n",
    "2. Compter le nombre de lignes par cas\n",
    "3. Compter le nombre d'index par cas\n",
    "4. Créer un tableau avec une ligne par cas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Vérifier que le nombre de lignes est indentique avant et après la création des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT COUNT(*)\n",
    "FROM siretisation.ets_insee_inpi\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database='siretisation',\n",
    "            s3_output=s3_output,\n",
    "  filename = 'count_ets_insee_inpi', ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT count(*)\n",
    "       FROM ets_insee_inpi_status_cas\n",
    " \"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database='siretisation',\n",
    "            s3_output=s3_output,\n",
    "  filename = 'count_ets_insee_inpi_status_cas', ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compter le nombre de lignes par cas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT status_cas, count(*)\n",
    "       FROM ets_insee_inpi_status_cas\n",
    "       GROUP BY status_cas\n",
    "       ORDER BY status_cas\n",
    "       \"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database='siretisation',\n",
    "            s3_output=s3_output,\n",
    "  filename = 'count_group_ets_insee_inpi_status_cas', ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Créer un tableau avec une ligne par cas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "       SELECT *\n",
    "       FROM (SELECT * \n",
    "             FROM ets_insee_inpi_status_cas\n",
    "       WHERE status_cas = 'CAS_1'\n",
    "       LIMIT 1\n",
    "             )\n",
    "       UNION (SELECT *\n",
    "       FROM ets_insee_inpi_status_cas\n",
    "       WHERE status_cas = 'CAS_2'\n",
    "              LIMIT 1\n",
    "              )\n",
    "       UNION (SELECT *\n",
    "       FROM ets_insee_inpi_status_cas\n",
    "       WHERE status_cas = 'CAS_3'\n",
    "              LIMIT 1\n",
    "              )\n",
    "       UNION (SELECT *\n",
    "       FROM ets_insee_inpi_status_cas\n",
    "       WHERE status_cas = 'CAS_4'\n",
    "              LIMIT 1\n",
    "              )\n",
    "       UNION (SELECT *\n",
    "       FROM ets_insee_inpi_status_cas\n",
    "       WHERE status_cas = 'CAS_5'\n",
    "              LIMIT 1\n",
    "              )\n",
    "       ORDER BY status_cas\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "tb = s3.run_query(\n",
    "            query=query,\n",
    "            database='siretisation',\n",
    "            s3_output=s3_output,\n",
    "  filename = 'tb_exemple', ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )\n",
    "pd.concat([\n",
    "\n",
    "pd.concat([\n",
    "tb[['siret', 'adresse_distance_insee', 'adresse_distance_inpi']]\n",
    "],keys=[\"Input\"], axis = 1),\n",
    "pd.concat([\n",
    "tb[['insee_except', 'inpi_except', 'intersection', 'union_', 'pct_intersection','status_cas']]\n",
    "],keys=[\"Output\"], axis = 1)\n",
    "], axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, shutil, urllib, ipykernel, json\n",
    "from pathlib import Path\n",
    "from notebook import notebookapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_report(extension = \"html\", keep_code = False):\n",
    "    \"\"\"\n",
    "    Create a report from the current notebook and save it in the \n",
    "    Report folder (Parent-> child directory)\n",
    "    \n",
    "    1. Exctract the current notbook name\n",
    "    2. Convert the Notebook \n",
    "    3. Move the newly created report\n",
    "    \n",
    "    Args:\n",
    "    extension: string. Can be \"html\", \"pdf\", \"md\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ### Get notebook name\n",
    "    connection_file = os.path.basename(ipykernel.get_connection_file())\n",
    "    kernel_id = connection_file.split('-', 1)[0].split('.')[0]\n",
    "\n",
    "    for srv in notebookapp.list_running_servers():\n",
    "        try:\n",
    "            if srv['token']=='' and not srv['password']:  \n",
    "                req = urllib.request.urlopen(srv['url']+'api/sessions')\n",
    "            else:\n",
    "                req = urllib.request.urlopen(srv['url']+ \\\n",
    "                                             'api/sessions?token=' + \\\n",
    "                                             srv['token'])\n",
    "            sessions = json.load(req)\n",
    "            notebookname = sessions[0]['name']\n",
    "        except:\n",
    "            pass  \n",
    "    \n",
    "    sep = '.'\n",
    "    path = os.getcwd()\n",
    "    #parent_path = str(Path(path).parent)\n",
    "    \n",
    "    ### Path report\n",
    "    #path_report = \"{}/Reports\".format(parent_path)\n",
    "    #path_report = \"{}/Reports\".format(path)\n",
    "    \n",
    "    ### Path destination\n",
    "    name_no_extension = notebookname.split(sep, 1)[0]\n",
    "    source_to_move = name_no_extension +'.{}'.format(extension)\n",
    "    dest = os.path.join(path,'Reports', source_to_move)\n",
    "    \n",
    "    ### Generate notebook\n",
    "    if keep_code:\n",
    "        os.system('jupyter nbconvert --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    else:\n",
    "        os.system('jupyter nbconvert --no-input --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    \n",
    "    ### Move notebook to report folder\n",
    "    #time.sleep(5)\n",
    "    shutil.move(source_to_move, dest)\n",
    "    print(\"Report Available at this adress:\\n {}\".format(dest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_report(extension = \"html\", keep_code = True)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.24.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
