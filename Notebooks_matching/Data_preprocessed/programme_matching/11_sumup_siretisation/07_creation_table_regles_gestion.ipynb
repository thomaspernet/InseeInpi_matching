{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation table ensemble regles de gestion\n",
    "\n",
    "# Objective(s)\n",
    "\n",
    "La siretisation repose sur une matrice de règles de gestion classée de manière ordonnée. Pour créer la matrice, il faut au préalable créer les variables nécéssaires à la création des tests. \n",
    "\n",
    "- status_cas,\n",
    "- test_list_num_voie,\n",
    "- test_enseigne\n",
    "- test_pct_intersection\n",
    "- test_index_id_duplicate\n",
    "- test_siren_insee_siren_inpi\n",
    "- test_similarite_exception_words\n",
    "- test_distance_levhenstein_exception_words\n",
    "- test_date\n",
    "- test_siege\n",
    "- test_status_admin\n",
    "\n",
    "# Metadata\n",
    "\n",
    "* Epic: Epic 6\n",
    "* US: US 5\n",
    "* Date Begin: 9/29/2020\n",
    "* Duration Task: 0\n",
    "* Description: Création de la table des regles de gestion\n",
    "* Step type: Raw table\n",
    "* Status: Active\n",
    "  * Change Status task: Active\n",
    "  * Update table: Modify rows\n",
    "* Source URL:  \n",
    "* Task type: Jupyter Notebook\n",
    "* Users: Thomas Pernet\n",
    "* Watchers: Thomas Pernet\n",
    "* User Account: https://937882855452.signin.aws.amazon.com/console\n",
    "* Estimated Log points: 5\n",
    "* Task tag: #computation\n",
    "* Toggl Tag: #documentation\n",
    "\n",
    "# Input Cloud Storage [AWS/GCP]\n",
    "\n",
    "## Table/file\n",
    "\n",
    "* Origin: \n",
    " \n",
    "* Name: \n",
    "* \n",
    "* Github: \n",
    "* \n",
    "\n",
    "# Destination Output/Delivery\n",
    "\n",
    "## Table/file\n",
    "\n",
    "* Origin: \n",
    "* Athena\n",
    "* Name:\n",
    "* rank_matrice_regles_gestion\n",
    "* GitHub:\n",
    "* https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/11_sumup_siretisation/07_creation_table_regles_gestion.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connexion serveur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awsPy.aws_authorization import aws_connector\n",
    "from awsPy.aws_s3 import service_s3\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os, shutil\n",
    "\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent)\n",
    "path_cred = r\"{}/credential_AWS.json\".format(parent_path)\n",
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = 'eu-west-3')\n",
    "\n",
    "region = 'eu-west-3'\n",
    "bucket = 'calfdata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = region)\n",
    "client= con.client_boto()\n",
    "s3 = service_s3.connect_S3(client = client,\n",
    "                      bucket = bucket, verbose = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_setting = True\n",
    "if pandas_setting:\n",
    "    cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "La siretisation repose sur une matrice de règles de gestion classée de manière ordonnée. Pour créer la matrice, il faut au préalable créer les variables nécéssaires à la création des tests. \n",
    "\n",
    "Les règles de gestion peuvent avoir les possibilités suivantes:\n",
    "\n",
    "- `test_pct_intersection` = ['TRUE', 'FALSE']\n",
    "- `status_cas` = ['CAS_1','CAS_3','CAS_4', 'CAS_5']\n",
    "- `test_index_id_duplicate` = ['TRUE', 'FALSE']\n",
    "- `test_list_num_voie` = ['TRUE','PARTIAL', 'NULL', 'FALSE']\n",
    "- `test_siege` = ['TRUE','NULL','FALSE']\n",
    "- `test_enseigne` =  ['TRUE','NULL', 'FALSE']\n",
    "- `test_siren_insee_siren_inpi` = ['TRUE', 'FALSE']\n",
    "- `test_similarite_exception_words` = ['TRUE', 'FALSE', 'NULL']\n",
    "- `test_distance_levhenstein_exception_words` = ['TRUE', 'FALSE', 'NULL']\n",
    "- `test_date` = ['TRUE','NULL','FALSE']\n",
    "- `test_status_admin` = ['TRUE', 'FALSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output = 'SQL_OUTPUT_ATHENA'\n",
    "database = 'ets_siretisation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "DROP TABLE ets_siretisation.rank_matrice_regles_gestion;\n",
    "\"\"\"\n",
    "\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "  filename = None, ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utlisons Pandas pour créer la matrice. Il faut prendre le soin d'intégrer les variables dans l'ordre de préférence. A savoir:\n",
    "\n",
    "1. `test_pct_intersection `\n",
    "2. `status_cas `\n",
    "3. `test_index_id_duplicate `\n",
    "4. `test_list_num_voie `\n",
    "5. `test_siege `\n",
    "6. `test_enseigne `\n",
    "7. `test_siren_insee_siren_inpi `\n",
    "8. `test_similarite_exception_words `\n",
    "9. `test_distance_levhenstein_exception_words `\n",
    "10. `test_date `\n",
    "11. `test_status_admin `\n",
    "\n",
    "Il en va de même pour le contenu des variables. L'ordre est très important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pct_intersection = ['TRUE', 'FALSE']\n",
    "status_cas = ['CAS_1','CAS_3','CAS_4', 'CAS_5']\n",
    "test_index_id_duplicate = ['TRUE', 'FALSE']\n",
    "test_list_num_voie = ['TRUE', 'PARTIAL','NULL', 'FALSE']\n",
    "test_siege = ['TRUE','NULL','FALSE']\n",
    "test_enseigne =  ['TRUE','NULL', 'FALSE']\n",
    "test_siren_insee_siren_inpi = ['TRUE', 'FALSE']\n",
    "test_similarite_exception_words = ['TRUE', 'FALSE', 'NULL']\n",
    "test_distance_levhenstein_exception_words = ['TRUE', 'FALSE', 'NULL']\n",
    "test_date = ['TRUE','NULL','FALSE']\n",
    "test_status_admin = ['TRUE', 'FALSE']\n",
    "\n",
    "index = pd.MultiIndex.from_product([\n",
    "    test_pct_intersection,\n",
    "    status_cas,\n",
    "    test_index_id_duplicate,\n",
    "    test_list_num_voie,\n",
    "    test_siren_insee_siren_inpi,\n",
    "    test_siege,\n",
    "    test_enseigne,\n",
    "    test_similarite_exception_words,\n",
    "    test_distance_levhenstein_exception_words,\n",
    "    test_date,\n",
    "    test_status_admin\n",
    "],\n",
    "                                   names = [\n",
    "                                       'test_pct_intersection',\n",
    "                                       \"status_cas\",\n",
    "                                            'test_index_id_duplicate',\n",
    "                                            \"test_list_num_voie\",\n",
    "                                            \"test_siren_insee_siren_inpi\",\n",
    "                                           'test_siege', \n",
    "                                           'test_enseigne',\n",
    "                                           'test_similarite_exception_words',\n",
    "                                           'test_distance_levhenstein_exception_words',\n",
    "                                           'test_date',\n",
    "                                           'test_status_admin'])\n",
    "\n",
    "df_ = (pd.DataFrame(index = index)\n",
    "       .reset_index()\n",
    "       .assign(rank = lambda x: x.index + 1)\n",
    "       #.to_csv('Regle_tests.csv', index = False)\n",
    "      )\n",
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Il y a environ {} règles de gestion\".format(df_.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le csv se trouve dans le dossier [TEMP_ANALYSE_SIRETISATION/REGLES_TESTS](https://s3.console.aws.amazon.com/s3/buckets/calfdata/TEMP_ANALYSE_SIRETISATION/REGLES_TESTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.to_csv('Regle_tests.csv', index = False)\n",
    "s3.upload_file(file_to_upload = 'Regle_tests.csv',\n",
    "            destination_in_s3 = 'TEMP_ANALYSE_SIRETISATION/REGLES_TESTS')\n",
    "\n",
    "create_table = \"\"\"\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS ets_siretisation.rank_matrice_regles_gestion (\n",
    "`test_pct_intersection`                     string,\n",
    "`status_cas`                     string,\n",
    "`test_index_id_duplicate`                     string,\n",
    "`test_list_num_voie`                     string,\n",
    "`test_siren_insee_siren_inpi`                     string,\n",
    "`test_siege`                     string,\n",
    "`test_enseigne`                     string,\n",
    "`test_similarite_exception_words`                     string,\n",
    "`test_distance_levhenstein_exception_words`                     string,\n",
    "`test_date`                     string,\n",
    "`test_status_admin`                     string,\n",
    "`rank`                     integer\n",
    "\n",
    "    )\n",
    "     ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'\n",
    "    WITH SERDEPROPERTIES (\n",
    "   'separatorChar' = ',',\n",
    "   'quoteChar' = '\"'\n",
    "   )\n",
    "     LOCATION 's3://calfdata/TEMP_ANALYSE_SIRETISATION/REGLES_TESTS'\n",
    "     TBLPROPERTIES ('has_encrypted_data'='false',\n",
    "              'skip.header.line.count'='1');\"\"\"\n",
    "s3.run_query(\n",
    "        query=create_table,\n",
    "        database='ets_siretisation',\n",
    "        s3_output=s3_output\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, shutil, urllib, ipykernel, json\n",
    "from pathlib import Path\n",
    "from notebook import notebookapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_report(extension = \"html\", keep_code = False):\n",
    "    \"\"\"\n",
    "    Create a report from the current notebook and save it in the \n",
    "    Report folder (Parent-> child directory)\n",
    "    \n",
    "    1. Exctract the current notbook name\n",
    "    2. Convert the Notebook \n",
    "    3. Move the newly created report\n",
    "    \n",
    "    Args:\n",
    "    extension: string. Can be \"html\", \"pdf\", \"md\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ### Get notebook name\n",
    "    connection_file = os.path.basename(ipykernel.get_connection_file())\n",
    "    kernel_id = connection_file.split('-', 1)[0].split('.')[0]\n",
    "\n",
    "    for srv in notebookapp.list_running_servers():\n",
    "        try:\n",
    "            if srv['token']=='' and not srv['password']:  \n",
    "                req = urllib.request.urlopen(srv['url']+'api/sessions')\n",
    "            else:\n",
    "                req = urllib.request.urlopen(srv['url']+ \\\n",
    "                                             'api/sessions?token=' + \\\n",
    "                                             srv['token'])\n",
    "            sessions = json.load(req)\n",
    "            notebookname = sessions[0]['name']\n",
    "        except:\n",
    "            pass  \n",
    "    \n",
    "    sep = '.'\n",
    "    path = os.getcwd()\n",
    "    #parent_path = str(Path(path).parent)\n",
    "    \n",
    "    ### Path report\n",
    "    #path_report = \"{}/Reports\".format(parent_path)\n",
    "    #path_report = \"{}/Reports\".format(path)\n",
    "    \n",
    "    ### Path destination\n",
    "    name_no_extension = notebookname.split(sep, 1)[0]\n",
    "    source_to_move = name_no_extension +'.{}'.format(extension)\n",
    "    dest = os.path.join(path,'Reports', source_to_move)\n",
    "    \n",
    "    ### Generate notebook\n",
    "    if keep_code:\n",
    "        os.system('jupyter nbconvert --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    else:\n",
    "        os.system('jupyter nbconvert --no-input --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    \n",
    "    ### Move notebook to report folder\n",
    "    #time.sleep(5)\n",
    "    shutil.move(source_to_move, dest)\n",
    "    print(\"Report Available at this adress:\\n {}\".format(dest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_report(extension = \"html\", keep_code = True)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.24.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
