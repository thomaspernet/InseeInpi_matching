{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import S3 connectors librairies\n",
    "#from awsPy.aws_authorization import aws_connector\n",
    "import importlib.util\n",
    "spec = importlib.util.spec_from_file_location(\"aws_connector.py\", \"C:/Users/Hp/Documents/GitHub/aws-python/awsPy/aws_authorization/aws_connector.py\")\n",
    "aws_connector = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(aws_connector)\n",
    "\n",
    "#from awsPy.aws_s3 import service_s3\n",
    "import importlib.util\n",
    "spec = importlib.util.spec_from_file_location(\"service_s3.py\", \"C:/Users/Hp/Documents/GitHub/aws-python/awsPy/aws_s3/service_s3.py\")\n",
    "service_s3 = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(service_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to S3\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "bucket = 'calfdata'\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent)\n",
    "path_cred = \"{}/programme_matching/credential_AWS.json\".format(parent_path)\n",
    "\n",
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                        region = 'eu-west-3')\n",
    "client= con.client_boto()\n",
    "s3 = service_s3.connect_S3(client = client,\n",
    "                      bucket = 'calfdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List files to send and compute each destination\n",
    "prep_path='data/prep'\n",
    "list_files=[]\n",
    "for root,dirs,files in os.walk(prep_path):\n",
    "    for file in files:\n",
    "          if file.endswith(('.csv','.zip')):\n",
    "                list_files.append((file, u.calc_dest(filename=file)))\n",
    "list_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send files to s3\n",
    "for (file_to_upload,destination_in_s3) in list_files:\n",
    "    # if file exist in S3?\n",
    "    s3.upload_file(file_to_upload, destination_in_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s3.ServiceResource()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client[\"resource\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(file_to_upload,destination_in_s3)=list_files[0]\n",
    "\n",
    "full_path=\"{}/{}\".format(destination_in_s3,file_to_upload)\n",
    "# check file existence in S3\n",
    "client[\"resource\"] # is equivalent to :\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "try:\n",
    "    s3.Object(bucket, 'dootdoot.jpg').load()\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    if e.response['Error']['Code'] == \"404\":\n",
    "        # The object does not exist.\n",
    "        ...\n",
    "    else:\n",
    "        # Something else has gone wrong.\n",
    "        raise\n",
    "else:\n",
    "    # The object does exist.\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A ajouter dans la classe service_s3\n",
    "\n",
    "def list_files_s3(self,path):\n",
    "        \"\"\"\n",
    "        List all csv files found in S3 inside a certain path and saves it to a csv.\n",
    "\n",
    "        args:\n",
    "        path: Any file path from the INPI source where the files should be taken from\n",
    "        #Ex : 'INPI/TC_1/Flux/2018'\n",
    "        #Ex : 'INPI/TC_1/Flux/2018/01'\n",
    "\n",
    "        returns:\n",
    "        Nothing\n",
    "\n",
    "        \"\"\"\n",
    "        import boto3, csv\n",
    "        \n",
    "        # Get existing files : S3 list all keys inside path and write in csv\n",
    "        s3 = boto3.resource('s3')\n",
    "        prefix_ = \"{}/\".format(path)#'INPI/TC_1/Flux/2018/'# syntax 'prefix/'\n",
    "\n",
    "        with open('s3_file_list.csv','w') as newFile:\n",
    "            newFileWriter = csv.writer(newFile)\n",
    "            fnames = ['csv_filename', 's3_path','s3_fullname']\n",
    "            writer = csv.DictWriter(newFile, fieldnames=fnames) \n",
    "            writer.writeheader()\n",
    "\n",
    "            for bucket in s3.buckets.all():\n",
    "                for obj in bucket.objects.filter(Prefix=prefix_):\n",
    "                    filepath = obj.key\n",
    "                    s = re.compile(r'\\/+').split(str(filepath))\n",
    "                    filename = s[len(s)-1]\n",
    "                    split=filepath.split(\"/\")\n",
    "                    s3_path = filepath[0:len(filepath)-len(filename)]\n",
    "\n",
    "                    writer.writerow({'csv_filename': filename,'s3_path' : s3_path,'s3_fullname' : filepath})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
