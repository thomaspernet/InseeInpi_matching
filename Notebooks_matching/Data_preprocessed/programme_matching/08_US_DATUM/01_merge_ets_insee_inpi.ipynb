{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation table merge INSEE INPI filtree \n",
    "\n",
    "Copy paste from Coda to fill the information\n",
    "\n",
    "## Objective(s)\n",
    "\n",
    "  *   Maintenant que la table INSEE et INPI sont prêtes, il faut faire la jointure en vue de créer des règles de différentiations\n",
    "  * Nous savons qu’un établissement peut être rattaché via le sirent et le siret. Pour cela, nous allons merger la table de l’inpi et de l’inpi via le siren, la ville et le code postale. \n",
    "  * Différentes règles supplémentaires sont a prendre en considérations:\n",
    "    * Le join doit etre INNER  → inutile de dédoublonner des siren non matché\n",
    "    * le status IGNORE doit être filtré\n",
    "  * La nouvelle table doit contenir les variables suivantes: \n",
    "    *  index_id, \n",
    "    *     sequence_id, \n",
    "    *     count_initial_insee, \n",
    "    *     ets_inpi_sql.siren, \n",
    "    *     siret, \n",
    "    *     datecreationetablissement, \n",
    "    *     \"date_début_activité\", \n",
    "    *     etatadministratifetablissement, \n",
    "    *     status_admin, \n",
    "    *     etablissementsiege, \n",
    "    *     status_ets, \n",
    "    *     adresse_distance_inpi, \n",
    "    *     adresse_distance_insee, \n",
    "    *     list_numero_voie_matching_inpi, \n",
    "    *     list_numero_voie_matching_insee, \n",
    "    *     typevoieetablissement, \n",
    "    *     type_voie_matching, \n",
    "    *     ets_inpi_sql.code_postal_matching, \n",
    "    *     ets_inpi_sql.ville_matching, \n",
    "    *     codecommuneetablissement, \n",
    "    *     code_commune, \n",
    "    *     enseigne, \n",
    "    *      list_enseigne\n",
    "    *     enseigne1etablissement, \n",
    "    *     enseigne2etablissement, \n",
    "    *     enseigne3etablissement\n",
    "\n",
    "## Metadata \n",
    "\n",
    "* Metadata parameters are available here: \n",
    "* US Title: Creation table merge INSEE INPI filtree \n",
    "* Epic: Epic 5\n",
    "* US: US 7\n",
    "* Date Begin: 8/31/2020\n",
    "* Duration Task: 1\n",
    "* Status:  \n",
    "* Source URL:[US 07 Preparation siretisation](https://coda.io/d/_dCtnoqIftTn/US-07-Preparation-siretisation_suFb9)\n",
    "* Task type:\n",
    "  * Jupyter Notebook\n",
    "* Users: :\n",
    "  * Thomas Pernet\n",
    "* Watchers:\n",
    "  * Thomas Pernet\n",
    "* Estimated Log points:\n",
    "  * One being a simple task, 15 a very difficult one\n",
    "  *  5\n",
    "* Task tag\n",
    "  *  #sql-query,#matching,#siretisation,#inpi  ,#insee\n",
    "* Toggl Tag\n",
    "  * #data-preparation\n",
    "  \n",
    "## Input Cloud Storage [AWS]\n",
    "\n",
    "If link from the internet, save it to the cloud first\n",
    "\n",
    "### Tables [AWS]\n",
    "\n",
    "1. Batch 1:\n",
    "  * Select Provider: Athena\n",
    "  * Select table(s): ets_insee_sql ,ets_inpi_sql\n",
    "    * Select only tables created from the same notebook, else copy/paste selection to add new input tables\n",
    "    * If table(s) does not exist, add them: Add New Table\n",
    "    * Information:\n",
    "      * Region: \n",
    "        * NameEurope (Paris)\n",
    "        * Code: eu-west-3\n",
    "      * Database: inpi\n",
    "      * Notebook construction file: \n",
    "        * https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/01_preparation/03_ETS_add_variables.md\n",
    "        * [05_nettoyage_enseigne_inpi](https://github.com/thomaspernet/InseeInpi_matching/blob/master/01_Data_preprocessing/Data_preprocessed/programme_matching/01_preparation/05_nettoyage_enseigne_inpi.md)\n",
    "\n",
    "## Destination Output/Delivery\n",
    "\n",
    "  * AWS\n",
    "    1. Athena: \n",
    "      * Region: Europe (Paris)\n",
    "      * Database: siretisation\n",
    "      * Tables (Add name new table): ets_insee_inpi \n",
    "      * List new tables\n",
    "      *  ets_insee_inpi \n",
    "\n",
    "## Things to know (Steps, Attention points or new flow of information)\n",
    "\n",
    "### Sources of information  (meeting notes, Documentation, Query, URL)\n",
    "\n",
    "1. Jupyter Notebook (Github Link)\n",
    "  1. md : https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/02_siretisation/06_analyse_pre_siretisation_v3.md#full-pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connexion serveur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awsPy.aws_authorization import aws_connector\n",
    "from awsPy.aws_athena import service_athena\n",
    "from awsPy.aws_s3 import service_s3\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os, shutil\n",
    "\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent)\n",
    "path_cred = r\"{}/credential_AWS.json\".format(parent_path)\n",
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = 'eu-west-3')\n",
    "\n",
    "region = 'eu-west-3'\n",
    "bucket = 'calfdata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = region)\n",
    "client= con.client_boto()\n",
    "s3 = service_s3.connect_S3(client = client,\n",
    "                      bucket = bucket, verbose = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_setting = True\n",
    "if pandas_setting:\n",
    "    cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation tables\n",
    "\n",
    "## Steps\n",
    "\n",
    "- Merger la table `` avec `` \n",
    "    - utiliser `inner join`\n",
    "- Filtrer lorsque statut est différent de 'IGNORE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output = 'inpi/sql_output'\n",
    "database = 'inpi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "DROP TABLE `ets_insee_inpi`;\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "  filename = None, ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "CREATE TABLE siretisation.ets_insee_inpi \n",
    "WITH (\n",
    "  format='PARQUET'\n",
    ") AS\n",
    " SELECT \n",
    "    index_id, \n",
    "    sequence_id, \n",
    "    count_initial_insee, \n",
    "    ets_inpi_sql.siren, \n",
    "    siret, \n",
    "    datecreationetablissement, \n",
    "    \"date_début_activité\", \n",
    "    etatadministratifetablissement, \n",
    "    status_admin, \n",
    "    etablissementsiege, \n",
    "    status_ets, \n",
    "    adresse_distance_inpi, \n",
    "    adresse_distance_insee, \n",
    "    list_numero_voie_matching_inpi, \n",
    "    list_numero_voie_matching_insee, \n",
    "    typevoieetablissement, \n",
    "    type_voie_matching, \n",
    "    ets_inpi_sql.code_postal_matching, \n",
    "    ets_inpi_sql.ville_matching, \n",
    "    codecommuneetablissement, \n",
    "    code_commune, \n",
    "    enseigne, \n",
    "    list_enseigne,\n",
    "    enseigne1etablissement, \n",
    "    enseigne2etablissement, \n",
    "    enseigne3etablissement \n",
    "  FROM \n",
    "    siretisation.ets_inpi_sql \n",
    "    INNER JOIN (\n",
    "      SELECT \n",
    "        count_initial_insee, \n",
    "        siren, \n",
    "        siret, \n",
    "        datecreationetablissement, \n",
    "        etablissementsiege, \n",
    "        etatadministratifetablissement, \n",
    "        codepostaletablissement, \n",
    "        codecommuneetablissement, \n",
    "        ville_matching, \n",
    "        list_numero_voie_matching_insee, \n",
    "        numerovoieetablissement, \n",
    "        typevoieetablissement, \n",
    "        adresse_reconstituee_insee, \n",
    "        adresse_distance_insee, \n",
    "        list_enseigne,\n",
    "        enseigne1etablissement, \n",
    "        enseigne2etablissement,\n",
    "        enseigne3etablissement \n",
    "      FROM \n",
    "        siretisation.ets_insee_sql\n",
    "    ) as insee ON ets_inpi_sql.siren = insee.siren \n",
    "    AND ets_inpi_sql.ville_matching = insee.ville_matching \n",
    "    AND ets_inpi_sql.code_postal_matching = insee.codepostaletablissement \n",
    "  WHERE \n",
    "    status != 'IGNORE'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "  filename = None, ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation\n",
    "\n",
    "1. Imprimer 10 lignes aléatoirement\n",
    "2. Compter le nombre d'observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM siretisation.ets_insee_inpi\n",
    "limit 10\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database='siretisation',\n",
    "            s3_output=s3_output,\n",
    "  filename = 'exemple_siretisation', ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT COUNT(*)\n",
    "FROM siretisation.ets_insee_inpi\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database='siretisation',\n",
    "            s3_output=s3_output,\n",
    "  filename = 'count_siretisation', ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, shutil, urllib, ipykernel, json\n",
    "from pathlib import Path\n",
    "from notebook import notebookapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_report(extension = \"html\", keep_code = False):\n",
    "    \"\"\"\n",
    "    Create a report from the current notebook and save it in the \n",
    "    Report folder (Parent-> child directory)\n",
    "    \n",
    "    1. Exctract the current notbook name\n",
    "    2. Convert the Notebook \n",
    "    3. Move the newly created report\n",
    "    \n",
    "    Args:\n",
    "    extension: string. Can be \"html\", \"pdf\", \"md\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ### Get notebook name\n",
    "    connection_file = os.path.basename(ipykernel.get_connection_file())\n",
    "    kernel_id = connection_file.split('-', 1)[0].split('.')[0]\n",
    "\n",
    "    for srv in notebookapp.list_running_servers():\n",
    "        try:\n",
    "            if srv['token']=='' and not srv['password']:  \n",
    "                req = urllib.request.urlopen(srv['url']+'api/sessions')\n",
    "            else:\n",
    "                req = urllib.request.urlopen(srv['url']+ \\\n",
    "                                             'api/sessions?token=' + \\\n",
    "                                             srv['token'])\n",
    "            sessions = json.load(req)\n",
    "            notebookname = sessions[0]['name']\n",
    "        except:\n",
    "            pass  \n",
    "    \n",
    "    sep = '.'\n",
    "    path = os.getcwd()\n",
    "    #parent_path = str(Path(path).parent)\n",
    "    \n",
    "    ### Path report\n",
    "    #path_report = \"{}/Reports\".format(parent_path)\n",
    "    #path_report = \"{}/Reports\".format(path)\n",
    "    \n",
    "    ### Path destination\n",
    "    name_no_extension = notebookname.split(sep, 1)[0]\n",
    "    source_to_move = name_no_extension +'.{}'.format(extension)\n",
    "    dest = os.path.join(path,'Reports', source_to_move)\n",
    "    \n",
    "    ### Generate notebook\n",
    "    if keep_code:\n",
    "        os.system('jupyter nbconvert --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    else:\n",
    "        os.system('jupyter nbconvert --no-input --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    \n",
    "    ### Move notebook to report folder\n",
    "    #time.sleep(5)\n",
    "    shutil.move(source_to_move, dest)\n",
    "    print(\"Report Available at this adress:\\n {}\".format(dest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_report(extension = \"html\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.24.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
