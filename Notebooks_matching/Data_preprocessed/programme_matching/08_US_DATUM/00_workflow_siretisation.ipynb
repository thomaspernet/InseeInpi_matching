{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation notebook presentation processus siretisation \n",
    "\n",
    "Copy paste from Coda to fill the information\n",
    "\n",
    "## Objective(s)\n",
    "\n",
    "- Créer un notebook qui récapitule le workflow de la siretisation via l’ensemble des notebooks créé dans les US\n",
    "\n",
    "## Metadata \n",
    "\n",
    "* Metadata parameters are available here: \n",
    "* US Title: Creation notebook presentation processus siretisation\n",
    "* Epic: Epic 5\n",
    "* US: US 7\n",
    "* Date Begin: 8/31/2020\n",
    "* Duration Task: 0\n",
    "* Status: Active\n",
    "* Source URL:US 07 Preparation siretisation\n",
    "* Task type:\n",
    "  * Jupyter Notebook\n",
    "* Users: :\n",
    "  * Thomas Pernet\n",
    "* Watchers:\n",
    "  * Thomas Pernet\n",
    "* Estimated Log points:\n",
    "  * One being a simple task, 15 a very difficult one\n",
    "  *  7\n",
    "* Task tag\n",
    "  *  #sql-query,#regle-de-gestion,#presentation\n",
    "* Toggl Tag\n",
    "  * #documentation\n",
    "  \n",
    "## Input Cloud Storage [AWS]\n",
    "\n",
    "If link from the internet, save it to the cloud first\n",
    "\n",
    "### Tables [AWS]\n",
    "\n",
    "1. Batch 1:\n",
    "  * Select Provider: Athena\n",
    "  * Select table(s): ets_insee_inpi\n",
    "    * Select only tables created from the same notebook, else copy/paste selection to add new input tables\n",
    "    * If table(s) does not exist, add them: Add New Table\n",
    "    * Information:\n",
    "      * Region: \n",
    "        * NameEurope (Paris)\n",
    "        * Code: eu-west-3\n",
    "      * Database: inpi\n",
    "      * Notebook construction file: \n",
    "        *  https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/01_preparation/03_ETS_add_variables.md \n",
    "    \n",
    "## Destination Output/Delivery\n",
    "\n",
    "* AWS\n",
    "  1. Athena: \n",
    "      * Region: \n",
    "      * Database: \n",
    "      * Tables (Add name new table): \n",
    "\n",
    "## Things to know (Steps, Attention points or new flow of information)\n",
    "\n",
    "### Sources of information  (meeting notes, Documentation, Query, URL)\n",
    "\n",
    "\n",
    "1. Jupyter Notebook (Github Link)\n",
    "  1. md : Notebooks_matching/Data_preprocessed/programme_matching/02_siretisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connexion serveur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awsPy.aws_authorization import aws_connector\n",
    "from awsPy.aws_s3 import service_s3\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os, shutil\n",
    "\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent)\n",
    "path_cred = r\"{}/credential_AWS.json\".format(parent_path)\n",
    "region = 'eu-west-3'\n",
    "bucket = 'calfdata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = region)\n",
    "client= con.client_boto()\n",
    "s3 = service_s3.connect_S3(client = client,\n",
    "                      bucket = bucket, verbose = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_setting = True\n",
    "if pandas_setting:\n",
    "    cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output = 'INPI/sql_output'\n",
    "database = 'inpi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation tables\n",
    "\n",
    "## Steps "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merger INPI - INSEE\n",
    "\n",
    "Nous allons merger la table de l'INSEE avec la table de l'INPI. \n",
    "\n",
    "Le nombre de lignes et d'index est indiqué ci dessous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre de lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =  \"\"\"\n",
    "SELECT COUNT(*) nb_lignes\n",
    "FROM ets_insee_inpi\n",
    "\"\"\"\n",
    "\n",
    "s3.run_query(\n",
    "        query=query,\n",
    "        database='inpi',\n",
    "        s3_output=s3_output, \n",
    "        filename = 'count_ets_inpi_insee'\n",
    "    \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre de index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =  \"\"\"\n",
    "SELECT COUNT(distinct(index_id)) as nb_index\n",
    "FROM ets_insee_inpi\n",
    "\"\"\"\n",
    "\n",
    "s3.run_query(\n",
    "        query=query,\n",
    "        database='inpi',\n",
    "        s3_output=s3_output, \n",
    "        filename = 'count_ets_inpi_insee'\n",
    "    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =  \"\"\"\n",
    "SELECT *\n",
    "FROM ets_insee_inpi\n",
    "limit 5\n",
    "\"\"\"\n",
    "\n",
    "s3.run_query(\n",
    "        query=query,\n",
    "        database='inpi',\n",
    "        s3_output=s3_output, \n",
    "        filename = 'count_ets_inpi_insee'\n",
    "    \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarité entre deux adresses\n",
    "\n",
    "Le rapprochement entre les deux tables, à savoir l’INSEE et l’INPI, va amener à la création de deux vecteurs d’adresse. Un vecteur avec des mots contenus spécifiquement à l’INSEE, et un second vecteur avec les mots de l’adresse de l’INPI. Notre objectif est de comparé ses deux vecteurs pour définir si ils sont identiques ou non. Nous avons distingué 7 cas de figures possibles entre les deux vecteurs (figure 1).\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1Qj_HooHrhFYSuTsoqFbl4Vxy9tN3V5Bu)\n",
    "\n",
    "### Creation table cas règle\n",
    "\n",
    "Il faut créer les tests suivants:\n",
    "\n",
    "- test_pct_intersection = ['TRUE', 'FALSE']:\n",
    "    - Si le pourcentage intersection/union de la ligne est égal au maximum du pourcentage intersection / union par index alors TRUE\n",
    "- status_cas = ['CAS_1','CAS_3','CAS_4', 'CAS_5','CAS_7', 'CAS_6']:\n",
    "    - Informe du statut de l'adresse de la ligne \n",
    "- index_id_duplicate = ['TRUE', 'FALSE']:\n",
    "    - informe si l'index a plusieurs siret possibles\n",
    "- test_list_num_voie = ['TRUE', 'NULL', 'FALSE']:\n",
    "    - informe si les numéros distincts de la voie sont identiques a l'INPI et a l'INSEE\n",
    "- test_siege = ['TRUE','NULL','FALSE']:\n",
    "    - informe si la ligne est un siege ou non\n",
    "- test_enseigne =  ['TRUE','NULL', 'FALSE']:\n",
    "    - informe si l'enseigne est identique\n",
    "- test_siren_insee_siren_inpi = ['TRUE', 'FALSE']:\n",
    "    - informe si le nombre de siret par siren est identique à l'insee et inpi\n",
    "- test_distance_cosine = ['TRUE', 'FALSE', 'NULL']:\n",
    "    - informe si la distance maximale (word2vec) entre les mots \"exceptions\" insee/inpi est supérieure à 0.6\n",
    "- test_distance_levhenstein = ['TRUE', 'FALSE', 'NULL']:\n",
    "    - informe si l'edit entre les deux mots les plus proches trouvée via la distance word2vec  est inférieure ou égale à 1\n",
    "- test_date = ['TRUE','NULL','FALSE']:\n",
    "    - informe si la date de création de l'établissement est égale à la date de début d'activité\n",
    "- test_status_admin = ['TRUE', 'FALSE']:\n",
    "    - informe si le status administratif est identique à l'INSEE et à l'INPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_table = False\n",
    "if drop_table:\n",
    "    output = s3.run_query(\n",
    "        query=\"DROP TABLE `ets_inpi_insee_cases`;\",\n",
    "        database='inpi',\n",
    "        s3_output=s3_output\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table = \"\"\"\n",
    "\n",
    "CREATE TABLE inpi.ets_inpi_insee_cases WITH (format = 'PARQUET') AS \n",
    "WITH test_proba AS (\n",
    "  SELECT \n",
    "    count_initial_insee, \n",
    "    index_id, \n",
    "    sequence_id, \n",
    "    siren, \n",
    "    siret, \n",
    "    Coalesce(\n",
    "      try(\n",
    "        date_parse(\n",
    "          datecreationetablissement, '%Y-%m-%d'\n",
    "        )\n",
    "      ), \n",
    "      try(\n",
    "        date_parse(\n",
    "          datecreationetablissement, '%Y-%m-%d %hh:%mm:%ss.SSS'\n",
    "        )\n",
    "      ), \n",
    "      try(\n",
    "        date_parse(\n",
    "          datecreationetablissement, '%Y-%m-%d %hh:%mm:%ss'\n",
    "        )\n",
    "      ), \n",
    "      try(\n",
    "        cast(\n",
    "          datecreationetablissement as timestamp\n",
    "        )\n",
    "      )\n",
    "    ) as datecreationetablissement, \n",
    "    Coalesce(\n",
    "      try(\n",
    "        date_parse(\n",
    "          \"date_début_activité\", '%Y-%m-%d'\n",
    "        )\n",
    "      ), \n",
    "      try(\n",
    "        date_parse(\n",
    "          \"date_début_activité\", '%Y-%m-%d %hh:%mm:%ss.SSS'\n",
    "        )\n",
    "      ), \n",
    "      try(\n",
    "        date_parse(\n",
    "          \"date_début_activité\", '%Y-%m-%d %hh:%mm:%ss'\n",
    "        )\n",
    "      ), \n",
    "      try(\n",
    "        cast(\n",
    "          \"date_début_activité\" as timestamp\n",
    "        )\n",
    "      )\n",
    "    ) as date_debut_activite, \n",
    "    etatadministratifetablissement, \n",
    "    status_admin, \n",
    "    etablissementsiege, \n",
    "    status_ets, \n",
    "    codecommuneetablissement, \n",
    "    code_commune, \n",
    "    codepostaletablissement, \n",
    "    code_postal_matching, \n",
    "    numerovoieetablissement, \n",
    "    numero_voie_matching, \n",
    "    typevoieetablissement, \n",
    "    type_voie_matching, \n",
    "    adresse_distance_inpi, \n",
    "    adresse_distance_insee, \n",
    "    list_numero_voie_matching_inpi, \n",
    "    list_numero_voie_matching_insee, \n",
    "    array_distinct(\n",
    "      split(adresse_distance_inpi, ' ')\n",
    "    ) as list_inpi, \n",
    "    cardinality(\n",
    "      array_distinct(\n",
    "        split(adresse_distance_inpi, ' ')\n",
    "      )\n",
    "    ) as lenght_list_inpi, \n",
    "    array_distinct(\n",
    "      split(adresse_distance_insee, ' ')\n",
    "    ) as list_insee, \n",
    "    cardinality(\n",
    "      array_distinct(\n",
    "        split(adresse_distance_insee, ' ')\n",
    "      )\n",
    "    ) as lenght_list_insee, \n",
    "    array_distinct(\n",
    "      array_except(\n",
    "        split(adresse_distance_insee, ' '), \n",
    "        split(adresse_distance_inpi, ' ')\n",
    "      )\n",
    "    ) as insee_except, \n",
    "    array_distinct(\n",
    "      array_except(\n",
    "        split(adresse_distance_inpi, ' '), \n",
    "        split(adresse_distance_insee, ' ')\n",
    "      )\n",
    "    ) as inpi_except, \n",
    "    CAST(\n",
    "      cardinality(\n",
    "        array_distinct(\n",
    "          array_intersect(\n",
    "            split(adresse_distance_inpi, ' '), \n",
    "            split(adresse_distance_insee, ' ')\n",
    "          )\n",
    "        )\n",
    "      ) AS DECIMAL(10, 2)\n",
    "    ) as intersection, \n",
    "    CAST(\n",
    "      cardinality(\n",
    "        array_distinct(\n",
    "          array_union(\n",
    "            split(adresse_distance_inpi, ' '), \n",
    "            split(adresse_distance_insee, ' ')\n",
    "          )\n",
    "        )\n",
    "      ) AS DECIMAL(10, 2)\n",
    "    ) as union_, \n",
    "    CAST(\n",
    "      cardinality(\n",
    "        array_distinct(\n",
    "          array_intersect(\n",
    "            list_numero_voie_matching_inpi, \n",
    "            list_numero_voie_matching_insee\n",
    "          )\n",
    "        )\n",
    "      ) AS DECIMAL(10, 2)\n",
    "    ) as intersection_numero_voie, \n",
    "    CAST(\n",
    "      cardinality(\n",
    "        array_distinct(\n",
    "          array_union(\n",
    "            list_numero_voie_matching_inpi, \n",
    "            list_numero_voie_matching_insee\n",
    "          )\n",
    "        )\n",
    "      ) AS DECIMAL(10, 2)\n",
    "    ) as union_numero_voie, \n",
    "    REGEXP_REPLACE(\n",
    "      NORMALIZE(enseigne, NFD), \n",
    "      '\\pM', \n",
    "      ''\n",
    "    ) AS enseigne, \n",
    "    enseigne1etablissement, \n",
    "    enseigne2etablissement, \n",
    "    enseigne3etablissement, \n",
    "    array_remove(\n",
    "      array_distinct(\n",
    "        SPLIT(\n",
    "          concat(\n",
    "            enseigne1etablissement, ',', enseigne2etablissement, \n",
    "            ',', enseigne3etablissement\n",
    "          ), \n",
    "          ','\n",
    "        )\n",
    "      ), \n",
    "      ''\n",
    "    ) as test, \n",
    "    contains(\n",
    "      array_remove(\n",
    "        array_distinct(\n",
    "          SPLIT(\n",
    "            concat(\n",
    "              enseigne1etablissement, ',', enseigne2etablissement, \n",
    "              ',', enseigne3etablissement\n",
    "            ), \n",
    "            ','\n",
    "          )\n",
    "        ), \n",
    "        ''\n",
    "      ), \n",
    "      REGEXP_REPLACE(\n",
    "        NORMALIZE(enseigne, NFD), \n",
    "        '\\pM', \n",
    "        ''\n",
    "      )\n",
    "    ) AS temp_test_enseigne \n",
    "  FROM \n",
    "    \"inpi\".\"ets_insee_inpi\" -- limit 10\n",
    "    ) \n",
    "SELECT \n",
    "  * \n",
    "FROM \n",
    "  (\n",
    "    WITH test_rules AS (\n",
    "      SELECT \n",
    "        ROW_NUMBER() OVER () AS row_id, \n",
    "        count_initial_insee, \n",
    "        index_id, \n",
    "        sequence_id, \n",
    "        siren, \n",
    "        siret, \n",
    "        CASE WHEN cardinality(list_numero_voie_matching_inpi) = 0 THEN NULL ELSE list_numero_voie_matching_inpi END as list_numero_voie_matching_inpi, \n",
    "        CASE WHEN cardinality(\n",
    "          list_numero_voie_matching_insee\n",
    "        ) = 0 THEN NULL ELSE list_numero_voie_matching_insee END as list_numero_voie_matching_insee, \n",
    "        intersection_numero_voie, \n",
    "        union_numero_voie, \n",
    "        CASE WHEN intersection_numero_voie = union_numero_voie \n",
    "        AND (\n",
    "          intersection_numero_voie IS NOT NULL \n",
    "          OR union_numero_voie IS NOT NULL\n",
    "        ) THEN 'TRUE' WHEN (\n",
    "          intersection_numero_voie IS NULL \n",
    "          OR union_numero_voie IS NULL\n",
    "        ) THEN 'NULL' ELSE 'FALSE' END AS test_list_num_voie, \n",
    "        datecreationetablissement, \n",
    "        date_debut_activite, \n",
    "        CASE WHEN datecreationetablissement = date_debut_activite THEN 'TRUE' WHEN datecreationetablissement IS NULL \n",
    "        OR date_debut_activite IS NULL THEN 'NULL' --WHEN datecreationetablissement = '' \n",
    "        ELSE 'FALSE' END AS test_date, \n",
    "        etatadministratifetablissement, \n",
    "        status_admin, \n",
    "        CASE WHEN etatadministratifetablissement = status_admin THEN 'TRUE' WHEN etatadministratifetablissement IS NULL \n",
    "        OR status_admin IS NULL THEN 'NULL' WHEN etatadministratifetablissement = '' \n",
    "        OR status_admin = '' THEN 'NULL' ELSE 'FALSE' END AS test_status_admin, \n",
    "        etablissementsiege, \n",
    "        status_ets, \n",
    "        CASE WHEN etablissementsiege = status_ets THEN 'TRUE' WHEN etablissementsiege IS NULL \n",
    "        OR status_ets IS NULL THEN 'NULL' WHEN etablissementsiege = '' \n",
    "        OR status_ets = '' THEN 'NULL' ELSE 'FALSE' END AS test_siege, \n",
    "        codecommuneetablissement, \n",
    "        code_commune, \n",
    "        CASE WHEN codecommuneetablissement = code_commune THEN 'TRUE' WHEN codecommuneetablissement IS NULL \n",
    "        OR code_commune IS NULL THEN 'NULL' WHEN codecommuneetablissement = '' \n",
    "        OR code_commune = '' THEN 'NULL' ELSE 'FALSE' END AS test_code_commune, \n",
    "        codepostaletablissement, \n",
    "        code_postal_matching, \n",
    "        numerovoieetablissement, \n",
    "        numero_voie_matching, \n",
    "        CASE WHEN numerovoieetablissement = numero_voie_matching THEN 'TRUE' WHEN numerovoieetablissement IS NULL \n",
    "        OR numero_voie_matching IS NULL THEN 'NULL' WHEN numerovoieetablissement = '' \n",
    "        OR numero_voie_matching = '' THEN 'NULL' ELSE 'FALSE' END AS test_numero_voie, \n",
    "        typevoieetablissement, \n",
    "        type_voie_matching, \n",
    "        CASE WHEN typevoieetablissement = type_voie_matching THEN 'TRUE' WHEN typevoieetablissement IS NULL \n",
    "        OR type_voie_matching IS NULL THEN 'NULL' WHEN typevoieetablissement = '' \n",
    "        OR type_voie_matching = '' THEN 'NULL' ELSE 'FALSE' END AS test_type_voie, \n",
    "        CASE WHEN cardinality(list_inpi) = 0 THEN NULL ELSE list_inpi END as list_inpi, \n",
    "        lenght_list_inpi, \n",
    "        CASE WHEN cardinality(list_insee) = 0 THEN NULL ELSE list_insee END as list_insee, \n",
    "        lenght_list_insee, \n",
    "        CASE WHEN cardinality(inpi_except) = 0 THEN NULL ELSE inpi_except END as inpi_except, \n",
    "        CASE WHEN cardinality(insee_except) = 0 THEN NULL ELSE insee_except END as insee_except, \n",
    "        intersection, \n",
    "        union_, \n",
    "        intersection / union_ as pct_intersection, \n",
    "        cardinality(inpi_except) AS len_inpi_except, \n",
    "        cardinality(insee_except) AS len_insee_except, \n",
    "        CASE WHEN intersection = union_ THEN 'CAS_1' WHEN intersection = 0 THEN 'CAS_2' WHEN lenght_list_inpi = intersection \n",
    "        AND intersection != union_ THEN 'CAS_3' WHEN lenght_list_insee = intersection \n",
    "        AND intersection != union_ THEN 'CAS_4' WHEN cardinality(insee_except) = cardinality(inpi_except) \n",
    "        AND intersection != 0 \n",
    "        AND cardinality(insee_except) > 0 THEN 'CAS_5' WHEN cardinality(insee_except) > cardinality(inpi_except) \n",
    "        AND intersection != 0 \n",
    "        AND cardinality(insee_except) > 0 \n",
    "        AND cardinality(inpi_except) > 0 THEN 'CAS_6' WHEN cardinality(insee_except) < cardinality(inpi_except) \n",
    "        AND intersection != 0 \n",
    "        AND cardinality(insee_except) > 0 \n",
    "        AND cardinality(inpi_except) > 0 THEN 'CAS_7' ELSE 'CAS_NO_ADRESSE' END AS status_cas, \n",
    "        enseigne, \n",
    "        enseigne1etablissement, \n",
    "        enseigne2etablissement, \n",
    "        enseigne3etablissement, \n",
    "        CASE WHEN cardinality(test) = 0 THEN 'NULL' WHEN enseigne = '' THEN 'NULL' WHEN temp_test_enseigne = TRUE THEN 'TRUE' ELSE 'FALSE' END AS test_enseigne \n",
    "      FROM \n",
    "        test_proba\n",
    "      \n",
    "    ) \n",
    "    \n",
    "    SELECT *\n",
    "    FROM (\n",
    "      WITH test AS(\n",
    "        SELECT *,\n",
    "        CASE WHEN status_cas = 'CAS_1' OR\n",
    "        status_cas = 'CAS_3' OR \n",
    "        status_cas = 'CAS_4' THEN 'TRUE' ELSE 'FALSE' END AS test_adresse_cas_1_3_4 \n",
    "        FROM test_rules\n",
    "        WHERE test_list_num_voie != 'FALSE' and status_cas != 'CAS_2'\n",
    "        )\n",
    "    \n",
    "    SELECT \n",
    "      --rank,\n",
    "      row_id, \n",
    "      test.index_id, \n",
    "      test.sequence_id, \n",
    "      test.siren, \n",
    "      test.siret,\n",
    "      \n",
    "      count_initial_insee, \n",
    "      count_inpi_siren_siret, \n",
    "      count_inpi_siren_sequence, \n",
    "      count_inpi_sequence_siret, \n",
    "      count_inpi_sequence_stat_cas_siret,\n",
    "      count_inpi_index_id_siret,\n",
    "      count_inpi_index_id_stat_cas_siret,\n",
    "      count_inpi_index_id_stat_cas,\n",
    "      CASE WHEN count_inpi_index_id_siret > 1 THEN 'TRUE' ELSE 'FALSE' END AS index_id_duplicate,\n",
    "      CASE WHEN count_inpi_sequence_siret = 1 THEN 'TRUE' ELSE 'FALSE' END AS test_sequence_siret,\n",
    "      CASE WHEN count_inpi_index_id_stat_cas_siret = 1 THEN 'TRUE' ELSE 'FALSE' END AS test_index_siret,\n",
    "      CASE WHEN count_initial_insee = count_inpi_siren_siret THEN 'TRUE' ELSE 'FALSE' END AS test_siren_insee_siren_inpi, \n",
    "    \n",
    "      CASE WHEN count_inpi_sequence_siret = count_inpi_sequence_stat_cas_siret THEN 'TRUE' ELSE 'FALSE' END AS test_sequence_siret_many_cas,\n",
    "    \n",
    "      list_numero_voie_matching_inpi, \n",
    "      list_numero_voie_matching_insee, \n",
    "      intersection_numero_voie, \n",
    "      union_numero_voie, \n",
    "      test.test_list_num_voie, \n",
    "      datecreationetablissement, \n",
    "      date_debut_activite, \n",
    "      test_date, \n",
    "      etatadministratifetablissement, \n",
    "      status_admin, \n",
    "      test_status_admin, \n",
    "      etablissementsiege, \n",
    "      status_ets, \n",
    "      test.test_siege, \n",
    "      codecommuneetablissement, \n",
    "      code_commune, \n",
    "      test_code_commune, \n",
    "      codepostaletablissement, \n",
    "      code_postal_matching, \n",
    "      numerovoieetablissement, \n",
    "      numero_voie_matching, \n",
    "      test_numero_voie, \n",
    "      typevoieetablissement, \n",
    "      type_voie_matching, \n",
    "      test_type_voie, \n",
    "      list_inpi, \n",
    "      lenght_list_inpi, \n",
    "      list_insee, \n",
    "      lenght_list_insee, \n",
    "      inpi_except, \n",
    "      insee_except, \n",
    "      intersection, \n",
    "      union_, \n",
    "      pct_intersection, \n",
    "      index_id_max_intersection,\n",
    "      CASE WHEN pct_intersection = index_id_max_intersection THEN 'TRUE' ELSE 'FALSE' END AS test_pct_intersection,\n",
    "      len_inpi_except, \n",
    "      len_insee_except, \n",
    "      test.status_cas, \n",
    "      test_adresse_cas_1_3_4,\n",
    "      index_id_dup_has_cas_1_3_4,\n",
    "      CASE\n",
    "      WHEN test_adresse_cas_1_3_4 = 'TRUE' AND index_id_dup_has_cas_1_3_4 = 'TRUE' AND count_inpi_index_id_siret > 1 THEN 'TO_KEEP' \n",
    "      WHEN test_adresse_cas_1_3_4 = 'FALSE' AND index_id_dup_has_cas_1_3_4 = 'TRUE' AND count_inpi_index_id_siret > 1 THEN 'TO_REMOVE'\n",
    "      WHEN count_inpi_index_id_siret = 1 THEN 'NULL'\n",
    "      ELSE 'TO_FIND' END AS test_duplicates_is_in_cas_1_3_4,\n",
    "      enseigne, \n",
    "      enseigne1etablissement, \n",
    "      enseigne2etablissement, \n",
    "      enseigne3etablissement, \n",
    "      test.test_enseigne \n",
    "    FROM \n",
    "      test \n",
    "      LEFT JOIN (\n",
    "        SELECT \n",
    "          siren, \n",
    "          COUNT(\n",
    "            DISTINCT(siret)\n",
    "          ) AS count_inpi_siren_siret \n",
    "        FROM \n",
    "          test \n",
    "        GROUP BY \n",
    "          siren\n",
    "      ) AS count_rows_sequence ON test.siren = count_rows_sequence.siren \n",
    "      LEFT JOIN (\n",
    "        SELECT \n",
    "          siren, \n",
    "          COUNT(\n",
    "            DISTINCT(sequence_id)\n",
    "          ) AS count_inpi_siren_sequence \n",
    "        FROM \n",
    "          test \n",
    "        GROUP BY \n",
    "          siren\n",
    "      ) AS count_rows_siren_sequence ON test.siren = count_rows_siren_sequence.siren \n",
    "      LEFT JOIN (\n",
    "        SELECT \n",
    "          sequence_id, \n",
    "          COUNT(\n",
    "            DISTINCT(siret)\n",
    "          ) AS count_inpi_sequence_siret \n",
    "        FROM \n",
    "          test \n",
    "        GROUP BY \n",
    "          sequence_id\n",
    "      ) AS count_rows_siret ON test.sequence_id = count_rows_siret.sequence_id\n",
    "    -- \n",
    "    LEFT JOIN (\n",
    "        SELECT \n",
    "          sequence_id, \n",
    "          status_cas,\n",
    "          COUNT(\n",
    "            DISTINCT(siret)\n",
    "          ) AS count_inpi_sequence_stat_cas_siret \n",
    "        FROM \n",
    "          test \n",
    "        GROUP BY \n",
    "          sequence_id,\n",
    "      status_cas\n",
    "      ) AS count_rows_status_cas_siret ON test.sequence_id = count_rows_status_cas_siret.sequence_id AND\n",
    "    test.status_cas = count_rows_status_cas_siret.status_cas\n",
    "    -- duplicate index\n",
    "    LEFT JOIN (\n",
    "        SELECT \n",
    "          index_id, \n",
    "          COUNT(\n",
    "            DISTINCT(siret)\n",
    "          ) AS count_inpi_index_id_siret \n",
    "        FROM \n",
    "          test \n",
    "        GROUP BY \n",
    "          index_id\n",
    "      ) AS count_rows_index_id_siret ON test.index_id = count_rows_index_id_siret.index_id\n",
    "    -- duplicate index cas\n",
    "    LEFT JOIN (\n",
    "        SELECT \n",
    "          index_id, \n",
    "          status_cas,\n",
    "          COUNT(\n",
    "            DISTINCT(siret)\n",
    "          ) AS count_inpi_index_id_stat_cas_siret \n",
    "        FROM \n",
    "          test_rules \n",
    "        GROUP BY \n",
    "          index_id,\n",
    "          status_cas\n",
    "      ) AS count_rows_index_status_cas_siret ON test.index_id = count_rows_index_status_cas_siret.index_id AND\n",
    "    test.status_cas = count_rows_index_status_cas_siret.status_cas\n",
    "    -- nb de cas par index\n",
    "    LEFT JOIN (\n",
    "        SELECT \n",
    "          index_id, \n",
    "          COUNT(\n",
    "            DISTINCT(status_cas)\n",
    "          ) AS count_inpi_index_id_stat_cas\n",
    "        FROM \n",
    "           test \n",
    "        GROUP BY \n",
    "          index_id\n",
    "      ) AS count_rows_index_status_cas ON test.index_id = count_rows_index_status_cas.index_id\n",
    "   LEFT JOIN (\n",
    "     SELECT \n",
    "     index_id,\n",
    "     MAX(test_adresse_cas_1_3_4) AS index_id_dup_has_cas_1_3_4\n",
    "     FROM test\n",
    "     GROUP BY index_id\n",
    "     ) AS  is_index_id_dup_has_cas_1_3_4 ON test.index_id = is_index_id_dup_has_cas_1_3_4.index_id\n",
    "   \n",
    "   \n",
    "  \n",
    "    LEFT JOIN (\n",
    "     SELECT \n",
    "     index_id,\n",
    "     MAX(pct_intersection) AS index_id_max_intersection\n",
    "     FROM test\n",
    "     GROUP BY index_id\n",
    "     ) AS  is_index_id_index_id_max_intersection ON test.index_id = is_index_id_index_id_max_intersection.index_id\n",
    "   \n",
    "  )\n",
    " )\n",
    "\"\"\"\n",
    "output = s3.run_query(\n",
    "        query=create_table,\n",
    "        database='inpi',\n",
    "        s3_output='INPI/sql_output'\n",
    "    )\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM ets_inpi_insee_cases\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "        query=query,\n",
    "        database='inpi',\n",
    "        s3_output='INPI/sql_output',\n",
    "    filename  = 'ex_ets_inpi_insee_cases'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation table Tests index a dedoublonné\n",
    "\n",
    "Création d'une table avec l'ensemble des tests possibles. Chacune des lignes vient par ordre croissant, c'est a dire que la ligne 1 est préférée à la ligne 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "DROP TABLE `regles_tests`;\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "        query=query,\n",
    "        database='inpi',\n",
    "        s3_output='INPI/sql_output'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pct_intersection = ['TRUE', 'FALSE']\n",
    "status_cas = ['CAS_1','CAS_3','CAS_4', 'CAS_5','CAS_7', 'CAS_6']\n",
    "index_id_duplicate = ['TRUE', 'FALSE']\n",
    "test_list_num_voie = ['TRUE', 'NULL', 'FALSE']\n",
    "test_siege = ['TRUE','NULL','FALSE']\n",
    "test_enseigne =  ['TRUE','NULL', 'FALSE']\n",
    "test_siren_insee_siren_inpi = ['TRUE', 'FALSE']\n",
    "test_distance_cosine = ['TRUE', 'FALSE', 'NULL']\n",
    "test_distance_levhenstein = ['TRUE', 'FALSE', 'NULL']\n",
    "test_date = ['TRUE','NULL','FALSE']\n",
    "test_status_admin = ['TRUE', 'FALSE']\n",
    "\n",
    "index = pd.MultiIndex.from_product([\n",
    "    test_pct_intersection,\n",
    "    status_cas,\n",
    "    index_id_duplicate,\n",
    "    test_list_num_voie,\n",
    "    test_siren_insee_siren_inpi,\n",
    "    test_siege,\n",
    "    test_enseigne,\n",
    "    test_distance_cosine,\n",
    "    test_distance_levhenstein,\n",
    "    test_date,\n",
    "    test_status_admin\n",
    "],\n",
    "                                   names = [\n",
    "                                       'test_pct_intersection',\n",
    "                                       \"status_cas\",\n",
    "                                            'index_id_duplicate',\n",
    "                                            \"test_list_num_voie\",\n",
    "                                            \"test_siren_insee_siren_inpi\",\n",
    "                                           'test_siege', \n",
    "                                           'test_enseigne',\n",
    "                                           'test_distance_cosine',\n",
    "                                           'test_distance_levhenstein',\n",
    "                                           'test_date',\n",
    "                                           'test_status_admin'])\n",
    "\n",
    "df_ = (pd.DataFrame(index = index)\n",
    "       .reset_index()\n",
    "       .assign(rank = lambda x: x.index + 1)\n",
    "       #.to_csv('Regle_tests.csv', index = False)\n",
    "      )\n",
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au total, il y a 69984 règles possibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.to_csv('Regle_tests.csv', index = False)\n",
    "s3.upload_file(file_to_upload = 'Regle_tests.csv',\n",
    "            destination_in_s3 = 'TEMP_ANALYSE_SIRETISATION/REGLES_TESTS')\n",
    "\n",
    "create_table = \"\"\"\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS inpi.REGLES_TESTS (\n",
    "`test_pct_intersection`                     string,\n",
    "`status_cas`                     string,\n",
    "`index_id_duplicate`                     string,\n",
    "`test_list_num_voie`                     string,\n",
    "`test_siren_insee_siren_inpi`                     string,\n",
    "`test_siege`                     string,\n",
    "`test_enseigne`                     string,\n",
    "`test_distance_cosine`                     string,\n",
    "`test_distance_levhenstein`                     string,\n",
    "`test_date`                     string,\n",
    "`test_status_admin`                     string,\n",
    "`rank`                     integer\n",
    "\n",
    "    )\n",
    "     ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'\n",
    "    WITH SERDEPROPERTIES (\n",
    "   'separatorChar' = ',',\n",
    "   'quoteChar' = '\"'\n",
    "   )\n",
    "     LOCATION 's3://calfdata/TEMP_ANALYSE_SIRETISATION/REGLES_TESTS'\n",
    "     TBLPROPERTIES ('has_encrypted_data'='false',\n",
    "              'skip.header.line.count'='1');\"\"\"\n",
    "s3.run_query(\n",
    "        query=create_table,\n",
    "        database='inpi',\n",
    "        s3_output='INPI/sql_output'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation test Distance \n",
    "\n",
    "Nous souhaitons connaite la distance maximum entre les mots \"exceptions\" INSEE et INPI. On ne prend que les cas 5/6/7. voici un exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT inpi_except, insee_except\n",
    "FROM ets_inpi_insee_cases\n",
    "WHERE status_cas = 'CAS_6'\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "        query=query,\n",
    "        database='inpi',\n",
    "        s3_output='INPI/sql_output',\n",
    "    filename  = 'ex_ets_inpi_insee_cases'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cela, nous avons entrainé un modèle via l'algorithme de Word2Vec entre l'ensemble des mots de chacune des lignes INPI/INSEE. On a gardé que les mots avec une récurence d'au moins 5, et nous avons calculé 100 poids par mot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM machine_learning.list_mots_insee_inpi\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "        query=query,\n",
    "        database='inpi',\n",
    "        s3_output='INPI/sql_output',\n",
    "    filename  = 'ex_ets_inpi_insee_cases'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un [rapport](https://scm.saas.cagip.group.gca/PERNETTH/inseeinpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/07_analytics_ETS/Reports/03_POC_word2Vec_weights_computation.html) a été crée pour montrer les relations possibles.\n",
    "\n",
    "Les poids ont été mis dans une table, appelée `list_mots_insee_inpi_word2vec_weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM machine_learning.list_mots_insee_inpi_word2vec_weights\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "        query=query,\n",
    "        database='inpi',\n",
    "        s3_output='INPI/sql_output',\n",
    "    filename  = 'ex_ets_inpi_insee_cases'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOus avons ensuite matché la liste avec la table `ets_inpi_insee_cases`, calculé la distance entre les deux mots exceptions, exempel \"APPARTMENT\" et \"APP\". Comme plusieurs possibilitées par lignes, nous avons récupéré la valeur la plus élevée par index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "DROP TABLE `inpi.ets_inpi_distance_max_word2vec`;\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "        query=query,\n",
    "        database='inpi',\n",
    "        s3_output='INPI/sql_output'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "CREATE TABLE inpi.ets_inpi_distance_max_word2vec\n",
    "WITH (\n",
    "  format='PARQUET'\n",
    ") AS\n",
    "WITH dataset AS (\n",
    "  SELECT \n",
    "    row_id, \n",
    "    index_id, \n",
    "    status_cas, \n",
    "    inpi_except, \n",
    "    insee_except, \n",
    "    pct_intersection, \n",
    "    len_inpi_except, \n",
    "    len_insee_except, \n",
    "    transform(\n",
    "      sequence(\n",
    "        1, \n",
    "        CARDINALITY(insee_except)\n",
    "      ), \n",
    "      x -> insee_except\n",
    "    ), \n",
    "    ZIP(\n",
    "      inpi_except, \n",
    "      transform(\n",
    "        sequence(\n",
    "          1, \n",
    "          CARDINALITY(inpi_except)\n",
    "        ), \n",
    "        x -> insee_except\n",
    "      )\n",
    "    ) as test \n",
    "  FROM \n",
    "    inpi.ets_inpi_insee_cases \n",
    "  where \n",
    "    (\n",
    "      status_cas = 'CAS_5' \n",
    "      OR status_cas = 'CAS_6' \n",
    "      OR status_cas = 'CAS_7'\n",
    "    ) \n",
    "  -- AND index_id = 8759351\n",
    ") \n",
    "SELECT \n",
    "  * \n",
    "FROM \n",
    "  (\n",
    "    WITH distance AS (\n",
    "      SELECT \n",
    "        * \n",
    "      FROM \n",
    "        (\n",
    "          WITH list_weights_insee_inpi AS (\n",
    "            SELECT \n",
    "              row_id, \n",
    "              index_id, \n",
    "              status_cas, \n",
    "              inpi_except, \n",
    "              insee_except, \n",
    "              len_inpi_except, \n",
    "              len_insee_except, \n",
    "              unzip_inpi, \n",
    "              unzip_insee, \n",
    "              list_weights_inpi, \n",
    "              list_weights_insee \n",
    "            FROM \n",
    "              (\n",
    "                SELECT \n",
    "                  row_id, \n",
    "                  index_id, \n",
    "                  status_cas, \n",
    "                  inpi_except, \n",
    "                  insee_except, \n",
    "                  len_inpi_except, \n",
    "                  len_insee_except, \n",
    "                  unzip.field0 as unzip_inpi, \n",
    "                  unzip.field1 as insee, \n",
    "                  test \n",
    "                FROM \n",
    "                  dataset CROSS \n",
    "                  JOIN UNNEST(test) AS new (unzip)\n",
    "              ) CROSS \n",
    "              JOIN UNNEST(insee) as test (unzip_insee) \n",
    "              LEFT JOIN (\n",
    "                SELECT \n",
    "                  words, \n",
    "                  list_weights as list_weights_inpi \n",
    "                FROM \n",
    "                  machine_learning.list_mots_insee_inpi_word2vec_weights\n",
    "              ) tb_weight_inpi ON unzip_inpi = tb_weight_inpi.words \n",
    "              LEFT JOIN (\n",
    "                SELECT \n",
    "                  words, \n",
    "                  list_weights as list_weights_insee \n",
    "                FROM \n",
    "                  machine_learning.list_mots_insee_inpi_word2vec_weights\n",
    "              ) tb_weight_insee ON unzip_insee = tb_weight_insee.words \n",
    "          ) \n",
    "          SELECT \n",
    "            row_id, \n",
    "            index_id, \n",
    "            status_cas, \n",
    "            inpi_except, \n",
    "            insee_except, \n",
    "            unzip_inpi, \n",
    "            unzip_insee, \n",
    "            len_inpi_except, \n",
    "            len_insee_except, \n",
    "            REDUCE(\n",
    "              zip_with(\n",
    "                list_weights_inpi, \n",
    "                list_weights_insee, \n",
    "                (x, y) -> x * y\n",
    "              ), \n",
    "              CAST(\n",
    "                ROW(0.0) AS ROW(sum DOUBLE)\n",
    "              ), \n",
    "              (s, x) -> CAST(\n",
    "                ROW(x + s.sum) AS ROW(sum DOUBLE)\n",
    "              ), \n",
    "              s -> s.sum\n",
    "            ) / (\n",
    "              SQRT(\n",
    "                REDUCE(\n",
    "                  transform(\n",
    "                    list_weights_inpi, \n",
    "                    (x) -> POW(x, 2)\n",
    "                  ), \n",
    "                  CAST(\n",
    "                    ROW(0.0) AS ROW(sum DOUBLE)\n",
    "                  ), \n",
    "                  (s, x) -> CAST(\n",
    "                    ROW(x + s.sum) AS ROW(sum DOUBLE)\n",
    "                  ), \n",
    "                  s -> s.sum\n",
    "                )\n",
    "              ) * SQRT(\n",
    "                REDUCE(\n",
    "                  transform(\n",
    "                    list_weights_insee, \n",
    "                    (x) -> POW(x, 2)\n",
    "                  ), \n",
    "                  CAST(\n",
    "                    ROW(0.0) AS ROW(sum DOUBLE)\n",
    "                  ), \n",
    "                  (s, x) -> CAST(\n",
    "                    ROW(x + s.sum) AS ROW(sum DOUBLE)\n",
    "                  ), \n",
    "                  s -> s.sum\n",
    "                )\n",
    "              )\n",
    "            ) AS cosine_distance \n",
    "          FROM \n",
    "            list_weights_insee_inpi\n",
    "        )\n",
    "    ) \n",
    "    SELECT \n",
    "      row_id, \n",
    "      dataset.index_id, \n",
    "      inpi_except, \n",
    "      insee_except, \n",
    "      unzip_inpi, \n",
    "      unzip_insee, \n",
    "      max_cosine_distance,\n",
    "      CASE WHEN max_cosine_distance >= .6 THEN 'TRUE' ELSE 'FALSE' END AS test_distance_cosine,\n",
    "      test as key_except_to_test,\n",
    "      levenshtein_distance(unzip_inpi, unzip_insee) AS levenshtein_distance,\n",
    "      CASE WHEN levenshtein_distance(unzip_inpi, unzip_insee) <=1  THEN 'TRUE' ELSE 'FALSE' END AS test_distance_levhenstein\n",
    "    \n",
    "    FROM \n",
    "      dataset \n",
    "      LEFT JOIN (\n",
    "        SELECT \n",
    "          distance.index_id, \n",
    "          unzip_inpi, \n",
    "          unzip_insee, \n",
    "          max_cosine_distance \n",
    "        FROM \n",
    "          distance \n",
    "          RIGHT JOIN (\n",
    "            SELECT \n",
    "              index_id, \n",
    "              MAX(cosine_distance) as max_cosine_distance \n",
    "            FROM \n",
    "              distance \n",
    "            GROUP BY \n",
    "              index_id\n",
    "          ) as tb_max_distance ON distance.index_id = tb_max_distance.index_id \n",
    "          AND distance.cosine_distance = tb_max_distance.max_cosine_distance\n",
    "      ) as tb_max_distance_lookup ON dataset.index_id = tb_max_distance_lookup.index_id\n",
    "  )\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database='inpi',\n",
    "            s3_output=s3_output,\n",
    "  filename = None, ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT * \n",
    "FROM ets_inpi_distance_max_word2vec  \n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "        query=query,\n",
    "        database='inpi',\n",
    "        s3_output='INPI/sql_output',\n",
    "    filename  = 'ex_ets_inpi_insee_cases'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create table ajout distance\n",
    "\n",
    "Ensuite, nous avons mergé la table contenant les distances avec la table initiale `ets_inpi_insee_cases` et bien sur matché le rank des règles avec la table `regles_tests`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "DROP TABLE `inpi.ets_inpi_insee_cases_distance`;\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "        query=query,\n",
    "        database='inpi',\n",
    "        s3_output='INPI/sql_output'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "CREATE TABLE inpi.ets_inpi_insee_cases_distance\n",
    "WITH (\n",
    "  format='PARQUET'\n",
    ") AS\n",
    "WITH tb_distance AS (\n",
    "SELECT \n",
    "  ets_inpi_insee_cases.row_id, \n",
    "  ets_inpi_insee_cases.index_id, \n",
    "  sequence_id, \n",
    "  siren, \n",
    "  siret,\n",
    "  list_inpi, \n",
    "  lenght_list_inpi, \n",
    "  list_insee, \n",
    "  lenght_list_insee, \n",
    "  ets_inpi_insee_cases.inpi_except, \n",
    "  ets_inpi_insee_cases.insee_except, \n",
    "  intersection, \n",
    "  union_, \n",
    "  pct_intersection,\n",
    "  index_id_max_intersection,\n",
    "  test_pct_intersection,\n",
    "  len_inpi_except, \n",
    "  len_insee_except, \n",
    "  status_cas,\n",
    "  unzip_inpi,\n",
    "  unzip_insee,\n",
    "  max_cosine_distance,\n",
    "  CASE WHEN test_distance_cosine IS NULL THEN 'NULL' ELSE test_distance_cosine END AS test_distance_cosine,\n",
    "  -- test_distance_costine,\n",
    "  levenshtein_distance,\n",
    "  CASE WHEN test_distance_levhenstein IS NULL THEN 'NULL' ELSE test_distance_levhenstein END AS test_distance_levhenstein,\n",
    "  -- test_levhenstein, \n",
    "  count_initial_insee, \n",
    "  count_inpi_siren_siret, \n",
    "  count_inpi_siren_sequence, \n",
    "  count_inpi_sequence_siret, \n",
    "  count_inpi_sequence_stat_cas_siret, \n",
    "  count_inpi_index_id_siret, \n",
    "  count_inpi_index_id_stat_cas_siret, \n",
    "  count_inpi_index_id_stat_cas, \n",
    "  index_id_duplicate, \n",
    "  test_sequence_siret, \n",
    "  test_index_siret, \n",
    "  test_siren_insee_siren_inpi, \n",
    "  test_sequence_siret_many_cas, \n",
    "  list_numero_voie_matching_inpi, \n",
    "  list_numero_voie_matching_insee, \n",
    "  intersection_numero_voie, \n",
    "  union_numero_voie, \n",
    "  test_list_num_voie, \n",
    "  datecreationetablissement, \n",
    "  date_debut_activite, \n",
    "  test_date, \n",
    "  etatadministratifetablissement, \n",
    "  status_admin, \n",
    "  test_status_admin, \n",
    "  etablissementsiege, \n",
    "  status_ets, \n",
    "  test_siege, \n",
    "  codecommuneetablissement, \n",
    "  code_commune, \n",
    "  test_code_commune, \n",
    "  codepostaletablissement, \n",
    "  code_postal_matching, \n",
    "  numerovoieetablissement, \n",
    "  numero_voie_matching, \n",
    "  test_numero_voie, \n",
    "  typevoieetablissement, \n",
    "  type_voie_matching, \n",
    "  test_type_voie, \n",
    "  test_adresse_cas_1_3_4, \n",
    "  index_id_dup_has_cas_1_3_4, \n",
    "  test_duplicates_is_in_cas_1_3_4, \n",
    "  enseigne, \n",
    "  enseigne1etablissement, \n",
    "  enseigne2etablissement, \n",
    "  enseigne3etablissement, \n",
    "  test_enseigne,\n",
    "  key_except_to_test\n",
    "FROM \n",
    "  ets_inpi_insee_cases\n",
    "LEFT JOIN\n",
    "ets_inpi_distance_max_word2vec \n",
    "ON ets_inpi_insee_cases.row_id = ets_inpi_distance_max_word2vec.row_id\n",
    ")\n",
    "SELECT \n",
    "  rank, \n",
    "  row_id, \n",
    "  index_id, \n",
    "  sequence_id, \n",
    "  siren, \n",
    "  siret,\n",
    "  list_inpi, \n",
    "  lenght_list_inpi, \n",
    "  list_insee, \n",
    "  lenght_list_insee, \n",
    "  inpi_except, \n",
    "  insee_except, \n",
    "  intersection, \n",
    "  union_, \n",
    "  pct_intersection,\n",
    "  index_id_max_intersection,\n",
    "  tb_distance.test_pct_intersection,\n",
    "  len_inpi_except, \n",
    "  len_insee_except, \n",
    "  tb_distance.status_cas,\n",
    "  unzip_inpi,\n",
    "  unzip_insee,\n",
    "  max_cosine_distance,\n",
    "  tb_distance.test_distance_cosine,\n",
    "  -- test_distance_costine,\n",
    "  levenshtein_distance,\n",
    "  tb_distance.test_distance_levhenstein,\n",
    "  -- test_levhenstein, \n",
    "  count_initial_insee, \n",
    "  count_inpi_siren_siret, \n",
    "  count_inpi_siren_sequence, \n",
    "  count_inpi_sequence_siret, \n",
    "  count_inpi_sequence_stat_cas_siret, \n",
    "  count_inpi_index_id_siret, \n",
    "  count_inpi_index_id_stat_cas_siret, \n",
    "  count_inpi_index_id_stat_cas, \n",
    "  tb_distance.index_id_duplicate, \n",
    "  test_sequence_siret, \n",
    "  test_index_siret, \n",
    "  tb_distance.test_siren_insee_siren_inpi, \n",
    "  test_sequence_siret_many_cas, \n",
    "  list_numero_voie_matching_inpi, \n",
    "  list_numero_voie_matching_insee, \n",
    "  intersection_numero_voie, \n",
    "  union_numero_voie, \n",
    "  tb_distance.test_list_num_voie, \n",
    "  datecreationetablissement, \n",
    "  date_debut_activite, \n",
    "  tb_distance.test_date, \n",
    "  etatadministratifetablissement, \n",
    "  status_admin, \n",
    "  tb_distance.test_status_admin, \n",
    "  etablissementsiege, \n",
    "  status_ets, \n",
    "  tb_distance.test_siege, \n",
    "  codecommuneetablissement, \n",
    "  code_commune, \n",
    "  test_code_commune, \n",
    "  codepostaletablissement, \n",
    "  code_postal_matching, \n",
    "  numerovoieetablissement, \n",
    "  numero_voie_matching, \n",
    "  test_numero_voie, \n",
    "  typevoieetablissement, \n",
    "  type_voie_matching, \n",
    "  test_type_voie, \n",
    "  test_adresse_cas_1_3_4, \n",
    "  index_id_dup_has_cas_1_3_4, \n",
    "  test_duplicates_is_in_cas_1_3_4, \n",
    "  enseigne, \n",
    "  enseigne1etablissement, \n",
    "  enseigne2etablissement, \n",
    "  enseigne3etablissement, \n",
    "  tb_distance.test_enseigne,\n",
    "  key_except_to_test\n",
    "FROM tb_distance\n",
    "LEFT JOIN regles_tests \n",
    "\n",
    "  ON  tb_distance.test_pct_intersection = regles_tests.test_pct_intersection\n",
    "\n",
    "  AND  tb_distance.status_cas = regles_tests.status_cas \n",
    "  \n",
    "  AND tb_distance.index_id_duplicate = regles_tests.index_id_duplicate \n",
    "  \n",
    "  AND tb_distance.test_list_num_voie = regles_tests.test_list_num_voie \n",
    "  AND tb_distance.test_siren_insee_siren_inpi = regles_tests.test_siren_insee_siren_inpi\n",
    "  AND tb_distance.test_siege = regles_tests.test_siege \n",
    "  AND tb_distance.test_enseigne = regles_tests.test_enseigne\n",
    "  \n",
    "  AND tb_distance.test_distance_cosine = regles_tests.test_distance_cosine \n",
    "  AND tb_distance.test_distance_levhenstein = regles_tests.test_distance_levhenstein\n",
    "  \n",
    "  AND tb_distance.test_date = regles_tests.test_date \n",
    "  AND tb_distance.test_status_admin = regles_tests.test_status_admin\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database='inpi',\n",
    "            s3_output=s3_output,\n",
    "  filename = None, ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT * \n",
    "FROM ets_inpi_insee_cases_distance  \n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "        query=query,\n",
    "        database='inpi',\n",
    "        s3_output='INPI/sql_output',\n",
    "    filename  = 'ex_ets_inpi_insee_cases'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation table finale\n",
    "\n",
    "- Afin de séparer les doublons, il suffit de récupérer le rank minimum par index. Celui ci va nous donner le meilleur des probables.\n",
    "- Il est bien sur possible d’avoir encore des doublons, dans ces cas la, il faut aller plus loin dans la rédaction des tests\n",
    "L’objectif, ici, est de récupérer le rank minimum de la table ets_inpi_insee_cases puis de faire une analyse brève des index récupérés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "DROP TABLE `inpi.ets_inpi_insee_cases_rank`;\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "        query=query,\n",
    "        database='inpi',\n",
    "        s3_output='INPI/sql_output'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "CREATE TABLE inpi.ets_inpi_insee_cases_rank\n",
    "WITH (\n",
    "  format='PARQUET'\n",
    ") AS\n",
    "WITH tb_min_rank AS (\n",
    "SELECT \n",
    "min_rank,\n",
    "  row_id, \n",
    "  ets_inpi_insee_cases_distance.index_id, \n",
    "  sequence_id, \n",
    "  siren, \n",
    "  siret,\n",
    "  list_inpi, \n",
    "  lenght_list_inpi, \n",
    "  list_insee, \n",
    "  lenght_list_insee, \n",
    "  inpi_except, \n",
    "  insee_except, \n",
    "  intersection, \n",
    "  union_, \n",
    "  pct_intersection, \n",
    "  index_id_max_intersection,\n",
    "  test_pct_intersection,\n",
    "  len_inpi_except, \n",
    "  len_insee_except, \n",
    "  status_cas,\n",
    "  unzip_inpi,\n",
    "  unzip_insee,\n",
    "  max_cosine_distance,\n",
    "  test_distance_cosine,\n",
    "  levenshtein_distance,\n",
    "  test_distance_levhenstein, \n",
    "  count_initial_insee, \n",
    "  count_inpi_siren_siret, \n",
    "  count_inpi_siren_sequence, \n",
    "  count_inpi_sequence_siret, \n",
    "  count_inpi_sequence_stat_cas_siret, \n",
    "  count_inpi_index_id_siret, \n",
    "  count_inpi_index_id_stat_cas_siret, \n",
    "  count_inpi_index_id_stat_cas, \n",
    "  index_id_duplicate, \n",
    "  test_sequence_siret, \n",
    "  test_index_siret, \n",
    "  test_siren_insee_siren_inpi, \n",
    "  test_sequence_siret_many_cas, \n",
    "  list_numero_voie_matching_inpi, \n",
    "  list_numero_voie_matching_insee, \n",
    "  intersection_numero_voie, \n",
    "  union_numero_voie, \n",
    "  test_list_num_voie, \n",
    "  datecreationetablissement, \n",
    "  date_debut_activite, \n",
    "  test_date, \n",
    "  etatadministratifetablissement, \n",
    "  status_admin, \n",
    "  test_status_admin, \n",
    "  etablissementsiege, \n",
    "  status_ets, \n",
    "  test_siege, \n",
    "  codecommuneetablissement, \n",
    "  code_commune, \n",
    "  test_code_commune, \n",
    "  codepostaletablissement, \n",
    "  code_postal_matching, \n",
    "  numerovoieetablissement, \n",
    "  numero_voie_matching, \n",
    "  test_numero_voie, \n",
    "  typevoieetablissement, \n",
    "  type_voie_matching, \n",
    "  test_type_voie, \n",
    "  test_adresse_cas_1_3_4, \n",
    "  index_id_dup_has_cas_1_3_4, \n",
    "  test_duplicates_is_in_cas_1_3_4, \n",
    "  enseigne, \n",
    "  enseigne1etablissement, \n",
    "  enseigne2etablissement, \n",
    "  enseigne3etablissement, \n",
    "  test_enseigne,\n",
    "  key_except_to_test\n",
    "FROM ets_inpi_insee_cases_distance \n",
    "INNER JOIN (\n",
    "  SELECT index_id, MIN(rank) AS min_rank\n",
    "FROM ets_inpi_insee_cases_distance\n",
    "GROUP BY index_id\n",
    "  ) as tb_min_rank\n",
    "ON ets_inpi_insee_cases_distance.index_id = tb_min_rank.index_id AND\n",
    "ets_inpi_insee_cases_distance.rank = tb_min_rank.min_rank\n",
    "  ) \n",
    "  SELECT \n",
    "  min_rank,\n",
    "  row_id, \n",
    "  tb_min_rank.index_id, \n",
    "  count_index,\n",
    "  sequence_id, \n",
    "  siren, \n",
    "  siret,\n",
    "  list_inpi, \n",
    "  lenght_list_inpi, \n",
    "  list_insee, \n",
    "  lenght_list_insee, \n",
    "  inpi_except, \n",
    "  insee_except, \n",
    "  intersection, \n",
    "  union_, \n",
    "  pct_intersection,\n",
    "  index_id_max_intersection,\n",
    "  test_pct_intersection,\n",
    "  len_inpi_except, \n",
    "  len_insee_except, \n",
    "  status_cas,\n",
    "  unzip_inpi,\n",
    "  unzip_insee,\n",
    "  max_cosine_distance,\n",
    "  test_distance_cosine,\n",
    "  levenshtein_distance,\n",
    "  test_distance_levhenstein, \n",
    "  count_initial_insee, \n",
    "  count_inpi_siren_siret, \n",
    "  count_inpi_siren_sequence, \n",
    "  count_inpi_sequence_siret, \n",
    "  count_inpi_sequence_stat_cas_siret, \n",
    "  count_inpi_index_id_siret, \n",
    "  count_inpi_index_id_stat_cas_siret, \n",
    "  count_inpi_index_id_stat_cas, \n",
    "  index_id_duplicate, \n",
    "  test_sequence_siret, \n",
    "  test_index_siret, \n",
    "  test_siren_insee_siren_inpi, \n",
    "  test_sequence_siret_many_cas, \n",
    "  list_numero_voie_matching_inpi, \n",
    "  list_numero_voie_matching_insee, \n",
    "  intersection_numero_voie, \n",
    "  union_numero_voie, \n",
    "  test_list_num_voie, \n",
    "  datecreationetablissement, \n",
    "  date_debut_activite, \n",
    "  test_date, \n",
    "  etatadministratifetablissement, \n",
    "  status_admin, \n",
    "  test_status_admin, \n",
    "  etablissementsiege, \n",
    "  status_ets, \n",
    "  test_siege, \n",
    "  codecommuneetablissement, \n",
    "  code_commune, \n",
    "  test_code_commune, \n",
    "  codepostaletablissement, \n",
    "  code_postal_matching, \n",
    "  numerovoieetablissement, \n",
    "  numero_voie_matching, \n",
    "  test_numero_voie, \n",
    "  typevoieetablissement, \n",
    "  type_voie_matching, \n",
    "  test_type_voie, \n",
    "  test_adresse_cas_1_3_4, \n",
    "  index_id_dup_has_cas_1_3_4, \n",
    "  test_duplicates_is_in_cas_1_3_4, \n",
    "  enseigne, \n",
    "  enseigne1etablissement, \n",
    "  enseigne2etablissement, \n",
    "  enseigne3etablissement, \n",
    "  test_enseigne,\n",
    "  key_except_to_test \n",
    "  FROM tb_min_rank\n",
    "  LEFT JOIN (\n",
    "    SELECT index_id, COUNT(*) AS count_index\n",
    "    FROM tb_min_rank\n",
    "    GROUP BY index_id\n",
    "    ) as tb_nb_index\n",
    "    ON tb_min_rank.index_id = tb_nb_index.index_id\n",
    "\"\"\"\n",
    "\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database='inpi',\n",
    "            s3_output=s3_output,\n",
    "  filename = None, ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT * \n",
    "FROM ets_inpi_insee_cases_rank  \n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "        query=query,\n",
    "        database='inpi',\n",
    "        s3_output='INPI/sql_output',\n",
    "    filename  = 'ex_ets_inpi_insee_cases'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count nombre lignes & index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre de lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT COUNT(*)\n",
    "FROM ets_inpi_insee_cases_rank \n",
    "\"\"\"\n",
    "\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database='inpi',\n",
    "            s3_output='INPI/sql_output',\n",
    "      filename = 'cnt_nb_lignes_rank', ## Add filename to print dataframe\n",
    "      destination_key = None ### Add destination key if need to copy output\n",
    "        )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre d'index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT COUNT(distinct(index_id))\n",
    "FROM ets_inpi_insee_cases_rank \n",
    "\"\"\"\n",
    "\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database='inpi',\n",
    "            s3_output='INPI/sql_output',\n",
    "      filename = 'cnt_nb_index_rank', ## Add filename to print dataframe\n",
    "      destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation des doublons\n",
    "\n",
    "Le tableau ci dessous récapitule les index uniques et les doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT count_index, COUNT(*) as ligne_dup\n",
    "FROM ets_inpi_insee_cases_rank \n",
    "GROUP BY count_index \n",
    "ORDER BY count_index\n",
    "\"\"\"\n",
    "\n",
    "nb_ligne = s3.run_query(\n",
    "            query=query,\n",
    "            database='inpi',\n",
    "            s3_output='INPI/sql_output',\n",
    "      filename = 'cnt_nb_dup_lignes_rank', ## Add filename to print dataframe\n",
    "      destination_key = None ### Add destination key if need to copy output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT count_index, COUNT(DISTINCT(index_id)) as index_dup\n",
    "FROM ets_inpi_insee_cases_rank \n",
    "GROUP BY count_index \n",
    "ORDER BY count_index\n",
    "\"\"\"\n",
    "\n",
    "nb_index = s3.run_query(\n",
    "            query=query,\n",
    "            database='inpi',\n",
    "            s3_output='INPI/sql_output',\n",
    "      filename = 'cnt_nb_dup_index_rank', ## Add filename to print dataframe\n",
    "      destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "pd.concat([    \n",
    " pd.concat([\n",
    "    pd.concat(\n",
    "    [\n",
    "        nb_ligne.sum().to_frame().T.rename(index = {0:'total'}), \n",
    "        nb_ligne\n",
    "    ], axis = 0),\n",
    "    ],axis = 1,keys=[\"Lignes\"]),\n",
    "    (\n",
    " pd.concat([\n",
    "    pd.concat(\n",
    "    [\n",
    "        nb_index.sum().to_frame().T.rename(index = {0:'total'}), \n",
    "        nb_index\n",
    "    ], axis = 0),\n",
    "    ],axis = 1,keys=[\"Index\"])\n",
    ")],axis= 1\n",
    "    )\n",
    "    .style\n",
    "    .format(\"{:,.0f}\")\n",
    "                  .bar(subset= [\n",
    "                      ('Lignes','ligne_dup'),\n",
    "                      ('Index','index_dup'),\n",
    "                      \n",
    "                  ],\n",
    "                       color='#d65f5f')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre d'index récuperé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_index.iloc[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre d'index a trouver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_index.sum().to_frame().T.rename(index = {0:'total'}).iloc[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pourcentage de probable trouvé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(nb_index.iloc[0,1] / nb_index.sum().to_frame().T.rename(index = {0:'total'}).iloc[0,1], 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "count_index, \n",
    "  approx_percentile(min_rank, ARRAY[.1, .15, .20, 0.25,0.50,0.75,.80,.85,.86,.87, .88, .89,.90,0.95, 0.99]) as pct_min_rank\n",
    "FROM \n",
    "  ets_inpi_insee_cases_rank\n",
    "GROUP BY count_index  \n",
    "ORDER BY count_index\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database='inpi',\n",
    "            s3_output='INPI/sql_output',\n",
    "      filename = 'distribution_rank', ## Add filename to print dataframe\n",
    "      destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prenons par exemple, le rank 32141, qui correspond a la règle suivante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"\"\"\n",
    "SELECT *\n",
    "FROM regles_tests \n",
    "WHERE rank = 32141\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database='inpi',\n",
    "            s3_output='INPI/sql_output',\n",
    "      filename = 'rules', ## Add filename to print dataframe\n",
    "      destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci dessous, un ensemble de lignes correspondant a la règle 32141"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"\"\"\n",
    "SELECT * \n",
    "FROM ets_inpi_insee_cases_rank \n",
    "WHERE min_rank = 32141\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database='inpi',\n",
    "            s3_output='INPI/sql_output',\n",
    "      filename = 'rules_32141', ## Add filename to print dataframe\n",
    "      destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, shutil, urllib, ipykernel, json\n",
    "from pathlib import Path\n",
    "from notebook import notebookapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_report(extension = \"html\", keep_code = False):\n",
    "    \"\"\"\n",
    "    Create a report from the current notebook and save it in the \n",
    "    Report folder (Parent-> child directory)\n",
    "    \n",
    "    1. Exctract the current notbook name\n",
    "    2. Convert the Notebook \n",
    "    3. Move the newly created report\n",
    "    \n",
    "    Args:\n",
    "    extension: string. Can be \"html\", \"pdf\", \"md\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ### Get notebook name\n",
    "    connection_file = os.path.basename(ipykernel.get_connection_file())\n",
    "    kernel_id = connection_file.split('-', 1)[0].split('.')[0]\n",
    "\n",
    "    for srv in notebookapp.list_running_servers():\n",
    "        try:\n",
    "            if srv['token']=='' and not srv['password']:  \n",
    "                req = urllib.request.urlopen(srv['url']+'api/sessions')\n",
    "            else:\n",
    "                req = urllib.request.urlopen(srv['url']+ \\\n",
    "                                             'api/sessions?token=' + \\\n",
    "                                             srv['token'])\n",
    "            sessions = json.load(req)\n",
    "            notebookname = sessions[0]['name']\n",
    "        except:\n",
    "            pass  \n",
    "    \n",
    "    sep = '.'\n",
    "    path = os.getcwd()\n",
    "    #parent_path = str(Path(path).parent)\n",
    "    \n",
    "    ### Path report\n",
    "    #path_report = \"{}/Reports\".format(parent_path)\n",
    "    #path_report = \"{}/Reports\".format(path)\n",
    "    \n",
    "    ### Path destination\n",
    "    name_no_extension = notebookname.split(sep, 1)[0]\n",
    "    source_to_move = name_no_extension +'.{}'.format(extension)\n",
    "    dest = os.path.join(path,'Reports', source_to_move)\n",
    "    \n",
    "    ### Generate notebook\n",
    "    if keep_code:\n",
    "        os.system('jupyter nbconvert --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    else:\n",
    "        os.system('jupyter nbconvert --no-input --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    \n",
    "    ### Move notebook to report folder\n",
    "    #time.sleep(5)\n",
    "    shutil.move(source_to_move, dest)\n",
    "    print(\"Report Available at this adress:\\n {}\".format(dest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_report(extension = \"html\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.24.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
