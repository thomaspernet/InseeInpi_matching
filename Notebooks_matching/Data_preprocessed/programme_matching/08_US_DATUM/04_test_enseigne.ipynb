{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation variable test_enseigne a effectuer pour dedoublonner les lignes\n",
    "\n",
    "Copy paste from Coda to fill the information\n",
    "\n",
    "## Objective(s)\n",
    "\n",
    "La siretisation repose sur une matrice de règles de gestion classée de manière ordonnée. Pour créer la matrice, il faut au préalable créer les variables nécéssaires à la création des tests. \n",
    "\n",
    "Le tableau ci dessous indique l'ensemble des tests a réaliser ainsi que leur dépendence.\n",
    "\n",
    "| Rang | Nom_variable                              | Dependence                                    | Notebook                           | Difficulte | Table_input                                                                                                                                                            | Variables_crees_US                                                                 | Possibilites                  |\n",
    "|------|-------------------------------------------|-----------------------------------------------|------------------------------------|------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------|-------------------------------|\n",
    "| 1    | status_cas                                |                                               | 02_cas_de_figure                   | Moyen      | ets_insee_inpi_status_cas                                                                                                                                              | status_cas,intersection,pct_intersection,union_,inpi_except,insee_except           | CAS_1,CAS_2,CAS_3,CAS_4,CAS_5 |\n",
    "| 2    | test_list_num_voie                        | intersection_numero_voie,union_numero_voie    | 03_test_list_num_voie              | Moyen      | ets_insee_inpi_list_num_voie                                                                                                                                           | intersection_numero_voie,union_numero_voie                                         | FALSE,NULL,TRUE,PARTIAL       |\n",
    "| 3    | test_enseigne                             | list_enseigne,enseigne                        | 04_test_enseigne                   | Moyen      | ets_insee_inpi_list_enseigne                                                                                                                                           | list_enseigne_contain                                                              | FALSE,NULL,TRUE               |\n",
    "| 4    | test_pct_intersection                     | pct_intersection,index_id_max_intersection    | 06_creation_nb_siret_siren_max_pct | Facile     | ets_insee_inpi_var_group_max                                                                                                                                           | count_inpi_index_id_siret,count_inpi_siren_siret,index_id_max_intersection         | FALSE,TRUE                    |\n",
    "| 4    | test_index_id_duplicate                   | count_inpi_index_id_siret                     | 06_creation_nb_siret_siren_max_pct | Facile     | ets_insee_inpi_var_group_max                                                                                                                                           | count_inpi_index_id_siret,count_inpi_siren_siret,index_id_max_intersection         | FALSE,TRUE                    |\n",
    "| 4    | test_siren_insee_siren_inpi               | count_initial_insee,count_inpi_siren_siret    | 06_creation_nb_siret_siren_max_pct | Facile     | ets_insee_inpi_var_group_max                                                                                                                                           | count_inpi_index_id_siret,count_inpi_siren_siret,index_id_max_intersection         | FALSE,TRUE                    |\n",
    "| 5    | test_similarite_exception_words           | max_cosine_distance                           | 08_calcul_cosine_levhenstein       | Difficile  | ets_insee_inpi_similarite_max_word2vec                                                                                                                                 | unzip_inpi,unzip_insee,max_cosine_distance,levenshtein_distance,key_except_to_test | FALSE,NULL,TRUE               |\n",
    "| 5    | test_distance_levhenstein_exception_words | levenshtein_distance                          | 08_calcul_cosine_levhenstein       | Difficile  | ets_insee_inpi_similarite_max_word2vec                                                                                                                                 | unzip_inpi,unzip_insee,max_cosine_distance,levenshtein_distance,key_except_to_test | FALSE,NULL,TRUE               |\n",
    "| 6    | test_date                                 | datecreationetablissement,date_debut_activite | 10_match_et_creation_regles.md     | Facile     | ets_insee_inpi_list_num_voie,ets_insee_inpi_list_enseigne,ets_insee_inpi_similarite_max_word2vec,ets_insee_inpi_status_cas,ets_insee_inpi_var_group_max,ets_insee_inpi |                                                                                    | FALSE,TRUE                    |\n",
    "| 6    | test_siege                                | status_ets,etablissementsiege                 | 10_match_et_creation_regles.md     | Facile     | ets_insee_inpi_list_num_voie,ets_insee_inpi_list_enseigne,ets_insee_inpi_similarite_max_word2vec,ets_insee_inpi_status_cas,ets_insee_inpi_var_group_max,ets_insee_inpi |                                                                                    | FALSE,TRUE,NULL               |\n",
    "| 6    | test_status_admin                         | etatadministratifetablissement,status_admin   | 10_match_et_creation_regles.md     | Facile     | ets_insee_inpi_list_num_voie,ets_insee_inpi_list_enseigne,ets_insee_inpi_similarite_max_word2vec,ets_insee_inpi_status_cas,ets_insee_inpi_var_group_max,ets_insee_inpi |                                                                                    | FALSE,NULL,TRUE               |\n",
    "\n",
    "Lors de cette US, nous allons créer 1 variable qui va permettre a la réalisation du test `test_enseigne`. La variable est la suivante:\n",
    "\n",
    "- `list_enseigne_contain`: Variable boolean indiquant si le string de la variable `enseigne` est contenu dans la liste `list_enseigne`\n",
    "* Il faut penser a garder la variable `row_id` \n",
    "\n",
    "## Metadata \n",
    "\n",
    "* Metadata parameters are available here: \n",
    "* US Title: Creation variable test_enseigne a effectuer pour dedoublonner les lignes\n",
    "* Epic: Epic 5\n",
    "* US: US 7\n",
    "* Date Begin: 9/1/2020\n",
    "* Duration Task: 0\n",
    "* Status: active  \n",
    "* Source URL: [US 07 Preparation tables et variables tests](https://coda.io/d/_dCtnoqIftTn/US-07-Preparation-tables-et-variables-tests_suFb9)\n",
    "* Task type:\n",
    "  * Jupyter Notebook\n",
    "* Users: :\n",
    "  * Thomas Pernet\n",
    "* Watchers:\n",
    "  * Thomas Pernet\n",
    "* Estimated Log points:\n",
    "  * One being a simple task, 15 a very difficult one\n",
    "  *  1\n",
    "* Task tag\n",
    "  *  #sql-query,#regle-de-gestion,#preparation-test-enseigne\n",
    "* Toggl Tag\n",
    "  * #data-preparation\n",
    "  \n",
    "## Input Cloud Storage [AWS]\n",
    "\n",
    "If link from the internet, save it to the cloud first\n",
    "\n",
    "### Tables [AWS]\n",
    "\n",
    "1. Batch 1:\n",
    "  * Select Provider: Athena\n",
    "  * Select table(s): ets_insee_inpi_siretisation\n",
    "    * Select only tables created from the same notebook, else copy/paste selection to add new input tables\n",
    "    * If table(s) does not exist, add them: Add New Table\n",
    "    * Information:\n",
    "      * Region: \n",
    "        * NameEurope (Paris)\n",
    "        * Code: eu-west-3\n",
    "      * Database: siretisation\n",
    "      * Notebook construction file: \n",
    "        * [01_merge_ets_insee_inpi](https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/08_US_DATUM/01_merge_ets_insee_inpi.md)\n",
    "    \n",
    "## Destination Output/Delivery\n",
    "\n",
    "  1. AWS\n",
    "    1. Athena: \n",
    "      * Region: Europe (Paris)\n",
    "      * Database: siretisation\n",
    "      * Tables (Add name new table): ets_insee_inpi_list_enseigne\n",
    "      * List new tables\n",
    "      * ets_insee_inpi_list_enseigne\n",
    "\n",
    "## Things to know (Steps, Attention points or new flow of information)\n",
    "\n",
    "### Sources of information  (meeting notes, Documentation, Query, URL)\n",
    "\n",
    "1. Jupyter Notebook (Github Link)\n",
    "  1. md : https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/02_siretisation/07_pourcentage_siretisation_v3.md#creation-table-analyse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connexion serveur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awsPy.aws_authorization import aws_connector\n",
    "from awsPy.aws_athena import service_athena\n",
    "from awsPy.aws_s3 import service_s3\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os, shutil\n",
    "\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent)\n",
    "path_cred = r\"{}/credential_AWS.json\".format(parent_path)\n",
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = 'eu-west-3')\n",
    "\n",
    "region = 'eu-west-3'\n",
    "bucket = 'calfdata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = region)\n",
    "client= con.client_boto()\n",
    "s3 = service_s3.connect_S3(client = client,\n",
    "                      bucket = bucket, verbose = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_setting = True\n",
    "if pandas_setting:\n",
    "    cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output = 'inpi/sql_output'\n",
    "database = 'inpi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "DROP TABLE siretisation.ets_insee_inpi_list_enseigne;\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "  filename = None, ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "CREATE TABLE siretisation.ets_insee_inpi_list_enseigne\n",
    "WITH (\n",
    "  format='PARQUET'\n",
    ") AS\n",
    "SELECT \n",
    "row_id,\n",
    "siret, \n",
    "enseigne,\n",
    "list_enseigne,\n",
    "contains(\n",
    "  list_enseigne,\n",
    "  enseigne\n",
    "  ) AS list_enseigne_contain \n",
    "FROM siretisation.ets_insee_inpi\n",
    "\"\"\"\n",
    "\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "  filename = None, ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT * \n",
    "FROM siretisation.ets_insee_inpi_list_enseigne\n",
    "WHERE list_enseigne_contain IS NOT NULL\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "  filename = 'exemple', ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test acceptance\n",
    "\n",
    "1. Vérifier que le nombre de lignes est indentique avant et après la création des variables\n",
    "2. Compter le nombre de lignes pour `list_enseigne_contain`\n",
    "3. Compter le nombre d'occurences selon la cardinalité de `list_enseigne`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Vérifier que le nombre de lignes est indentique avant et après la création des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT COUNT(*)\n",
    "FROM siretisation.ets_insee_inpi_list_enseigne\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database='siretisation',\n",
    "            s3_output=s3_output,\n",
    "  filename = 'count_ets_insee_inpi', ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT COUNT(*)\n",
    "FROM siretisation.ets_insee_inpi_list_enseigne\n",
    "\"\"\"\n",
    "\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "  filename = 'test_count_enseigne', ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compter le nombre de lignes pour `list_enseigne_contain`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT list_enseigne_contain, count(*) as cnt\n",
    "       FROM siretisation.ets_insee_inpi_list_enseigne\n",
    "       GROUP BY list_enseigne_contain\n",
    "\"\"\"\n",
    "\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "  filename = 'test_count_ligne_enseigne', ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compter le nombre d'occurences selon la cardinalité de `list_enseigne`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT CARDINALITY(list_enseigne) AS cardinality, COUNT(*) as cnt\n",
    "FROM \"siretisation\".\"ets_insee_inpi_list_enseigne\"\n",
    "GROUP BY CARDINALITY(list_enseigne)\n",
    "ORDER BY cnt\n",
    "\"\"\"\n",
    "\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "  filename = 'cardinality', ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, shutil, urllib, ipykernel, json\n",
    "from pathlib import Path\n",
    "from notebook import notebookapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_report(extension = \"html\", keep_code = False):\n",
    "    \"\"\"\n",
    "    Create a report from the current notebook and save it in the \n",
    "    Report folder (Parent-> child directory)\n",
    "    \n",
    "    1. Exctract the current notbook name\n",
    "    2. Convert the Notebook \n",
    "    3. Move the newly created report\n",
    "    \n",
    "    Args:\n",
    "    extension: string. Can be \"html\", \"pdf\", \"md\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ### Get notebook name\n",
    "    connection_file = os.path.basename(ipykernel.get_connection_file())\n",
    "    kernel_id = connection_file.split('-', 1)[0].split('.')[0]\n",
    "\n",
    "    for srv in notebookapp.list_running_servers():\n",
    "        try:\n",
    "            if srv['token']=='' and not srv['password']:  \n",
    "                req = urllib.request.urlopen(srv['url']+'api/sessions')\n",
    "            else:\n",
    "                req = urllib.request.urlopen(srv['url']+ \\\n",
    "                                             'api/sessions?token=' + \\\n",
    "                                             srv['token'])\n",
    "            sessions = json.load(req)\n",
    "            notebookname = sessions[0]['name']\n",
    "        except:\n",
    "            pass  \n",
    "    \n",
    "    sep = '.'\n",
    "    path = os.getcwd()\n",
    "    #parent_path = str(Path(path).parent)\n",
    "    \n",
    "    ### Path report\n",
    "    #path_report = \"{}/Reports\".format(parent_path)\n",
    "    #path_report = \"{}/Reports\".format(path)\n",
    "    \n",
    "    ### Path destination\n",
    "    name_no_extension = notebookname.split(sep, 1)[0]\n",
    "    source_to_move = name_no_extension +'.{}'.format(extension)\n",
    "    dest = os.path.join(path,'Reports', source_to_move)\n",
    "    \n",
    "    ### Generate notebook\n",
    "    if keep_code:\n",
    "        os.system('jupyter nbconvert --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    else:\n",
    "        os.system('jupyter nbconvert --no-input --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    \n",
    "    ### Move notebook to report folder\n",
    "    #time.sleep(5)\n",
    "    shutil.move(source_to_move, dest)\n",
    "    print(\"Report Available at this adress:\\n {}\".format(dest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_report(extension = \"html\", keep_code = True)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.24.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
