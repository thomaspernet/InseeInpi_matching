{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_infos(filename):\n",
    "\n",
    "    import datetime\n",
    "    from datetime import datetime\n",
    "\n",
    "    f_s = filename.split('_')\n",
    "\n",
    "    nature_=f_s[-1].split('.')[0]\n",
    "    suborigin_ = None\n",
    "\n",
    "    date_=f_s[2]\n",
    "    year_=date_[0:4]\n",
    "    month_=date_[4:6]\n",
    "    day_=date_[6:9]\n",
    "\n",
    "    if filename.endswith('EVT.csv'):\n",
    "        nature_='ETS'\n",
    "        suborigin_ = 'EVT'\n",
    "\n",
    "    time_= f_s[3]    \n",
    "    if f_s[1].startswith('S'):\n",
    "        origin_='Stock'\n",
    "        time_='0000'\n",
    "        if str(year_) == '2017':\n",
    "            suborigin_ = 'Initial'\n",
    "        else:\n",
    "            suborigin_ = 'Partiel'\n",
    "    else :\n",
    "        origin_='Flux'\n",
    "        \n",
    "        \n",
    "    if suborigin_ is None:\n",
    "            suborigin_ ='NEW'\n",
    "\n",
    "    datetime_str=date_ + '_' + time_\n",
    "    timestamp_=datetime.strptime(datetime_str,\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    if nature_ == 'annuels':\n",
    "        nature_ = 'comptes_annuels'\n",
    "    nature_=nature_.upper()\n",
    "    \n",
    "    return (nature_,origin_,suborigin_,year_,timestamp_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dest(filename):\n",
    "    (nature_,origin_,suborigin_,year_,timestamp_) = get_file_infos(filename)\n",
    "    if origin_ == 'Flux':\n",
    "        root_path='/INPI/TC_1/01_donnee_source/Flux'\n",
    "        dest_path = \"{}/{}/{}/{}\".format(root_path,year_,nature_,suborigin_)\n",
    "    else:\n",
    "        root_path='/INPI/TC_1/01_donnee_source/Stock/Stock'\n",
    "        dest_path = \"{}_{}/{}/{}\".format(root_path,suborigin_,year_,nature_)\n",
    "    \n",
    "    return dest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ETS', 'Flux', 'EVT', '2018', datetime.datetime(2018, 1, 1, 20, 15, 23))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename='7501_122_20180101_201523_10_ets_supprime_EVT.csv'\n",
    "(nature_,origin_,suborigin_,year_,timestamp_) = (None,None,None,None,None)\n",
    "(nature_,origin_,suborigin_,year_,timestamp_) = get_file_infos(filename)\n",
    "(nature_,origin_,suborigin_,year_,timestamp_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/INPI/TC_1/01_donnee_source/Flux/2018/ETS/EVT'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_dest(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('OBS', 'Flux', 'NEW', '2018', datetime.datetime(2018, 1, 1, 20, 15, 23))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename='7501_122_20180101_201523_11_obs.csv'\n",
    "(nature_,origin_,suborigin_,year_,timestamp_) = (None,None,None,None,None)\n",
    "(nature_,origin_,suborigin_,year_,timestamp_) = get_file_infos(filename)\n",
    "(nature_,origin_,suborigin_,year_,timestamp_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/INPI/TC_1/01_donnee_source/Flux/2018/OBS/NEW'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_dest(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ETS', 'Flux', 'EVT', '2018', datetime.datetime(2018, 3, 16, 6, 32, 10))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename='3801_222_20180316_063210_9_ets_nouveau_modifie_EVT.csv'\n",
    "(nature_,origin_,suborigin_,year_,timestamp_) = (None,None,None,None,None)\n",
    "(nature_,origin_,suborigin_,year_,timestamp_) = get_file_infos(filename)\n",
    "(nature_,origin_,suborigin_,year_,timestamp_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/INPI/TC_1/01_donnee_source/Flux/2018/ETS/EVT'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_dest(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('COMPTES_ANNUELS',\n",
       " 'Stock',\n",
       " 'Initial',\n",
       " '2017',\n",
       " datetime.datetime(2017, 5, 4, 0, 0))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename='0101_S1_20170504_13_comptes_annuels.csv'\n",
    "(nature_,origin_,suborigin_,year_,timestamp_) = (None,None,None,None,None)\n",
    "(nature_,origin_,suborigin_,year_,timestamp_) = get_file_infos(filename)\n",
    "(nature_,origin_,suborigin_,year_,timestamp_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/INPI/TC_1/01_donnee_source/Stock/Stock_Initial/2017/COMPTES_ANNUELS'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_dest(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('COMPTES_ANNUELS',\n",
       " 'Stock',\n",
       " 'Partiel',\n",
       " '2019',\n",
       " datetime.datetime(2019, 5, 4, 0, 0))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename='0101_S1_20190504_13_comptes_annuels.csv'\n",
    "(nature_,origin_,suborigin_,year_,timestamp_) = (None,None,None,None,None)\n",
    "(nature_,origin_,suborigin_,year_,timestamp_) = get_file_infos(filename)\n",
    "(nature_,origin_,suborigin_,year_,timestamp_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/INPI/TC_1/01_donnee_source/Stock/Stock_Partiel/2019/COMPTES_ANNUELS'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_dest(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLUX '/INPI/TC_1/01_donnee_source/Flux/2017/ACTES/EVT/'\n",
    "# STOCK '/INPI/TC_1/01_donnee_source/Stock/Stock_initial/ACTES/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_path = 'new'\n",
    "path='temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def add_source_info(filename,source_path,dest_path = None):\n",
    "\n",
    "    source_full_path=\"{}/{}\".format(source_path,filename)\n",
    "    if dest_path:\n",
    "        if not os.path.isdir(dest_path):\n",
    "             os.mkdir(dest_path)\n",
    "    else:\n",
    "        dest_path = source_path\n",
    "    dest_full_path=\"{}/{}\".format(dest_path,filename)\n",
    "    \n",
    "    try:\n",
    "        df=pd.read_csv(source_full_path, sep=';', header=0)\n",
    "        (nature_,origin_,suborigin_,year_,timestamp_) = get_file_infos(filename)\n",
    "        df['csv_source']=filename\n",
    "        df['file_timestamp']=timestamp_\n",
    "        df['nature']=nature_\n",
    "        df['type']=origin_\n",
    "        df['origin']=suborigin_\n",
    "\n",
    "        df.to_csv(dest_full_path, index=False)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "    \n",
    "    return dest_full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] File b'temp/7501_122_20180101_201523_10_ets_supprime_EVT-checkpoint.csv' does not exist: b'temp/7501_122_20180101_201523_10_ets_supprime_EVT-checkpoint.csv'\n",
      "[Errno 2] File b'temp/3801_222_20180316_063210_9_ets_nouveau_modifie_EVT-checkpoint.csv' does not exist: b'temp/3801_222_20180316_063210_9_ets_nouveau_modifie_EVT-checkpoint.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for filename in f:\n",
    "        add_source_info(filename,path,dest_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dl/0101_S1_20170504.zip\n"
     ]
    }
   ],
   "source": [
    "# UNZIP File\n",
    "import zipfile\n",
    "zip_filename = '0101_S1_20170504.zip'\n",
    "path='dl'\n",
    "dest_path = 'dl'\n",
    "full_path = os.path.join(path, zip_filename)\n",
    "with zipfile.ZipFile(full_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNZIP All Files in directory\n",
    "import os\n",
    "\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for filename in f:\n",
    "        full_path = os.path.join(path, filename)\n",
    "        with zipfile.ZipFile(full_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(dest_path)\n",
    "            os.remove(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
