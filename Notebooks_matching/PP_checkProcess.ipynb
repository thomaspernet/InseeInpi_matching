{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aims to check example of siren on full process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, json\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import Match_inpi_insee.aws_connectors as aws\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '349599092' is in initial, partiel, new, evt\n",
    "# '344981501' is in initial, partiel, new\n",
    "# '6041099' is in initial, partiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpi_nature = 'PP' #* nature → ACTES/COMPTES/ETS/etc\n",
    "siren_test = 6041099"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_aws = 'https://calfdata.s3.eu-west-3.amazonaws.com'\n",
    "bucket = 'calfdata'\n",
    "\n",
    "# define import paths\n",
    "## INSEE\n",
    "source='insee'\n",
    "insee_csv_relative_filepath = \"INSEE/Stock/ETS/StockEtablissement_utf8.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciate AWS connection\n",
    "AWS_connection = aws.aws_instantiate(instance_aws, bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSEE : source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get files\n",
    "\n",
    "insee = AWS_connection.url_instance_bucket(path_file = insee_csv_relative_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecols_=['siren',\n",
    "                                   'siret',\n",
    "                                   \"numeroVoieEtablissement\",\n",
    "                                   \"indiceRepetitionEtablissement\",\n",
    "                                   \"typeVoieEtablissement\",\n",
    "                                   \"libelleVoieEtablissement\",\n",
    "                                   \"complementAdresseEtablissement\",\n",
    "                                   \"codeCommuneEtablissement\",\n",
    "                                   \"libelleCommuneEtablissement\",\n",
    "                                   \"codePostalEtablissement\",\n",
    "                                   \"codeCedexEtablissement\",\n",
    "                                   \"libelleCedexEtablissement\",\n",
    "                                   \"distributionSpecialeEtablissement\",\n",
    "                                   \"libelleCommuneEtrangerEtablissement\",\n",
    "                                   \"codePaysEtrangerEtablissement\",\n",
    "                                   \"libellePaysEtrangerEtablissement\"\n",
    "                                   ]\n",
    "dtype_={'siren': 'object',\n",
    "                                 'siret': 'object',\n",
    "                                 \"numeroVoieEtablissement\":'object',\n",
    "                                   \"indiceRepetitionEtablissement\":'object',\n",
    "                                   \"typeVoieEtablissement\":'object',\n",
    "                                   \"libelleVoieEtablissement\":'object',\n",
    "                                   \"complementAdresseEtablissement\":'object',\n",
    "                                   \"codeCommuneEtablissement\":'object',\n",
    "                                   \"libelleCommuneEtablissement\":'object',\n",
    "                                   \"codePostalEtablissement\":'object',\n",
    "                                   \"codeCedexEtablissement\":'object',\n",
    "                                   \"libelleCedexEtablissement\":'object',\n",
    "                                   \"distributionSpecialeEtablissement\":'object',\n",
    "                                   \"libelleCommuneEtrangerEtablissement\":'object',\n",
    "                                   \"codePaysEtrangerEtablissement\":'object',\n",
    "                                   \"libellePaysEtrangerEtablissement\":'object'\n",
    "                                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load insee full data\n",
    "\n",
    "data_insee_ = dd.read_csv(insee,\n",
    "                          usecols=usecols_,\n",
    "                          dtype=dtype_\n",
    "                          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter on example siren\n",
    "#data_insee_.compute().loc[lambda x: x['siren'].isin(siren_test)] #ko"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPI : source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_full_path = \"INPI/TC_1/Stock_processed\"\n",
    "year='2017'\n",
    "\n",
    "initial_file_name = \"{}_{}.{}\".format('initial',inpi_nature,'gz')\n",
    "new_file_name = \"{}_{}_{}.{}\".format(year,'NEW',inpi_nature.upper(),'gz')\n",
    "evt_file_name = \"{}_{}_{}.{}\".format(year,'EVT',inpi_nature.upper(),'gz')\n",
    "partiel_file_name = \"{}_{}.{}\".format('partiel',inpi_nature,'gz')\n",
    "initial_filepath = \"{}/{}\".format(import_full_path,initial_file_name)\n",
    "new_filepath = \"{}/{}\".format(import_full_path,new_file_name)\n",
    "evt_filepath = \"{}/{}\".format(import_full_path,evt_file_name)\n",
    "partiel_filepath = \"{}/{}\".format(import_full_path,partiel_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get files\n",
    "\n",
    "pp_initial = AWS_connection.url_instance_bucket(path_file = initial_filepath)\n",
    "pp_new = AWS_connection.url_instance_bucket(path_file = new_filepath)\n",
    "pp_evt = AWS_connection.url_instance_bucket(path_file = evt_filepath)\n",
    "pp_partiel = AWS_connection.url_instance_bucket(path_file = partiel_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dtypes__\n",
    "dtypes__ = {'Siren':'object',\n",
    "            'Adresse_Ligne1': 'object',\n",
    "       'Code_Commune': 'object',\n",
    "       'Code_Postal': 'object',\n",
    "       'Conjoint_Collab_Pseudo': 'object',\n",
    "       'DAP_Adresse_Ligne1': 'object',\n",
    "       'DAP_Code_Commune': 'object',\n",
    "       'Date_Immatriculation': 'object',\n",
    "       'Date_1re_Immatriculation': 'object',\n",
    "       'Date_Radiation': 'object',\n",
    "       'Date_Greffe': 'object',\n",
    "       'Sans_Activité': 'object',\n",
    "       'Auto-entrepreneur': 'object',\n",
    "       'DAP_Adresse_Ligne3': 'object',\n",
    "       'Pseudonyme': 'object'\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code Greffe</th>\n",
       "      <th>Nom_Greffe</th>\n",
       "      <th>Numero_Gestion</th>\n",
       "      <th>Siren</th>\n",
       "      <th>Type_Inscription</th>\n",
       "      <th>Date_Immatriculation</th>\n",
       "      <th>Date_1re_Immatriculation</th>\n",
       "      <th>Date_Radiation</th>\n",
       "      <th>Date_Transfert</th>\n",
       "      <th>Sans_Activité</th>\n",
       "      <th>...</th>\n",
       "      <th>DAP_Ville</th>\n",
       "      <th>DAP_Code_Commune</th>\n",
       "      <th>DAP_Pays</th>\n",
       "      <th>Conjoint_Collab_Nom_Patronym</th>\n",
       "      <th>Conjoint_Collab_Nom_Usage</th>\n",
       "      <th>Conjoint_Collab_Pseudo</th>\n",
       "      <th>Conjoint_Collab_Prénoms</th>\n",
       "      <th>Conjoint_Collab_Date_Fin</th>\n",
       "      <th>Date_Greffe</th>\n",
       "      <th>Libelle_Evt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Code Greffe, Nom_Greffe, Numero_Gestion, Siren, Type_Inscription, Date_Immatriculation, Date_1re_Immatriculation, Date_Radiation, Date_Transfert, Sans_Activité, Date_Debut_Activité, Date_Début_1re_Activité, Date_Cessation_Activité, Nom_Patronymique, Nom_Usage, Pseudonyme, Prénoms, Date_Naissance, Ville_Naissance, Pays_Naissance, Nationalité, Adresse_Ligne1, Adresse_Ligne2, Adresse_Ligne3, Code_Postal, Ville, Code_Commune, Pays, Activité_Forain, EIRL, Auto-entrepreneur, DAP, DAP_Dénomination, DAP_Objet, DAP_Date_Clôture, DAP_Adresse_Ligne1, DAP_Adresse_Ligne2, DAP_Adresse_Ligne3, DAP_Code_Postal, DAP_Ville, DAP_Code_Commune, DAP_Pays, Conjoint_Collab_Nom_Patronym, Conjoint_Collab_Nom_Usage, Conjoint_Collab_Pseudo, Conjoint_Collab_Prénoms, Conjoint_Collab_Date_Fin, Date_Greffe, Libelle_Evt]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 49 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "data_pp_initial= dd.read_csv(pp_initial,\n",
    "                         compression='gzip',\n",
    "                         dtype=dtypes__,\n",
    "                         blocksize=None,\n",
    "                         low_memory=False\n",
    "                      )\n",
    "# filter on example siren\n",
    "data_pp_initial = data_pp_initial.compute().loc[lambda x: x['Siren'].isin([siren_test])] \n",
    "data_pp_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code Greffe</th>\n",
       "      <th>Nom_Greffe</th>\n",
       "      <th>Numero_Gestion</th>\n",
       "      <th>Siren</th>\n",
       "      <th>Type_Inscription</th>\n",
       "      <th>Date_Immatriculation</th>\n",
       "      <th>Date_1re_Immatriculation</th>\n",
       "      <th>Date_Radiation</th>\n",
       "      <th>Date_Transfert</th>\n",
       "      <th>Sans_Activité</th>\n",
       "      <th>...</th>\n",
       "      <th>DAP_Ville</th>\n",
       "      <th>DAP_Code_Commune</th>\n",
       "      <th>DAP_Pays</th>\n",
       "      <th>Conjoint_Collab_Nom_Patronym</th>\n",
       "      <th>Conjoint_Collab_Nom_Usage</th>\n",
       "      <th>Conjoint_Collab_Pseudo</th>\n",
       "      <th>Conjoint_Collab_Prénoms</th>\n",
       "      <th>Conjoint_Collab_Date_Fin</th>\n",
       "      <th>Date_Greffe</th>\n",
       "      <th>Libelle_Evt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Code Greffe, Nom_Greffe, Numero_Gestion, Siren, Type_Inscription, Date_Immatriculation, Date_1re_Immatriculation, Date_Radiation, Date_Transfert, Sans_Activité, Date_Debut_Activité, Date_Début_1re_Activité, Date_Cessation_Activité, Nom_Patronymique, Nom_Usage, Pseudonyme, Prénoms, Date_Naissance, Ville_Naissance, Pays_Naissance, Nationalité, Adresse_Ligne1, Adresse_Ligne2, Adresse_Ligne3, Code_Postal, Ville, Code_Commune, Pays, Activité_Forain, EIRL, Auto-entrepreneur, DAP, DAP_Dénomination, DAP_Objet, DAP_Date_Clôture, DAP_Adresse_Ligne1, DAP_Adresse_Ligne2, DAP_Adresse_Ligne3, DAP_Code_Postal, DAP_Ville, DAP_Code_Commune, DAP_Pays, Conjoint_Collab_Nom_Patronym, Conjoint_Collab_Nom_Usage, Conjoint_Collab_Pseudo, Conjoint_Collab_Prénoms, Conjoint_Collab_Date_Fin, Date_Greffe, Libelle_Evt]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 49 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pp_new= dd.read_csv(pp_new,\n",
    "                         compression='gzip',\n",
    "                         dtype=dtypes__,\n",
    "                         blocksize=None,\n",
    "                         low_memory=False\n",
    "                      )\n",
    "\n",
    "# filter on example siren\n",
    "data_pp_new = data_pp_new.compute().loc[lambda x: x['Siren'].isin([siren_test])] \n",
    "data_pp_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mismatched dtypes found in `pd.read_csv`/`pd.read_table`.\n\n+------------+--------+----------+\n| Column     | Found  | Expected |\n+------------+--------+----------+\n| Pseudonyme | object | float64  |\n+------------+--------+----------+\n\nThe following columns also raised exceptions on conversion:\n\n- Pseudonyme\n  ValueError('could not convert string to float: \"Mo\\'Li\"',)\n\nUsually this is due to dask's dtype inference failing, and\n*may* be fixed by specifying dtypes manually by adding:\n\ndtype={'Pseudonyme': 'object'}\n\nto the call to `read_csv`/`read_table`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-e66f371239b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                       )\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# filter on example siren\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdata_pp_evt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_pp_evt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Siren'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msiren_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdata_pp_evt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/chainer_p36/lib/python3.6/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \"\"\"\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/chainer_p36/lib/python3.6/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_keys__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0mpostcomputes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/chainer_p36/lib/python3.6/site-packages/dask/threaded.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(dsk, result, cache, num_workers, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     results = get_async(pool.apply_async, len(pool._pool), dsk, result,\n\u001b[1;32m     74\u001b[0m                         \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_thread_get_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                         pack_exception=pack_exception, **kwargs)\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# Cleanup pools associated to dead threads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/chainer_p36/lib/python3.6/site-packages/dask/local.py\u001b[0m in \u001b[0;36mget_async\u001b[0;34m(apply_async, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                         \u001b[0m_execute_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Re-execute locally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                         \u001b[0mraise_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m                 \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cache'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/chainer_p36/lib/python3.6/site-packages/dask/compatibility.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(exc, tb)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/chainer_p36/lib/python3.6/site-packages/dask/local.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m         \u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/chainer_p36/lib/python3.6/site-packages/dask/local.py\u001b[0m in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0margs2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_execute_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mishashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/chainer_p36/lib/python3.6/site-packages/dask/compatibility.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(func, args, kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/chainer_p36/lib/python3.6/site-packages/dask/dataframe/io/csv.py\u001b[0m in \u001b[0;36mpandas_read_text\u001b[0;34m(reader, b, header, kwargs, dtypes, columns, write_header, enforce)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mcoerce_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0menforce\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/chainer_p36/lib/python3.6/site-packages/dask/dataframe/io/csv.py\u001b[0m in \u001b[0;36mcoerce_dtypes\u001b[0;34m(df, dtypes)\u001b[0m\n\u001b[1;32m    154\u001b[0m         msg = (\"Mismatched dtypes found in `pd.read_csv`/`pd.read_table`.\\n\\n\"\n\u001b[1;32m    155\u001b[0m                \"%s\" % (rule.join(filter(None, [dtype_msg, date_msg]))))\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Mismatched dtypes found in `pd.read_csv`/`pd.read_table`.\n\n+------------+--------+----------+\n| Column     | Found  | Expected |\n+------------+--------+----------+\n| Pseudonyme | object | float64  |\n+------------+--------+----------+\n\nThe following columns also raised exceptions on conversion:\n\n- Pseudonyme\n  ValueError('could not convert string to float: \"Mo\\'Li\"',)\n\nUsually this is due to dask's dtype inference failing, and\n*may* be fixed by specifying dtypes manually by adding:\n\ndtype={'Pseudonyme': 'object'}\n\nto the call to `read_csv`/`read_table`."
     ]
    }
   ],
   "source": [
    "data_pp_evt= dd.read_csv(pp_evt,\n",
    "                         compression='gzip',\n",
    "                         dtype=dtypes__,\n",
    "                         blocksize=None,\n",
    "                         low_memory=False\n",
    "                      )\n",
    "# filter on example siren\n",
    "data_pp_evt = data_pp_evt.compute().loc[lambda x: x['Siren'].isin([siren_test])] \n",
    "data_pp_evt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pp_partiel= dd.read_csv(pp_partiel,\n",
    "                         compression='gzip',\n",
    "                         dtype=dtypes__,\n",
    "                         blocksize=None,\n",
    "                         low_memory=False\n",
    "                      )\n",
    "# filter on example siren\n",
    "data_pp_partiel = data_pp_partiel.compute().loc[lambda x: x['Siren'].isin([siren_test])] \n",
    "data_pp_partiel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIRETISATION : matched data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matched data\n",
    "# define import paths\n",
    "import_path = 'SIRETISATION/matche'\n",
    "gz_filename = 'insee_PP_all_matche.gz'\n",
    "full_filename =  \"{}/{}\".format(import_path,gz_filename) #'SIRETISATION/matche/insee_PP_all_matche.gz'\n",
    "\n",
    "# get files\n",
    "matche = AWS_connection.url_instance_bucket(path_file = full_filename)\n",
    "\n",
    "#load matched data\n",
    "data_matche= dd.read_csv(matche,\n",
    "                         compression='gzip',\n",
    "                         dtype=dtypes__,\n",
    "                         blocksize=None,\n",
    "                         low_memory=False\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter on example siren\n",
    "data_matche = data_matche.compute().loc[lambda x: x['siren'].isin([siren_test])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siren</th>\n",
       "      <th>siret</th>\n",
       "      <th>statutDiffusionEtablissement</th>\n",
       "      <th>Date_Immatriculation</th>\n",
       "      <th>Date_1re_Immatriculation</th>\n",
       "      <th>Date_Radiation</th>\n",
       "      <th>Sans_Activité</th>\n",
       "      <th>Adresse_Ligne1</th>\n",
       "      <th>Code_Postal</th>\n",
       "      <th>Code_Commune</th>\n",
       "      <th>DAP_Adresse_Ligne1</th>\n",
       "      <th>DAP_Code_Commune</th>\n",
       "      <th>Conjoint_Collab_Pseudo</th>\n",
       "      <th>Date_Greffe</th>\n",
       "      <th>_merge</th>\n",
       "      <th>url</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>6041099</td>\n",
       "      <td>604109900018</td>\n",
       "      <td>O</td>\n",
       "      <td>1960-05-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>both</td>\n",
       "      <td>https://data.inpi.fr/entreprises/006041099</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>6041099</td>\n",
       "      <td>604109900026</td>\n",
       "      <td>O</td>\n",
       "      <td>1960-05-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>both</td>\n",
       "      <td>https://data.inpi.fr/entreprises/006041099</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>6041099</td>\n",
       "      <td>604109900034</td>\n",
       "      <td>O</td>\n",
       "      <td>1960-05-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>both</td>\n",
       "      <td>https://data.inpi.fr/entreprises/006041099</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>6041099</td>\n",
       "      <td>604109900018</td>\n",
       "      <td>O</td>\n",
       "      <td>1960-05-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-17</td>\n",
       "      <td>both</td>\n",
       "      <td>https://data.inpi.fr/entreprises/006041099</td>\n",
       "      <td>partiel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>6041099</td>\n",
       "      <td>604109900026</td>\n",
       "      <td>O</td>\n",
       "      <td>1960-05-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-17</td>\n",
       "      <td>both</td>\n",
       "      <td>https://data.inpi.fr/entreprises/006041099</td>\n",
       "      <td>partiel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>6041099</td>\n",
       "      <td>604109900034</td>\n",
       "      <td>O</td>\n",
       "      <td>1960-05-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-17</td>\n",
       "      <td>both</td>\n",
       "      <td>https://data.inpi.fr/entreprises/006041099</td>\n",
       "      <td>partiel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       siren         siret statutDiffusionEtablissement Date_Immatriculation  \\\n",
       "196  6041099  604109900018                            O           1960-05-24   \n",
       "197  6041099  604109900026                            O           1960-05-24   \n",
       "198  6041099  604109900034                            O           1960-05-24   \n",
       "199  6041099  604109900018                            O           1960-05-24   \n",
       "200  6041099  604109900026                            O           1960-05-24   \n",
       "201  6041099  604109900034                            O           1960-05-24   \n",
       "\n",
       "    Date_1re_Immatriculation Date_Radiation Sans_Activité Adresse_Ligne1  \\\n",
       "196                      NaN            NaN           NaN            NaN   \n",
       "197                      NaN            NaN           NaN            NaN   \n",
       "198                      NaN            NaN           NaN            NaN   \n",
       "199                      NaN            NaN           NaN            NaN   \n",
       "200                      NaN            NaN           NaN            NaN   \n",
       "201                      NaN            NaN           NaN            NaN   \n",
       "\n",
       "    Code_Postal Code_Commune DAP_Adresse_Ligne1 DAP_Code_Commune  \\\n",
       "196       04120          NaN                NaN              NaN   \n",
       "197       04120          NaN                NaN              NaN   \n",
       "198       04120          NaN                NaN              NaN   \n",
       "199       04120          NaN                NaN              NaN   \n",
       "200       04120          NaN                NaN              NaN   \n",
       "201       04120          NaN                NaN              NaN   \n",
       "\n",
       "    Conjoint_Collab_Pseudo Date_Greffe _merge  \\\n",
       "196                    NaN  2009-01-01   both   \n",
       "197                    NaN  2009-01-01   both   \n",
       "198                    NaN  2009-01-01   both   \n",
       "199                    NaN  2018-05-17   both   \n",
       "200                    NaN  2018-05-17   both   \n",
       "201                    NaN  2018-05-17   both   \n",
       "\n",
       "                                            url   source  \n",
       "196  https://data.inpi.fr/entreprises/006041099  initial  \n",
       "197  https://data.inpi.fr/entreprises/006041099  initial  \n",
       "198  https://data.inpi.fr/entreprises/006041099  initial  \n",
       "199  https://data.inpi.fr/entreprises/006041099  partiel  \n",
       "200  https://data.inpi.fr/entreprises/006041099  partiel  \n",
       "201  https://data.inpi.fr/entreprises/006041099  partiel  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_matche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_chainer_p36",
   "language": "python",
   "name": "conda_chainer_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
