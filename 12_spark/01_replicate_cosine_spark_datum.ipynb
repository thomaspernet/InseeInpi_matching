{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repliquer calcul cosine en Spark\n",
    "\n",
    "# Objective(s)\n",
    "\n",
    "Repliquer le code du calcul de la distance entre 2 listes de mots en Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.types import StructType, ArrayType, StringType, FloatType, MapType\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.mllib.linalg import DenseVector, Vectors, VectorUDT\n",
    "\n",
    "spark = (SparkSession \n",
    "    .builder \n",
    "    .appName(\"Python Spark SQL basic example\") \n",
    "    .config('spark.executor.memory', '4G') \n",
    "    .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.sql.debug.maxToStringFields\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'row_id': 5,\n",
       "  'inpi_except': ['RUE', 'CHARLES', 'GILLE'],\n",
       "  'insee_except': ['BOULEVARD', 'PREUILLY']},\n",
       " {'row_id': 7, 'inpi_except': ['JB'], 'insee_except': ['JEAN', 'BAPTISTE']},\n",
       " {'row_id': 8, 'inpi_except': ['JB'], 'insee_except': ['JEAN', 'BAPTISTE']},\n",
       " {'row_id': 10,\n",
       "  'inpi_except': ['MARCELIN', 'BERTHELOT', 'CENTRE', 'D', 'ENTREPRISES'],\n",
       "  'insee_except': ['PROSPER', 'LEGOUTE']},\n",
       " {'row_id': 12,\n",
       "  'inpi_except': ['CHEMIN', 'BEL', 'AIR'],\n",
       "  'insee_except': ['RUE', 'VICTOR', 'HUGO']},\n",
       " {'row_id': 19,\n",
       "  'inpi_except': ['A', 'E'],\n",
       "  'insee_except': ['AIME', 'EUGENIE', 'ZI', 'NORD']},\n",
       " {'row_id': 21, 'inpi_except': ['ST'], 'insee_except': ['SAINT']},\n",
       " {'row_id': 23,\n",
       "  'inpi_except': ['LOTISSEMENT', 'N'],\n",
       "  'insee_except': ['BOULEVARD', 'RAYMOND', 'POINCARE', 'PALAIS', 'ORIENTAL']},\n",
       " {'row_id': 24,\n",
       "  'inpi_except': ['LOTISSEMENT', 'N'],\n",
       "  'insee_except': ['PLACE', 'AMIRAL', 'ORTOLI']},\n",
       " {'row_id': 25,\n",
       "  'inpi_except': ['RUE', 'FURSANNES'],\n",
       "  'insee_except': ['COLLINE']}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('test_cosine_inpi_insee_clean.json') as f:\n",
    "    data = json.load(f)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recupération premier ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = data[0]['row_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = 'word2vec_weights_100_v2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RUE',\n",
       " 'CHARLES',\n",
       " 'GILLE',\n",
       " 'BOULEVARD',\n",
       " 'PREUILLY',\n",
       " 'JB',\n",
       " 'JEAN',\n",
       " 'BAPTISTE',\n",
       " 'JB',\n",
       " 'JEAN',\n",
       " 'BAPTISTE',\n",
       " 'MARCELIN',\n",
       " 'BERTHELOT',\n",
       " 'CENTRE',\n",
       " 'D',\n",
       " 'ENTREPRISES',\n",
       " 'PROSPER',\n",
       " 'LEGOUTE',\n",
       " 'CHEMIN',\n",
       " 'BEL',\n",
       " 'AIR',\n",
       " 'RUE',\n",
       " 'VICTOR',\n",
       " 'HUGO',\n",
       " 'A',\n",
       " 'E',\n",
       " 'AIME',\n",
       " 'EUGENIE',\n",
       " 'ZI',\n",
       " 'NORD',\n",
       " 'ST',\n",
       " 'SAINT',\n",
       " 'LOTISSEMENT',\n",
       " 'N',\n",
       " 'BOULEVARD',\n",
       " 'RAYMOND',\n",
       " 'POINCARE',\n",
       " 'PALAIS',\n",
       " 'ORIENTAL',\n",
       " 'LOTISSEMENT',\n",
       " 'N',\n",
       " 'PLACE',\n",
       " 'AMIRAL',\n",
       " 'ORTOLI',\n",
       " 'RUE',\n",
       " 'FURSANNES',\n",
       " 'COLLINE']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_keep = []\n",
    "for i in data:\n",
    "    words_to_keep.extend(i['inpi_except'])\n",
    "    words_to_keep.extend(i['insee_except'])\n",
    "words_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(path_list).loc[lambda x: x['0'].isin(words_to_keep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 101)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_json('word2vec_weights_100_v2.json',orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "schema  = (\n",
    "    StructType()\n",
    "    .add('words', StringType(),True)\n",
    "    .add(\"list_weigths\", ArrayType(FloatType(), True))\n",
    ")\n",
    "\n",
    "cols = [str(i) for i in range(1, 101)]\n",
    "weights = (spark.read.csv(path_list, header = True)\n",
    "           .select('0',(F.array(cols)).cast(ArrayType(FloatType(), True)).alias('list_weights'))\n",
    "           .withColumnRenamed(\"0\",\"words\")\n",
    "          )\n",
    "weights.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul Cosine depuis deux listes en Spark 3.0\n",
    "\n",
    "Comme la fonction du cosine est assez simple, il n'y a pas besoin de créer une fonction (et le décorateur). Une fonction lambda est amplement suffisante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine = F.udf(lambda x, y: \n",
    "               (np.dot(x, y)/ (np.linalg.norm(x) * np.linalg.norm(y))).item(),\n",
    "               FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = (\n",
    "    df\n",
    "    .filter(\"row_id = {}\".format(test_id))\n",
    "    .select(\n",
    "        'row_id',\n",
    "        F.expr(\n",
    "        \"\"\"\n",
    "explode(\n",
    "map_from_entries(    \n",
    " arrays_zip(\n",
    "  inpi_except, \n",
    "  transform(\n",
    "    sequence(\n",
    "      1, \n",
    "      size(inpi_except)\n",
    "    ), \n",
    "    x -> insee_except\n",
    "    )\n",
    "    )\n",
    "  )\n",
    ")\n",
    "      \"\"\"\n",
    "                        )\n",
    "         .alias(\"inpi\", \"value\")\n",
    "    )\n",
    "       \n",
    "    .select(\n",
    "        'row_id',\n",
    "        \"inpi\",\n",
    "        F.explode_outer(\"value\")\n",
    "        .alias(\"insee\")\n",
    "   )\n",
    "    .join((weights.withColumnRenamed(\"words\",\"inpi\")),\n",
    "        on = ['inpi'], how = 'left')\n",
    "    .withColumnRenamed(\"list_weights\",\"list_weights_inpi\")\n",
    "    .join((weights.withColumnRenamed(\"words\",\"insee\")),\n",
    "       on = ['insee'], how = 'left')\n",
    "    .withColumnRenamed(\"list_weights\",\"list_weights_insee\")\n",
    "    .select('row_id',\n",
    "            'inpi',\n",
    "            'insee',\n",
    "            \"list_weights_inpi\",\n",
    "            \"list_weights_insee\",\n",
    "            cosine(\"list_weights_inpi\", \"list_weights_insee\").alias(\"cosine\"),\n",
    "           )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.show(truncate = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul Cosine depuis deux listes en Spark, version < 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_a = [\"RUE\", \"CHARLES\", \"GILLE\"]\n",
    "list_b = [\"BOULEVARD\", \"PREUILLY\"]\n",
    "\n",
    "test_list =[dict(zip([i], [list_b])) for i in list_a]\n",
    "test_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "udf pour remplacer `explode(map_from_entries(arrays_zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_except = F.udf(lambda x, y: [dict(zip([i], [y])) for i in x],\n",
    "                   ArrayType(MapType(StringType(), ArrayType(StringType()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine = F.udf(lambda x, y: \n",
    "               (np.dot(x, y)/ (np.linalg.norm(x) * np.linalg.norm(y))).item(),\n",
    "               FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = (\n",
    "    df\n",
    "    .filter(\"row_id = {}\".format(test_id))\n",
    "    .select(\n",
    "        'row_id',\n",
    "        'inpi_except',\n",
    "        'insee_except',\n",
    "        F.explode(zip_except(\"inpi_except\",\"insee_except\")).alias(\"zip_except\")\n",
    "    )\n",
    "    .select(\n",
    "    'row_id',\n",
    "        'inpi_except',\n",
    "        'insee_except',\n",
    "        F.explode(\"zip_except\").alias(\"inpi\", \"value\")\n",
    "    )\n",
    "    .select(\n",
    "    'row_id',\n",
    "        'inpi_except',\n",
    "        'insee_except',\n",
    "        'inpi',\n",
    "         F.explode(\"value\")\n",
    "        .alias(\"insee\")\n",
    "    )\n",
    "    .join((weights.withColumnRenamed(\"words\",\"inpi\")),\n",
    "        on = ['inpi'], how = 'left')\n",
    "    .withColumnRenamed(\"list_weights\",\"list_weights_inpi\")\n",
    "    .join((weights.withColumnRenamed(\"words\",\"insee\")),\n",
    "       on = ['insee'], how = 'left')\n",
    "    .withColumnRenamed(\"list_weights\",\"list_weights_insee\")\n",
    "    .select('row_id',\n",
    "            'inpi',\n",
    "            'insee',\n",
    "            \"list_weights_inpi\",\n",
    "            \"list_weights_insee\",\n",
    "            cosine(\"list_weights_inpi\", \"list_weights_insee\").alias(\"cosine\"),\n",
    "           )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.show(truncate =True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
