{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repliquer calcul cosine en Spark\n",
    "\n",
    "# Objective(s)\n",
    "\n",
    "Repliquer le code du calcul de la distance entre 2 listes de mots en Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.types import StructType, ArrayType, StringType, FloatType, MapType\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.mllib.linalg import DenseVector, Vectors, VectorUDT\n",
    "\n",
    "spark = (SparkSession \n",
    "    .builder \n",
    "    .appName(\"Python Spark SQL basic example\") \n",
    "    .config('spark.executor.memory', '4G') \n",
    "    .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.sql.debug.maxToStringFields\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'row_id': 5,\n",
       "  'inpi_except': ['RUE', 'CHARLES', 'GILLE'],\n",
       "  'insee_except': ['BOULEVARD', 'PREUILLY']},\n",
       " {'row_id': 7, 'inpi_except': ['JB'], 'insee_except': ['JEAN', 'BAPTISTE']},\n",
       " {'row_id': 8, 'inpi_except': ['JB'], 'insee_except': ['JEAN', 'BAPTISTE']},\n",
       " {'row_id': 10,\n",
       "  'inpi_except': ['MARCELIN', 'BERTHELOT', 'CENTRE', 'D', 'ENTREPRISES'],\n",
       "  'insee_except': ['PROSPER', 'LEGOUTE']},\n",
       " {'row_id': 12,\n",
       "  'inpi_except': ['CHEMIN', 'BEL', 'AIR'],\n",
       "  'insee_except': ['RUE', 'VICTOR', 'HUGO']},\n",
       " {'row_id': 19,\n",
       "  'inpi_except': ['A', 'E'],\n",
       "  'insee_except': ['AIME', 'EUGENIE', 'ZI', 'NORD']},\n",
       " {'row_id': 21, 'inpi_except': ['ST'], 'insee_except': ['SAINT']},\n",
       " {'row_id': 23,\n",
       "  'inpi_except': ['LOTISSEMENT', 'N'],\n",
       "  'insee_except': ['BOULEVARD', 'RAYMOND', 'POINCARE', 'PALAIS', 'ORIENTAL']},\n",
       " {'row_id': 24,\n",
       "  'inpi_except': ['LOTISSEMENT', 'N'],\n",
       "  'insee_except': ['PLACE', 'AMIRAL', 'ORTOLI']},\n",
       " {'row_id': 25,\n",
       "  'inpi_except': ['RUE', 'FURSANNES'],\n",
       "  'insee_except': ['COLLINE']}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('test_cosine_inpi_insee_clean.json') as f:\n",
    "    data = json.load(f)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recupération premier ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = data[0]['row_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PERNETTH\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pyspark\\sql\\session.py:381: UserWarning: inferring schema from dict is deprecated,please use pyspark.sql.Row instead\n",
      "  warnings.warn(\"inferring schema from dict is deprecated,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- inpi_except: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- insee_except: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- row_id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(inpi_except=['RUE', 'CHARLES', 'GILLE'], insee_except=['BOULEVARD', 'PREUILLY'], row_id=5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('words', 'string'), ('list_weights', 'array<float>')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_list = 'word2vec_weights_100_v2.csv'\n",
    "schema  = (\n",
    "    StructType()\n",
    "    .add('words', StringType(),True)\n",
    "    .add(\"list_weigths\", ArrayType(FloatType(), True))\n",
    ")\n",
    "\n",
    "cols = [str(i) for i in range(1, 101)]\n",
    "weights = (spark.read.csv(path_list, header = True)\n",
    "           .select('0',(F.array(cols)).cast(ArrayType(FloatType(), True)).alias('list_weights'))\n",
    "           .withColumnRenamed(\"0\",\"words\")\n",
    "          )\n",
    "weights.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|    words|        list_weights|\n",
      "+---------+--------------------+\n",
      "|      RUE|[-0.86694837, -0....|\n",
      "|   AVENUE|[-2.206969, -0.84...|\n",
      "|    ROUTE|[0.75751305, -0.2...|\n",
      "|   CHEMIN|[-0.33908606, 0.7...|\n",
      "|        D|[1.1837989, -1.35...|\n",
      "|        L|[-1.9471866, -0.5...|\n",
      "|BOULEVARD|[-1.4547851, 0.14...|\n",
      "|    PLACE|[-0.21757227, 0.1...|\n",
      "|      BIS|[0.76434, -0.1137...|\n",
      "|    SAINT|[0.7002688, -2.22...|\n",
      "|     LIEU|[-0.5478822, 1.27...|\n",
      "|      DIT|[-1.040085, -0.21...|\n",
      "|        A|[-1.2238628, -0.0...|\n",
      "|     ZONE|[-1.985939, -1.25...|\n",
      "|        B|[-0.30842575, 0.0...|\n",
      "|    ALLEE|[-0.8832805, -2.1...|\n",
      "|     JEAN|[-2.4126835, 1.26...|\n",
      "|   CENTRE|[-3.6606867, -4.1...|\n",
      "|RESIDENCE|[-0.3581616, -0.9...|\n",
      "|      BAT|[-1.2430978, 0.25...|\n",
      "+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul Cosine depuis deux listes en Spark 3.0\n",
    "\n",
    "Comme la fonction du cosine est assez simple, il n'y a pas besoin de créer une fonction (et le décorateur). Une fonction lambda est amplement suffisante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine = F.udf(lambda x, y: \n",
    "               (np.dot(x, y)/ (np.linalg.norm(x) * np.linalg.norm(y))).item(),\n",
    "               FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = (\n",
    "    df\n",
    "    .filter(\"row_id = {}\".format(test_id))\n",
    "    .select(\n",
    "        'row_id',\n",
    "        F.expr(\n",
    "        \"\"\"\n",
    "explode(\n",
    "map_from_entries(    \n",
    " arrays_zip(\n",
    "  inpi_except, \n",
    "  transform(\n",
    "    sequence(\n",
    "      1, \n",
    "      size(inpi_except)\n",
    "    ), \n",
    "    x -> insee_except\n",
    "    )\n",
    "    )\n",
    "  )\n",
    ")\n",
    "      \"\"\"\n",
    "                        )\n",
    "         .alias(\"inpi\", \"value\")\n",
    "    )\n",
    "       \n",
    "    .select(\n",
    "        'row_id',\n",
    "        \"inpi\",\n",
    "        F.explode_outer(\"value\")\n",
    "        .alias(\"insee\")\n",
    "   )\n",
    "    .join((weights.withColumnRenamed(\"words\",\"inpi\")),\n",
    "        on = ['inpi'], how = 'left')\n",
    "    .withColumnRenamed(\"list_weights\",\"list_weights_inpi\")\n",
    "    .join((weights.withColumnRenamed(\"words\",\"insee\")),\n",
    "       on = ['insee'], how = 'left')\n",
    "    .withColumnRenamed(\"list_weights\",\"list_weights_insee\")\n",
    "    .select('row_id',\n",
    "            'inpi',\n",
    "            'insee',\n",
    "            \"list_weights_inpi\",\n",
    "            \"list_weights_insee\",\n",
    "            cosine(\"list_weights_inpi\", \"list_weights_insee\").alias(\"cosine\"),\n",
    "           )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+---------+--------------------+--------------------+-----------+\n",
      "|row_id|   inpi|    insee|   list_weights_inpi|  list_weights_insee|     cosine|\n",
      "+------+-------+---------+--------------------+--------------------+-----------+\n",
      "|     5|    RUE|BOULEVARD|[-0.86694837, -0....|[-1.4547851, 0.14...| 0.40306154|\n",
      "|     5|    RUE| PREUILLY|[-0.86694837, -0....|[0.026656773, -0....|0.096528575|\n",
      "|     5|CHARLES|BOULEVARD|[-1.1762805, -0.5...|[-1.4547851, 0.14...| 0.09133629|\n",
      "|     5|CHARLES| PREUILLY|[-1.1762805, -0.5...|[0.026656773, -0....| 0.10189664|\n",
      "|     5|  GILLE|BOULEVARD|[0.34494784, -0.2...|[-1.4547851, 0.14...| 0.03590281|\n",
      "|     5|  GILLE| PREUILLY|[0.34494784, -0.2...|[0.026656773, -0....| 0.22824264|\n",
      "+------+-------+---------+--------------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show(truncate = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul Cosine depuis deux listes en Spark, version < 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'RUE': ['BOULEVARD', 'PREUILLY']},\n",
       " {'CHARLES': ['BOULEVARD', 'PREUILLY']},\n",
       " {'GILLE': ['BOULEVARD', 'PREUILLY']}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_a = [\"RUE\", \"CHARLES\", \"GILLE\"]\n",
    "list_b = [\"BOULEVARD\", \"PREUILLY\"]\n",
    "\n",
    "test_list =[dict(zip([i], [list_b])) for i in list_a]\n",
    "test_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "udf pour remplacer `explode(map_from_entries(arrays_zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_except = F.udf(lambda x, y: [dict(zip([i], [y])) for i in x],\n",
    "                   ArrayType(MapType(StringType(), ArrayType(StringType()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine = F.udf(lambda x, y: \n",
    "               (np.dot(x, y)/ (np.linalg.norm(x) * np.linalg.norm(y))).item(),\n",
    "               FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = (\n",
    "    df\n",
    "    .filter(\"row_id = {}\".format(test_id))\n",
    "    .select(\n",
    "        'row_id',\n",
    "        'inpi_except',\n",
    "        'insee_except',\n",
    "        F.explode(zip_except(\"inpi_except\",\"insee_except\")).alias(\"zip_except\")\n",
    "    )\n",
    "    .select(\n",
    "    'row_id',\n",
    "        'inpi_except',\n",
    "        'insee_except',\n",
    "        F.explode(\"zip_except\").alias(\"inpi\", \"value\")\n",
    "    )\n",
    "    .select(\n",
    "    'row_id',\n",
    "        'inpi_except',\n",
    "        'insee_except',\n",
    "        'inpi',\n",
    "         F.explode(\"value\")\n",
    "        .alias(\"insee\")\n",
    "    )\n",
    "    .join((weights.withColumnRenamed(\"words\",\"inpi\")),\n",
    "        on = ['inpi'], how = 'left')\n",
    "    .withColumnRenamed(\"list_weights\",\"list_weights_inpi\")\n",
    "    .join((weights.withColumnRenamed(\"words\",\"insee\")),\n",
    "       on = ['insee'], how = 'left')\n",
    "    .withColumnRenamed(\"list_weights\",\"list_weights_insee\")\n",
    "    .select('row_id',\n",
    "            'inpi',\n",
    "            'insee',\n",
    "            \"list_weights_inpi\",\n",
    "            \"list_weights_insee\",\n",
    "            cosine(\"list_weights_inpi\", \"list_weights_insee\").alias(\"cosine\"),\n",
    "           )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+---------+--------------------+--------------------+-----------+\n",
      "|row_id|   inpi|    insee|   list_weights_inpi|  list_weights_insee|     cosine|\n",
      "+------+-------+---------+--------------------+--------------------+-----------+\n",
      "|     5|    RUE|BOULEVARD|[-0.86694837, -0....|[-1.4547851, 0.14...| 0.40306154|\n",
      "|     5|    RUE| PREUILLY|[-0.86694837, -0....|[0.026656773, -0....|0.096528575|\n",
      "|     5|CHARLES|BOULEVARD|[-1.1762805, -0.5...|[-1.4547851, 0.14...| 0.09133629|\n",
      "|     5|CHARLES| PREUILLY|[-1.1762805, -0.5...|[0.026656773, -0....| 0.10189664|\n",
      "|     5|  GILLE|BOULEVARD|[0.34494784, -0.2...|[-1.4547851, 0.14...| 0.03590281|\n",
      "|     5|  GILLE| PREUILLY|[0.34494784, -0.2...|[0.026656773, -0....| 0.22824264|\n",
      "+------+-------+---------+--------------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show(truncate =True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
