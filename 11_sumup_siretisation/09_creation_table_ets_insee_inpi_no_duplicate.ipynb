{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation table INSEE INPI sans doublon\n",
    "\n",
    "# Objective(s)\n",
    "\n",
    "* Dans cette dernière étape, il suffit de récupérer le rang minimum de la table ets_insee_inpi_regle par index_id. En récupérant le minimum, la technique retourne la ligne la plus probable par rapport aux autres informations fournies par l'INSEE. AUtrement dit, nous avons récupéré la ligne qui satisfaient le plus de condition. Il est possible d'avoir encore des doublons, qui résultent d'une mauvaise préparation de la donnée ou d'une impossibilité de dédoubler le siret.\n",
    "\n",
    "# Metadata\n",
    "\n",
    "* Epic: Epic 6\n",
    "* US: US 7\n",
    "* Date Begin: 9/29/2020\n",
    "* Duration Task: 0\n",
    "* Description: récupérer le rang minimum de la table ets_insee_inpi_regle par index_id.\n",
    "* Step type: Final table\n",
    "* Status: Active\n",
    "  * Change Status task: Active\n",
    "  * Update table: Modify rows\n",
    "* Source URL: US 07 Dedoublonnement\n",
    "* Task type: Jupyter Notebook\n",
    "* Users: Thomas Pernet\n",
    "* Watchers: Thomas Pernet\n",
    "* User Account: https://937882855452.signin.aws.amazon.com/console\n",
    "* Estimated Log points: 5\n",
    "* Task tag: #athena,#lookup-table,#sql,#remove-duplicate,#siretisation,#inpi,#siren,#siret,#insee,#documentation\n",
    "* Toggl Tag: #documentation\n",
    "\n",
    "# Input Cloud Storage [AWS/GCP]\n",
    "\n",
    "## Table/file\n",
    "\n",
    "* Origin: \n",
    "* Athena\n",
    "* Name: \n",
    "* ets_insee_inpi_regle\n",
    "* Github: \n",
    "  * https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/11_sumup_siretisation/08_creation_table_match_regles_gestion_insee_inpi.md\n",
    "\n",
    "# Destination Output/Delivery\n",
    "\n",
    "## Table/file\n",
    "\n",
    "* Origin: \n",
    "* Athena\n",
    "* Name:\n",
    "* ets_insee_inpi_no_duplicate\n",
    "* GitHub:\n",
    "* https://github.com/thomaspernet/InseeInpi_matching/blob/master/Notebooks_matching/Data_preprocessed/programme_matching/11_sumup_siretisation/09_creation_table_ets_insee_inpi_no_duplicate.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connexion serveur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awsPy.aws_authorization import aws_connector\n",
    "from awsPy.aws_s3 import service_s3\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os, shutil\n",
    "\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent)\n",
    "path_cred = r\"{}/credential_AWS.json\".format(parent_path)\n",
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = 'eu-west-3')\n",
    "\n",
    "region = 'eu-west-3'\n",
    "bucket = 'calfdata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = region)\n",
    "client= con.client_boto()\n",
    "s3 = service_s3.connect_S3(client = client,\n",
    "                      bucket = bucket, verbose = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_setting = True\n",
    "if pandas_setting:\n",
    "    cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Le rapprochement entre les deux tables, à savoir l’INSEE et l’INPI, va amener à la création de deux vecteurs d’adresse. Un vecteur avec des mots contenus spécifiquement à l’INSEE, et un second vecteur avec les mots de l’adresse de l’INPI. Notre objectif est de comparé ses deux vecteurs pour définir si ils sont identiques ou non. Nous avons distingué 7 cas de figures possibles entre les deux vecteurs (figure 1).\n",
    "\n",
    "![](https://scm.saas.cagip.group.gca/PERNETTH/inseeinpi_matching/-/raw/master/IMAGES/11_cas_de_figure.jpeg)\n",
    "\n",
    "A partir de la, nous avons créé une matrice de règles de gestion, puis créer lesdites règles selon les informations de l'INSEE et de l'INPI.\n",
    "\n",
    "Dans cette matrice, chacune des lignes vient par ordre croissant, c'est a dire que la ligne 1 est préférée à la ligne 2\n",
    "\n",
    "Le tableau ci dessous récapitule les règles:\n",
    "\n",
    "\n",
    "| Rang | Nom_variable                              | Dependence                                    | Notebook                           | Difficulte | Table_input                                                                                                                                                            | Variables_crees_US                                                                 | Possibilites                  |\n",
    "|------|-------------------------------------------|-----------------------------------------------|------------------------------------|------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------|-------------------------------|\n",
    "| 1    | status_cas                                |                                               | 02_cas_de_figure                   | Moyen      | ets_insee_inpi_status_cas                                                                                                                                              | status_cas,intersection,pct_intersection,union_,inpi_except,insee_except           | CAS_1,CAS_2,CAS_3,CAS_4,CAS_5 |\n",
    "| 2    | test_list_num_voie                        | intersection_numero_voie,union_numero_voie    | 03_test_list_num_voie              | Moyen      | ets_insee_inpi_list_num_voie                                                                                                                                           | intersection_numero_voie,union_numero_voie                                         | FALSE,NULL,TRUE,PARTIAL       |\n",
    "| 3    | test_enseigne                             | list_enseigne,enseigne                        | 04_test_enseigne                   | Moyen      | ets_insee_inpi_list_enseigne                                                                                                                                           | list_enseigne_contain                                                              | FALSE,NULL,TRUE               |\n",
    "| 4    | test_pct_intersection                     | pct_intersection,index_id_max_intersection    | 06_creation_nb_siret_siren_max_pct | Facile     | ets_insee_inpi_var_group_max                                                                                                                                           | count_inpi_index_id_siret,count_inpi_siren_siret,index_id_max_intersection         | FALSE,TRUE                    |\n",
    "| 4    | test_index_id_duplicate                   | count_inpi_index_id_siret                     | 06_creation_nb_siret_siren_max_pct | Facile     | ets_insee_inpi_var_group_max                                                                                                                                           | count_inpi_index_id_siret,count_inpi_siren_siret,index_id_max_intersection         | FALSE,TRUE                    |\n",
    "| 4    | test_siren_insee_siren_inpi               | count_initial_insee,count_inpi_siren_siret    | 06_creation_nb_siret_siren_max_pct | Facile     | ets_insee_inpi_var_group_max                                                                                                                                           | count_inpi_index_id_siret,count_inpi_siren_siret,index_id_max_intersection         | FALSE,TRUE                    |\n",
    "| 5    | test_similarite_exception_words           | max_cosine_distance                           | 08_calcul_cosine_levhenstein       | Difficile  | ets_insee_inpi_similarite_max_word2vec                                                                                                                                 | unzip_inpi,unzip_insee,max_cosine_distance,levenshtein_distance,key_except_to_test | FALSE,NULL,TRUE               |\n",
    "| 5    | test_distance_levhenstein_exception_words | levenshtein_distance                          | 08_calcul_cosine_levhenstein       | Difficile  | ets_insee_inpi_similarite_max_word2vec                                                                                                                                 | unzip_inpi,unzip_insee,max_cosine_distance,levenshtein_distance,key_except_to_test | FALSE,NULL,TRUE               |\n",
    "| 6    | test_date                                 | datecreationetablissement,date_debut_activite | 10_match_et_creation_regles.md     | Facile     | ets_insee_inpi_list_num_voie,ets_insee_inpi_list_enseigne,ets_insee_inpi_similarite_max_word2vec,ets_insee_inpi_status_cas,ets_insee_inpi_var_group_max,ets_insee_inpi |                                                                                    | FALSE,TRUE                    |\n",
    "| 6    | test_siege                                | status_ets,etablissementsiege                 | 10_match_et_creation_regles.md     | Facile     | ets_insee_inpi_list_num_voie,ets_insee_inpi_list_enseigne,ets_insee_inpi_similarite_max_word2vec,ets_insee_inpi_status_cas,ets_insee_inpi_var_group_max,ets_insee_inpi |                                                                                    | FALSE,TRUE,NULL               |\n",
    "| 6    | test_status_admin                         | etatadministratifetablissement,status_admin   | 10_match_et_creation_regles.md     | Facile     | ets_insee_inpi_list_num_voie,ets_insee_inpi_list_enseigne,ets_insee_inpi_similarite_max_word2vec,ets_insee_inpi_status_cas,ets_insee_inpi_var_group_max,ets_insee_inpi |                                                                                    | FALSE,NULL,TRUE               |\n",
    "\n",
    "Dans cette dernière étape, il suffit de récupérer le rang minimum de la table `ets_insee_inpi_regle` par `index_id`. En récupérant le minimum, la technique retourne la ligne la plus probable par rapport aux autres informations fournies par l'INSEE. AUtrement dit, nous avons récupéré la ligne qui satisfaient le plus de condition. Il est possible d'avoir encore des doublons, qui résultent d'une mauvaise préparation de la donnée ou d'une impossibilité de dédoubler le siret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output = 'SQL_OUTPUT_ATHENA'\n",
    "database = 'ets_siretisation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "DROP TABLE ets_siretisation.ets_insee_inpi_no_duplicate;\n",
    "\"\"\"\n",
    "\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "  filename = None, ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "CREATE TABLE ets_siretisation.ets_insee_inpi_no_duplicate\n",
    "WITH (\n",
    "  format='PARQUET'\n",
    ") AS\n",
    "WITH tb_min_rank AS (\n",
    "SELECT \n",
    "  rank, \n",
    "  min_rank, \n",
    "  row_id, \n",
    "  ets_insee_inpi_regle.index_id, \n",
    "  siren, \n",
    "  siret, \n",
    "  sequence_id, \n",
    "  count_inpi_index_id_siret, \n",
    "  count_inpi_siren_siret, \n",
    "  count_initial_insee, \n",
    "  test_index_id_duplicate, \n",
    "  test_siren_insee_siren_inpi, \n",
    "  adresse_distance_insee, \n",
    "  adresse_distance_inpi, \n",
    "  insee_except, \n",
    "  inpi_except, \n",
    "  intersection, \n",
    "  union_, \n",
    "  pct_intersection, \n",
    "  index_id_max_intersection, \n",
    "  status_cas, \n",
    "  test_pct_intersection, \n",
    "  unzip_inpi, \n",
    "  unzip_insee, \n",
    "  max_cosine_distance, \n",
    "  key_except_to_test, \n",
    "  levenshtein_distance, \n",
    "  test_similarite_exception_words, \n",
    "  test_distance_levhenstein_exception_words, \n",
    "  list_numero_voie_matching_inpi, \n",
    "  list_numero_voie_matching_insee, \n",
    "  intersection_numero_voie, \n",
    "  union_numero_voie, \n",
    "  test_list_num_voie, \n",
    "  enseigne, \n",
    "  list_enseigne, \n",
    "  list_enseigne_contain, \n",
    "  test_enseigne, \n",
    "  date_debut_activite, \n",
    "  test_date, \n",
    "  etablissementsiege, \n",
    "  status_ets, \n",
    "  test_siege, \n",
    "  etatadministratifetablissement, \n",
    "  status_admin, \n",
    "  test_status_admin \n",
    "FROM \n",
    "  ets_siretisation.ets_insee_inpi_regle \n",
    "  INNER JOIN (\n",
    "    SELECT \n",
    "      index_id, \n",
    "      MIN(rank) AS min_rank \n",
    "    FROM \n",
    "      ets_siretisation.ets_insee_inpi_regle \n",
    "    GROUP BY \n",
    "      index_id\n",
    "  ) as tb_min_rank ON ets_insee_inpi_regle.index_id = tb_min_rank.index_id \n",
    "  AND ets_insee_inpi_regle.rank = tb_min_rank.min_rank\n",
    "  )\n",
    "  SELECT \n",
    "  rank, \n",
    "  min_rank, \n",
    "  row_id, \n",
    "  tb_min_rank.index_id, \n",
    "  count_index,\n",
    "  siren, \n",
    "  siret, \n",
    "  sequence_id, \n",
    "  count_inpi_index_id_siret, \n",
    "  count_inpi_siren_siret, \n",
    "  count_initial_insee, \n",
    "  test_index_id_duplicate, \n",
    "  test_siren_insee_siren_inpi, \n",
    "  adresse_distance_insee, \n",
    "  adresse_distance_inpi, \n",
    "  insee_except, \n",
    "  inpi_except, \n",
    "  intersection, \n",
    "  union_, \n",
    "  pct_intersection, \n",
    "  index_id_max_intersection, \n",
    "  status_cas, \n",
    "  test_pct_intersection, \n",
    "  unzip_inpi, \n",
    "  unzip_insee, \n",
    "  max_cosine_distance, \n",
    "  key_except_to_test, \n",
    "  levenshtein_distance, \n",
    "  test_similarite_exception_words, \n",
    "  test_distance_levhenstein_exception_words, \n",
    "  list_numero_voie_matching_inpi, \n",
    "  list_numero_voie_matching_insee, \n",
    "  intersection_numero_voie, \n",
    "  union_numero_voie, \n",
    "  test_list_num_voie, \n",
    "  enseigne, \n",
    "  list_enseigne, \n",
    "  list_enseigne_contain, \n",
    "  test_enseigne, \n",
    "  date_debut_activite, \n",
    "  test_date, \n",
    "  etablissementsiege, \n",
    "  status_ets, \n",
    "  test_siege, \n",
    "  etatadministratifetablissement, \n",
    "  status_admin, \n",
    "  test_status_admin \n",
    "  FROM tb_min_rank\n",
    "  LEFT JOIN (\n",
    "    SELECT index_id, COUNT(*) AS count_index\n",
    "    FROM tb_min_rank\n",
    "    GROUP BY index_id\n",
    "    ) as tb_nb_index\n",
    "    ON tb_min_rank.index_id = tb_nb_index.index_id\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "  filename = None, ## Add filename to print dataframe\n",
    "  destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse\n",
    "\n",
    "1. Count nombre lignes & index\n",
    "2. Evaluation des doublons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Count nombre lignes & index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre de lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT COUNT(*) as CNT\n",
    "FROM ets_insee_inpi_no_duplicate \n",
    "\"\"\"\n",
    "\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "      filename = 'cnt_nb_lignes_rank', ## Add filename to print dataframe\n",
    "      destination_key = None ### Add destination key if need to copy output\n",
    "        )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre d'index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT COUNT(distinct(index_id)) as CNT\n",
    "FROM ets_insee_inpi_no_duplicate \n",
    "\"\"\"\n",
    "\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "      filename = 'cnt_nb_index_rank', ## Add filename to print dataframe\n",
    "      destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre d'index par cas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT status_cas,  COUNT(distinct(index_id)) as cnt\n",
    "FROM ets_insee_inpi_no_duplicate \n",
    "GROUP BY status_cas\n",
    "ORDER BY cnt\n",
    "\"\"\"\n",
    "\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "      filename = 'cnt_nb_index_rank', ## Add filename to print dataframe\n",
    "      destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluation des doublons\n",
    "\n",
    "Le tableau ci dessous récapitule les index uniques et les doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT count_index, COUNT(*) as ligne_dup\n",
    "FROM ets_insee_inpi_no_duplicate \n",
    "GROUP BY count_index \n",
    "ORDER BY count_index\n",
    "\"\"\"\n",
    "\n",
    "nb_ligne = s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "      filename = 'cnt_nb_dup_lignes_rank', ## Add filename to print dataframe\n",
    "      destination_key = None ### Add destination key if need to copy output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT count_index, COUNT(DISTINCT(index_id)) as index_dup\n",
    "FROM ets_insee_inpi_no_duplicate \n",
    "GROUP BY count_index \n",
    "ORDER BY count_index\n",
    "\"\"\"\n",
    "\n",
    "nb_index = s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "      filename = 'cnt_nb_dup_index_rank', ## Add filename to print dataframe\n",
    "      destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "pd.concat([    \n",
    " pd.concat([\n",
    "    pd.concat(\n",
    "    [\n",
    "        nb_ligne.sum().to_frame().T.rename(index = {0:'total'}), \n",
    "        nb_ligne\n",
    "    ], axis = 0),\n",
    "    ],axis = 1,keys=[\"Lignes\"]),\n",
    "    (\n",
    " pd.concat([\n",
    "    pd.concat(\n",
    "    [\n",
    "        nb_index.sum().to_frame().T.rename(index = {0:'total'}), \n",
    "        nb_index\n",
    "    ], axis = 0),\n",
    "    ],axis = 1,keys=[\"Index\"])\n",
    ")],axis= 1\n",
    "    )\n",
    "    .style\n",
    "    .format(\"{:,.0f}\")\n",
    "                  .bar(subset= [\n",
    "                      ('Lignes','ligne_dup'),\n",
    "                      ('Index','index_dup'),\n",
    "                      \n",
    "                  ],\n",
    "                       color='#d65f5f')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre d'index récuperé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_index.iloc[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre d'index a trouver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_index.sum().to_frame().T.rename(index = {0:'total'}).iloc[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pourcentage de probable trouvé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(nb_index.iloc[0,1] / nb_index.sum().to_frame().T.rename(index = {0:'total'}).iloc[0,1], 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse des ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH dataset AS (\n",
    "  \n",
    "  SELECT \n",
    "  MAP(\n",
    "    ARRAY[0.1,0.25,0.5,0.75,0.8,0.95],\n",
    "    approx_percentile(\n",
    "      min_rank,\n",
    "    ARRAY[0.1,0.25,0.5,0.75,0.8,0.95])\n",
    "    ) AS nest\n",
    "    FROM \"ets_siretisation\".\"ets_insee_inpi_no_duplicate\"  \n",
    "    ) \n",
    "    \n",
    "    SELECT \n",
    "    pct, \n",
    "    value AS  min_rank\n",
    "    FROM dataset\n",
    "    CROSS JOIN UNNEST(nest) as t(pct, value)\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "      filename = 'distribution_rank', ## Add filename to print dataframe\n",
    "      destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regle 10% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"\"\"\n",
    "SELECT *\n",
    "FROM rank_matrice_regles_gestion \n",
    "WHERE rank = 2857\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "      filename = 'rules', ## Add filename to print dataframe\n",
    "      destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"\"\"\n",
    "SELECT *\n",
    "FROM ets_insee_inpi_no_duplicate \n",
    "WHERE rank = 2857\n",
    "LIMIT 3\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "      filename = 'rules', ## Add filename to print dataframe\n",
    "      destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regle 25% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"\"\"\n",
    "SELECT *\n",
    "FROM rank_matrice_regles_gestion \n",
    "WHERE rank = 3995\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "      filename = 'rules', ## Add filename to print dataframe\n",
    "      destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"\"\"\n",
    "SELECT *\n",
    "FROM ets_insee_inpi_no_duplicate \n",
    "WHERE rank = 3995\n",
    "LIMIT 3\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output='INPI/sql_output',\n",
    "      filename = 'rules', ## Add filename to print dataframe\n",
    "      destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regle 50% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"\"\"\n",
    "SELECT *\n",
    "FROM rank_matrice_regles_gestion \n",
    "WHERE rank = 4481\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "      filename = 'rules', ## Add filename to print dataframe\n",
    "      destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"\"\"\n",
    "SELECT * \n",
    "FROM ets_insee_inpi_no_duplicate \n",
    "WHERE min_rank = 4481\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "      filename = 'rules_32141', ## Add filename to print dataframe\n",
    "      destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regle 75% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"\"\"\n",
    "SELECT *\n",
    "FROM rank_matrice_regles_gestion \n",
    "WHERE rank = 14335\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "      filename = 'rules', ## Add filename to print dataframe\n",
    "      destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"\"\"\n",
    "SELECT * \n",
    "FROM ets_insee_inpi_no_duplicate \n",
    "WHERE min_rank = 14336\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "      filename = 'rules_32141', ## Add filename to print dataframe\n",
    "      destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regle 80% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"\"\"\n",
    "SELECT *\n",
    "FROM rank_matrice_regles_gestion \n",
    "WHERE rank = 27295\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output=s3_output,\n",
    "      filename = 'rules', ## Add filename to print dataframe\n",
    "      destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"\"\"\n",
    "SELECT * \n",
    "FROM ets_insee_inpi_no_duplicate \n",
    "WHERE min_rank = 27295\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output='INPI/sql_output',\n",
    "      filename = 'rules_32141', ## Add filename to print dataframe\n",
    "      destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regle 95% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"\"\"\n",
    "SELECT *\n",
    "FROM rank_matrice_regles_gestion \n",
    "WHERE rank = 32021\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output='INPI/sql_output',\n",
    "      filename = 'rules', ## Add filename to print dataframe\n",
    "      destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"\"\"\n",
    "SELECT * \n",
    "FROM ets_insee_inpi_no_duplicate \n",
    "WHERE min_rank = 32021\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "s3.run_query(\n",
    "            query=query,\n",
    "            database=database,\n",
    "            s3_output='INPI/sql_output',\n",
    "      filename = 'rules_32141', ## Add filename to print dataframe\n",
    "      destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_key = \"nom_greffe\"\n",
    "proba = .9\n",
    "dic_tables = {}\n",
    "\n",
    "to_include_cat = []\n",
    "to_include_cont = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT nom_greffe, origin, COUNT(*) AS COUNT\n",
    "FROM ets_filtre_enrichie_historique \n",
    "GROUP BY nom_greffe, origin\n",
    "\"\"\"\n",
    "df_ = s3.run_query(\n",
    "            query=query,\n",
    "            database=\"ets_inpi\",\n",
    "            s3_output='INPI/sql_output',\n",
    "      filename = 'test_chi', ## Add filename to print dataframe\n",
    "      destination_key = None ### Add destination key if need to copy output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'origin'\n",
    "table = (\n",
    "    df_\n",
    "    .set_index(['nom_greffe', 'origin'])\n",
    "    .unstack('origin')\n",
    "    .fillna(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p, dof, expected = chi2_contingency(table)\n",
    "critical = chi2.ppf(proba, dof)\n",
    "\n",
    "if abs(stat) >= critical:\n",
    "    to_include_cat.append('PO Sub Type')\n",
    "    result = 'Dependent (reject H0)'\n",
    "    to_include_cat.append(col)\n",
    "else:\n",
    "    result = 'Independent (fail to reject H0)'\n",
    "\n",
    "dic_results = {\n",
    "            'test': 'Chi Square',\n",
    "            'primary_key': primary_key,\n",
    "            'secondary_key': col,\n",
    "            'statistic': stat,\n",
    "            'p_value': p,\n",
    "            'dof': dof,\n",
    "            'critical': critical,\n",
    "            'result': result\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, shutil, urllib, ipykernel, json\n",
    "from pathlib import Path\n",
    "from notebook import notebookapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_report(extension = \"html\", keep_code = False):\n",
    "    \"\"\"\n",
    "    Create a report from the current notebook and save it in the \n",
    "    Report folder (Parent-> child directory)\n",
    "    \n",
    "    1. Exctract the current notbook name\n",
    "    2. Convert the Notebook \n",
    "    3. Move the newly created report\n",
    "    \n",
    "    Args:\n",
    "    extension: string. Can be \"html\", \"pdf\", \"md\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ### Get notebook name\n",
    "    connection_file = os.path.basename(ipykernel.get_connection_file())\n",
    "    kernel_id = connection_file.split('-', 1)[0].split('.')[0]\n",
    "\n",
    "    for srv in notebookapp.list_running_servers():\n",
    "        try:\n",
    "            if srv['token']=='' and not srv['password']:  \n",
    "                req = urllib.request.urlopen(srv['url']+'api/sessions')\n",
    "            else:\n",
    "                req = urllib.request.urlopen(srv['url']+ \\\n",
    "                                             'api/sessions?token=' + \\\n",
    "                                             srv['token'])\n",
    "            sessions = json.load(req)\n",
    "            notebookname = sessions[0]['name']\n",
    "        except:\n",
    "            pass  \n",
    "    \n",
    "    sep = '.'\n",
    "    path = os.getcwd()\n",
    "    #parent_path = str(Path(path).parent)\n",
    "    \n",
    "    ### Path report\n",
    "    #path_report = \"{}/Reports\".format(parent_path)\n",
    "    #path_report = \"{}/Reports\".format(path)\n",
    "    \n",
    "    ### Path destination\n",
    "    name_no_extension = notebookname.split(sep, 1)[0]\n",
    "    source_to_move = name_no_extension +'.{}'.format(extension)\n",
    "    dest = os.path.join(path,'Reports', source_to_move)\n",
    "    \n",
    "    ### Generate notebook\n",
    "    if keep_code:\n",
    "        os.system('jupyter nbconvert --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    else:\n",
    "        os.system('jupyter nbconvert --no-input --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    \n",
    "    ### Move notebook to report folder\n",
    "    #time.sleep(5)\n",
    "    shutil.move(source_to_move, dest)\n",
    "    print(\"Report Available at this adress:\\n {}\".format(dest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_report(extension = \"html\",keep_code = True)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.24.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
